{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9c6047b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import IPython.display as ipd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "import sklearn as skl\n",
    "import sklearn.utils, sklearn.preprocessing, sklearn.decomposition, sklearn.svm\n",
    "#import librosa\n",
    "#import librosa.display\n",
    "\n",
    "import utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45099de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('project_part1/fma_metadata')\n",
    "X = np.load('X_cleaned_attempt_new.npy',allow_pickle=True)\n",
    "Y = np.load('Y_cleaned_attempt_new.npy',allow_pickle=True)\n",
    "feature_map = {'Rock':0,'Electronic':1,'Experimental':2,'Hip-Hop':3,'Folk':4,'Instrumental':5,'Pop':6,\n",
    "              'International':7,'Classical':8,'Old-Time / Historic':9, 'Jazz':10,'Country':11,'Soul-RnB':12,\n",
    "              'Spoken':13,'Blues':14,'Easy Listening':15}\n",
    "for i in range(Y.shape[0]):\n",
    "    Y[i] = float(feature_map[Y[i]])\n",
    "Y[i] = np.asarray(Y[i]).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "30d50e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f9e59195",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for (i,j) in zip(range(X.shape[0]),range(X.shape[1])):\n",
    " #  assert first_X[i,j] == scaled_X[i,j] (assertion failed)\n",
    "\n",
    "def train_mlp(X,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs):\n",
    "    \n",
    "    #usage: history = train_mlp(X,Y,input_dim,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "    \n",
    "    # X: input training matrix\n",
    "    # Y: labels (numerical)\n",
    "    # init_activation: activation function for the first layer (just easier to code if it's separate from the others)\n",
    "    # hidden_layers: list of numbers of nodes for hidden each layer,\n",
    "    # --------------> starting from the second (the first will have all 520 features)\n",
    "    # activation_funcs: activation function for each hidden layer (string)\n",
    "    # optimizer: some kind of thing\n",
    "    # loss: string specifying loss function\n",
    "    # metrics: list of strings of metrics to use to measure the success of the model on training set\n",
    "    # epochs: number of training epochs\n",
    "    \n",
    "    # first, scale data to mean 0 and variance 1\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    # then, get X and Y in proper forms\n",
    "    X = np.asarray(X).astype('float32')\n",
    "    Y = np.asarray(Y).astype('float32')\n",
    "    \n",
    "    inputs = keras.Input(shape=X.shape[1], )\n",
    "    x = layers.Dense(Y.shape[0], activation=\"relu\")(inputs)\n",
    "    for n in range(len(hidden_layers)):\n",
    "        x = layers.Dense(hidden_layers[n],activation=activation_funcs[n])(x)\n",
    "    outputs = layers.Dense(16, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizer,loss=loss,metrics=metrics)\n",
    "    return (X, Y, model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "43d407bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we need to load in the test data\n",
    "X_test = np.load('X_test.npy',allow_pickle=True)\n",
    "Y_test = np.load(\"Y_test.npy\",allow_pickle=True)\n",
    "X_test = np.asarray(X_test).astype('float32')\n",
    "Y_test = np.asarray(Y_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "b6c0acb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "293/293 [==============================] - 16s 51ms/step - loss: 1.7547 - accuracy: 0.4540\n",
      "Epoch 2/200\n",
      "293/293 [==============================] - 15s 50ms/step - loss: 1.4292 - accuracy: 0.5375\n",
      "Epoch 3/200\n",
      "293/293 [==============================] - 14s 47ms/step - loss: 1.2647 - accuracy: 0.5848\n",
      "Epoch 4/200\n",
      "293/293 [==============================] - 14s 47ms/step - loss: 1.1497 - accuracy: 0.6241\n",
      "Epoch 5/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 1.0518 - accuracy: 0.6514\n",
      "Epoch 6/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.9324 - accuracy: 0.6900\n",
      "Epoch 7/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.8442 - accuracy: 0.7189\n",
      "Epoch 8/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.7205 - accuracy: 0.7570\n",
      "Epoch 9/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.6285 - accuracy: 0.7886\n",
      "Epoch 10/200\n",
      "293/293 [==============================] - 14s 46ms/step - loss: 0.5496 - accuracy: 0.8183\n",
      "Epoch 11/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.4993 - accuracy: 0.8352\n",
      "Epoch 12/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.5134 - accuracy: 0.8370\n",
      "Epoch 13/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.3999 - accuracy: 0.8737\n",
      "Epoch 14/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.3449 - accuracy: 0.8852\n",
      "Epoch 15/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.3184 - accuracy: 0.8955\n",
      "Epoch 16/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.2333 - accuracy: 0.9282\n",
      "Epoch 17/200\n",
      "293/293 [==============================] - 13s 43ms/step - loss: 0.2992 - accuracy: 0.9019\n",
      "Epoch 18/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.2470 - accuracy: 0.9187\n",
      "Epoch 19/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1991 - accuracy: 0.9364\n",
      "Epoch 20/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.2183 - accuracy: 0.9299\n",
      "Epoch 21/200\n",
      "293/293 [==============================] - 13s 46ms/step - loss: 0.2495 - accuracy: 0.9225\n",
      "Epoch 22/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.2199 - accuracy: 0.9291\n",
      "Epoch 23/200\n",
      "293/293 [==============================] - 16s 54ms/step - loss: 0.2023 - accuracy: 0.9375\n",
      "Epoch 24/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.2087 - accuracy: 0.9340\n",
      "Epoch 25/200\n",
      "293/293 [==============================] - 15s 50ms/step - loss: 0.2003 - accuracy: 0.9405\n",
      "Epoch 26/200\n",
      "293/293 [==============================] - 14s 47ms/step - loss: 0.1722 - accuracy: 0.9500\n",
      "Epoch 27/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1236 - accuracy: 0.9622\n",
      "Epoch 28/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1618 - accuracy: 0.9509\n",
      "Epoch 29/200\n",
      "293/293 [==============================] - 14s 46ms/step - loss: 0.2256 - accuracy: 0.9310\n",
      "Epoch 30/200\n",
      "293/293 [==============================] - 17s 57ms/step - loss: 0.1506 - accuracy: 0.9538\n",
      "Epoch 31/200\n",
      "293/293 [==============================] - 16s 54ms/step - loss: 0.1152 - accuracy: 0.9652\n",
      "Epoch 32/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1509 - accuracy: 0.9560\n",
      "Epoch 33/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.2072 - accuracy: 0.9427\n",
      "Epoch 34/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1818 - accuracy: 0.9478\n",
      "Epoch 35/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1643 - accuracy: 0.9543\n",
      "Epoch 36/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1074 - accuracy: 0.9697\n",
      "Epoch 37/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1221 - accuracy: 0.9692\n",
      "Epoch 38/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1380 - accuracy: 0.9599\n",
      "Epoch 39/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1595 - accuracy: 0.9598\n",
      "Epoch 40/200\n",
      "293/293 [==============================] - 15s 50ms/step - loss: 0.1492 - accuracy: 0.9597\n",
      "Epoch 41/200\n",
      "293/293 [==============================] - 16s 56ms/step - loss: 0.1025 - accuracy: 0.9688\n",
      "Epoch 42/200\n",
      "293/293 [==============================] - 14s 47ms/step - loss: 0.0966 - accuracy: 0.9709\n",
      "Epoch 43/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0987 - accuracy: 0.9705\n",
      "Epoch 44/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1314 - accuracy: 0.9651\n",
      "Epoch 45/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1449 - accuracy: 0.9615\n",
      "Epoch 46/200\n",
      "293/293 [==============================] - 14s 47ms/step - loss: 0.1281 - accuracy: 0.9652\n",
      "Epoch 47/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1446 - accuracy: 0.9615\n",
      "Epoch 48/200\n",
      "293/293 [==============================] - 13s 43ms/step - loss: 0.1300 - accuracy: 0.9650\n",
      "Epoch 49/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1188 - accuracy: 0.9698\n",
      "Epoch 50/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0959 - accuracy: 0.9730\n",
      "Epoch 51/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0603 - accuracy: 0.9818\n",
      "Epoch 52/200\n",
      "293/293 [==============================] - 13s 43ms/step - loss: 0.0558 - accuracy: 0.9841\n",
      "Epoch 53/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1458 - accuracy: 0.9642\n",
      "Epoch 54/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1093 - accuracy: 0.9677\n",
      "Epoch 55/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1531 - accuracy: 0.9619\n",
      "Epoch 56/200\n",
      "293/293 [==============================] - 14s 46ms/step - loss: 0.1459 - accuracy: 0.9652\n",
      "Epoch 57/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0844 - accuracy: 0.9744\n",
      "Epoch 58/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0817 - accuracy: 0.9757\n",
      "Epoch 59/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1220 - accuracy: 0.9674\n",
      "Epoch 60/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0872 - accuracy: 0.9766\n",
      "Epoch 61/200\n",
      "293/293 [==============================] - 15s 51ms/step - loss: 0.0955 - accuracy: 0.9757\n",
      "Epoch 62/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1123 - accuracy: 0.9723\n",
      "Epoch 63/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0759 - accuracy: 0.9788\n",
      "Epoch 64/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1744 - accuracy: 0.9618\n",
      "Epoch 65/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1460 - accuracy: 0.9645\n",
      "Epoch 66/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0942 - accuracy: 0.9795\n",
      "Epoch 67/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0930 - accuracy: 0.9771\n",
      "Epoch 68/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0451 - accuracy: 0.9878\n",
      "Epoch 69/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0217 - accuracy: 0.9938\n",
      "Epoch 70/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0538 - accuracy: 0.9861\n",
      "Epoch 71/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1561 - accuracy: 0.9604\n",
      "Epoch 72/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1941 - accuracy: 0.9546\n",
      "Epoch 73/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0794 - accuracy: 0.9787\n",
      "Epoch 74/200\n",
      "293/293 [==============================] - 13s 46ms/step - loss: 0.0752 - accuracy: 0.9825\n",
      "Epoch 75/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1040 - accuracy: 0.9735\n",
      "Epoch 76/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1065 - accuracy: 0.9783\n",
      "Epoch 77/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0614 - accuracy: 0.9835\n",
      "Epoch 78/200\n",
      "293/293 [==============================] - 14s 46ms/step - loss: 0.0620 - accuracy: 0.9842\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0487 - accuracy: 0.9871\n",
      "Epoch 80/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0577 - accuracy: 0.9853\n",
      "Epoch 81/200\n",
      "293/293 [==============================] - 14s 46ms/step - loss: 0.1419 - accuracy: 0.9690\n",
      "Epoch 82/200\n",
      "293/293 [==============================] - 15s 51ms/step - loss: 0.1492 - accuracy: 0.9660\n",
      "Epoch 83/200\n",
      "293/293 [==============================] - 14s 49ms/step - loss: 0.0784 - accuracy: 0.9814\n",
      "Epoch 84/200\n",
      "293/293 [==============================] - 14s 48ms/step - loss: 0.0321 - accuracy: 0.9917\n",
      "Epoch 85/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0404 - accuracy: 0.9871\n",
      "Epoch 86/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0693 - accuracy: 0.9841\n",
      "Epoch 87/200\n",
      "293/293 [==============================] - 13s 43ms/step - loss: 0.1141 - accuracy: 0.9732\n",
      "Epoch 88/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0684 - accuracy: 0.9812\n",
      "Epoch 89/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0987 - accuracy: 0.9772\n",
      "Epoch 90/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1081 - accuracy: 0.9738\n",
      "Epoch 91/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0946 - accuracy: 0.9758\n",
      "Epoch 92/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0721 - accuracy: 0.9827\n",
      "Epoch 93/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0233 - accuracy: 0.9937\n",
      "Epoch 94/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0097 - accuracy: 0.9974\n",
      "Epoch 95/200\n",
      "293/293 [==============================] - 14s 47ms/step - loss: 0.0637 - accuracy: 0.9862\n",
      "Epoch 96/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1419 - accuracy: 0.9694\n",
      "Epoch 97/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1611 - accuracy: 0.9696\n",
      "Epoch 98/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1419 - accuracy: 0.9690\n",
      "Epoch 99/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0572 - accuracy: 0.9856\n",
      "Epoch 100/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1150 - accuracy: 0.9772\n",
      "Epoch 101/200\n",
      "293/293 [==============================] - 14s 48ms/step - loss: 0.0994 - accuracy: 0.9809\n",
      "Epoch 102/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0336 - accuracy: 0.9902\n",
      "Epoch 103/200\n",
      "293/293 [==============================] - 14s 48ms/step - loss: 0.0290 - accuracy: 0.9930\n",
      "Epoch 104/200\n",
      "293/293 [==============================] - 16s 55ms/step - loss: 0.0505 - accuracy: 0.9884\n",
      "Epoch 105/200\n",
      "293/293 [==============================] - 15s 51ms/step - loss: 0.1194 - accuracy: 0.9729\n",
      "Epoch 106/200\n",
      "293/293 [==============================] - 14s 47ms/step - loss: 0.1256 - accuracy: 0.9698\n",
      "Epoch 107/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0472 - accuracy: 0.9882\n",
      "Epoch 108/200\n",
      "293/293 [==============================] - 14s 48ms/step - loss: 0.1526 - accuracy: 0.9709\n",
      "Epoch 109/200\n",
      "293/293 [==============================] - 16s 55ms/step - loss: 0.0980 - accuracy: 0.9769\n",
      "Epoch 110/200\n",
      "293/293 [==============================] - 14s 49ms/step - loss: 0.0338 - accuracy: 0.9921\n",
      "Epoch 111/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0522 - accuracy: 0.9883\n",
      "Epoch 112/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0882 - accuracy: 0.9824\n",
      "Epoch 113/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0283 - accuracy: 0.9942\n",
      "Epoch 114/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0444 - accuracy: 0.9906\n",
      "Epoch 115/200\n",
      "293/293 [==============================] - 14s 46ms/step - loss: 0.1240 - accuracy: 0.9755\n",
      "Epoch 116/200\n",
      "293/293 [==============================] - 13s 46ms/step - loss: 0.1107 - accuracy: 0.9750\n",
      "Epoch 117/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0467 - accuracy: 0.9882\n",
      "Epoch 118/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0358 - accuracy: 0.9894\n",
      "Epoch 119/200\n",
      "293/293 [==============================] - 13s 46ms/step - loss: 0.0304 - accuracy: 0.9929\n",
      "Epoch 120/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0609 - accuracy: 0.9853\n",
      "Epoch 121/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0556 - accuracy: 0.9877\n",
      "Epoch 122/200\n",
      "293/293 [==============================] - 14s 47ms/step - loss: 0.1075 - accuracy: 0.9770\n",
      "Epoch 123/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0370 - accuracy: 0.9897\n",
      "Epoch 124/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1239 - accuracy: 0.9774\n",
      "Epoch 125/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1056 - accuracy: 0.9761\n",
      "Epoch 126/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0955 - accuracy: 0.9809\n",
      "Epoch 127/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0666 - accuracy: 0.9868\n",
      "Epoch 128/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0228 - accuracy: 0.9942\n",
      "Epoch 129/200\n",
      "293/293 [==============================] - 14s 46ms/step - loss: 0.0324 - accuracy: 0.9927\n",
      "Epoch 130/200\n",
      "293/293 [==============================] - 15s 52ms/step - loss: 0.0575 - accuracy: 0.9865\n",
      "Epoch 131/200\n",
      "293/293 [==============================] - 16s 53ms/step - loss: 0.0190 - accuracy: 0.9950\n",
      "Epoch 132/200\n",
      "293/293 [==============================] - 15s 50ms/step - loss: 0.0282 - accuracy: 0.9929\n",
      "Epoch 133/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1899 - accuracy: 0.9666\n",
      "Epoch 134/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1199 - accuracy: 0.9746\n",
      "Epoch 135/200\n",
      "293/293 [==============================] - 13s 46ms/step - loss: 0.0742 - accuracy: 0.9851\n",
      "Epoch 136/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0526 - accuracy: 0.9893\n",
      "Epoch 137/200\n",
      "293/293 [==============================] - 15s 50ms/step - loss: 0.0444 - accuracy: 0.9912\n",
      "Epoch 138/200\n",
      "293/293 [==============================] - 18s 62ms/step - loss: 0.0538 - accuracy: 0.9878\n",
      "Epoch 139/200\n",
      "293/293 [==============================] - 19s 65ms/step - loss: 0.0437 - accuracy: 0.9907\n",
      "Epoch 140/200\n",
      "293/293 [==============================] - 14s 48ms/step - loss: 0.0407 - accuracy: 0.9920\n",
      "Epoch 141/200\n",
      "293/293 [==============================] - 15s 52ms/step - loss: 0.0830 - accuracy: 0.9841\n",
      "Epoch 142/200\n",
      "293/293 [==============================] - 21s 72ms/step - loss: 0.0858 - accuracy: 0.9824\n",
      "Epoch 143/200\n",
      "293/293 [==============================] - 27s 92ms/step - loss: 0.0685 - accuracy: 0.9826\n",
      "Epoch 144/200\n",
      "293/293 [==============================] - 20s 68ms/step - loss: 0.0596 - accuracy: 0.9886\n",
      "Epoch 145/200\n",
      "293/293 [==============================] - 16s 56ms/step - loss: 0.0455 - accuracy: 0.9910\n",
      "Epoch 146/200\n",
      "293/293 [==============================] - 17s 58ms/step - loss: 0.1368 - accuracy: 0.9766\n",
      "Epoch 147/200\n",
      "293/293 [==============================] - 16s 54ms/step - loss: 0.1105 - accuracy: 0.9770\n",
      "Epoch 148/200\n",
      "293/293 [==============================] - 16s 54ms/step - loss: 0.0180 - accuracy: 0.9953\n",
      "Epoch 149/200\n",
      "293/293 [==============================] - 16s 56ms/step - loss: 0.0505 - accuracy: 0.9910\n",
      "Epoch 150/200\n",
      "293/293 [==============================] - 14s 47ms/step - loss: 0.0407 - accuracy: 0.9919\n",
      "Epoch 151/200\n",
      "293/293 [==============================] - 15s 51ms/step - loss: 0.0320 - accuracy: 0.9929\n",
      "Epoch 152/200\n",
      "293/293 [==============================] - 15s 52ms/step - loss: 0.0475 - accuracy: 0.9874\n",
      "Epoch 153/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0820 - accuracy: 0.9825\n",
      "Epoch 154/200\n",
      "293/293 [==============================] - 15s 52ms/step - loss: 0.0699 - accuracy: 0.9865\n",
      "Epoch 155/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0987 - accuracy: 0.9821\n",
      "Epoch 156/200\n",
      "293/293 [==============================] - 13s 46ms/step - loss: 0.0623 - accuracy: 0.9872\n",
      "Epoch 157/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0395 - accuracy: 0.9917\n",
      "Epoch 158/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0339 - accuracy: 0.9942\n",
      "Epoch 159/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0425 - accuracy: 0.9909\n",
      "Epoch 160/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0826 - accuracy: 0.9838\n",
      "Epoch 161/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1111 - accuracy: 0.9787\n",
      "Epoch 162/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0794 - accuracy: 0.9846\n",
      "Epoch 163/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0284 - accuracy: 0.9945\n",
      "Epoch 164/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0431 - accuracy: 0.9919\n",
      "Epoch 165/200\n",
      "293/293 [==============================] - 14s 47ms/step - loss: 0.0716 - accuracy: 0.9859\n",
      "Epoch 166/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0286 - accuracy: 0.9941\n",
      "Epoch 167/200\n",
      "293/293 [==============================] - 13s 43ms/step - loss: 0.0235 - accuracy: 0.9955\n",
      "Epoch 168/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.2019 - accuracy: 0.9647\n",
      "Epoch 169/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1551 - accuracy: 0.9725\n",
      "Epoch 170/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0484 - accuracy: 0.9893\n",
      "Epoch 171/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0219 - accuracy: 0.9954\n",
      "Epoch 172/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0190 - accuracy: 0.9953\n",
      "Epoch 173/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0741 - accuracy: 0.9848\n",
      "Epoch 174/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0883 - accuracy: 0.9806\n",
      "Epoch 175/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0544 - accuracy: 0.9872\n",
      "Epoch 176/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0163 - accuracy: 0.9963\n",
      "Epoch 177/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0175 - accuracy: 0.9965\n",
      "Epoch 178/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0862 - accuracy: 0.9870\n",
      "Epoch 179/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1068 - accuracy: 0.9778\n",
      "Epoch 180/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1060 - accuracy: 0.9787\n",
      "Epoch 181/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0360 - accuracy: 0.9924\n",
      "Epoch 182/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0326 - accuracy: 0.9925\n",
      "Epoch 183/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0755 - accuracy: 0.9848\n",
      "Epoch 184/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0481 - accuracy: 0.9905\n",
      "Epoch 185/200\n",
      "293/293 [==============================] - 13s 46ms/step - loss: 0.0221 - accuracy: 0.9947\n",
      "Epoch 186/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0335 - accuracy: 0.9937\n",
      "Epoch 187/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0573 - accuracy: 0.9904\n",
      "Epoch 188/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0265 - accuracy: 0.9952\n",
      "Epoch 189/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0159 - accuracy: 0.9964\n",
      "Epoch 190/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.1015 - accuracy: 0.9842\n",
      "Epoch 191/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0439 - accuracy: 0.9909\n",
      "Epoch 192/200\n",
      "293/293 [==============================] - 14s 47ms/step - loss: 0.0834 - accuracy: 0.9835\n",
      "Epoch 193/200\n",
      "293/293 [==============================] - 14s 49ms/step - loss: 0.0669 - accuracy: 0.9888\n",
      "Epoch 194/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0577 - accuracy: 0.9928\n",
      "Epoch 195/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0535 - accuracy: 0.9911\n",
      "Epoch 196/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0881 - accuracy: 0.9837\n",
      "Epoch 197/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0491 - accuracy: 0.9904\n",
      "Epoch 198/200\n",
      "293/293 [==============================] - 13s 45ms/step - loss: 0.0536 - accuracy: 0.9903\n",
      "Epoch 199/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.0510 - accuracy: 0.9909\n",
      "Epoch 200/200\n",
      "293/293 [==============================] - 13s 44ms/step - loss: 0.1032 - accuracy: 0.9857\n",
      "1258/1258 [==============================] - 16s 13ms/step - loss: 7694.7480 - accuracy: 0.0284\n",
      "test loss, test acc: [7694.748046875, 0.02837337553501129]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABwR0lEQVR4nO2dd3xb1fn/30fDlve2YydOYmeShOxFgAz2KFBaRilltUBpofy6KHTT0s23e1HassoIlL0pI2ElIYHsvbeTeG/LlnR+fxxdWbJlW7bl/bxfL79kXd17dY6udD/nec7zPEdprREEQRAEoe+w9XUDBEEQBGGoI2IsCIIgCH2MiLEgCIIg9DEixoIgCILQx4gYC4IgCEIfI2IsCIIgCH1Mh2KslHpAKXVCKbW5jdeVUupPSqndSqmNSqmZ0W+mIAiCIAxeIrGMHwLOa+f184Fx/r+bgb93v1mCIAiCMHToUIy11u8BZe3scgnwiDasAlKVUrnRaqAgCIIgDHaiMWc8HDgU9Pywf5sgCIIgCBHgiMI5VJhtYWtsKqVuxriyiYuLm5Wfnx+Ftzf4fD5strbHFo1eOFrrIzteEe8I1+T+Q0d9GUhIX3oGh6eGWHc5oKmLH4FWnWtXT/dFaR8ohQ57e4guLfuitNf/eYS+t8NTi8/mxGeL6fE2tYfSXhzeOpocibRsY1evi9IetOr4dm7zedBKoZU99Hg0Nm8Ddq8brz0Wrz0u7PF2nxu7pxZQ+GwxeBwJbe4X01CKQqOVjQZXVkTtC3surxsAn80R0m6Hpxa7tx6brwmPI5EmZ1KXzh8J0fy97Ny5s0RrndVyezTE+DAQrKojgKPhdtRa3w/cDzB79mz98ccfR+HtDcuXL2fx4sVtvn6orI7Tf7OM31w2lStmR28Q0BN01JeBRL/qS20pPHsjlOyC616E9MJOHd7tvmx5DrImQvZJXT8HwDM3waanIG08lO+HORfDhb/t1CkCfSnZDev+AwdXwsxrYdrnoTM3nY/uh6QcmHhR83ENlfC3U6CpDubfCvO+DK7kts9RvBNW/BE8brj4z+AMLwQd9kVreOceeP+3YI+B3Glw7i8hfw68dTd88HtzQPJw+PxTMGxK2yetr4DDa8x3JGOM2VZxyGwr3gGjToHCxe03rGwv+HyQOTZ0u3X90nNg/lfBXQ0VB6D8ABWlxaRe/icYMavjjrurYfX9sPG/ULwNUkfCvK/A7BvCf4Ylu+D+xea6FCyE075h+lB9HB44F8qPm/3S8+D2da2PX/8EvPT/wNtoNQA+/28Yf27ofpVH4J9LaHSnETNiuvnMcgrg+lfAERu6b0Ml/O+HUH0M7E5Y9B1z3QCObYL//QD2Lm/ef/hs079NT8PeZeCMB2eq6dOtb0Fqvnl/RywkZDYfV30M3rsXyvbBiDlw0qdg2MnmNZ8PKg+BsoGvydwnYuIhZ3Lg8Gjex5RSB8Jtj4YYvwjcppRaCswDKrXWRVE4b1RJjnMCUFXf1MctEfqE41vg8c9BzXFzo3r4YrjhVXMD6w4+X/ONMLadkfnG/5qBgLLDKV+FhXeAK6Xz77f5GXMjP+0bcMYPzc1q1d/gpIuhcFHnzrVhKTx3i7kJpY2CF26FdY/C5x6H+PTQPq6+HyZ/GpKGNW8/sAJeu8P8nz0Jzv+1ucm/9ROoLjL/L/sZHPgQrn0+9L0PrIBPHjLCVrTB3Dw9bqgtMe9/fDN4Gsw5ADY+Zfr5hWdD22ahNbz1Y/jwj3Dy5ZCUC1ueh4cuhCmfhQ2Pw4xrIH8uvHYnfPJg+AHMgRXwzs/M4ET7AAUTLoDGGtj3bvN+yg5X/gcmXtj6HJuehg//YMQkJgn+3wZIyDCv1ZbA1udhzJlQeRhe/bbZHp8BaaOJqy+CB86Bs+42A5lwAyOtzcDuje9D9VEYuQDO/BHsehPe+C5sfQGufir0+9VYB09dZz7nuTfDpv/CI5+Gxd+FbS+Z38UVj8CxzfDeb4x4BV/rVX+H1++C0afD5Q+Z39C/z4HnvwpfWWEGZNb7LP08NNaxfvovmHvhteY6/Pc6ePUOuPhPoX15/3ew9hEjjJWH4ZFL4LqXYPdb8PY9ZhB37i8gbbT5rqz7j/mexiTBBf8Hs78IVUfgr/PMdZ13Myz9AsQkmPOkF5pB2Ae/A28TZIyFd39tnl/xCIw8BZ78Aux/v/XnPPtLcM7PjDD3Ah2KsVLqCWAxkKmUOgz8GHACaK3vA14FLgB2A3XADT3V2O6QFOtAKahq8PR1U4YWWhvL5/gmmPRpsNk7PCTqNFQaIfY1wRdfA5sTHr4IHv0s3LoaVCdcqT6vEZeqo1C6GzY8CZUHjaANmwqf/XdrS6hsL7z8DcifB1kTYMWfYc2/jUgsvMMIYSRUH4NXvgXDZ8GSH5jP8owfws434KXb4bZPwB7mJ334E2MtXvhbSDaxlUlVu+D978Po00ybE7Jg/aPG8vngd+YmZLHnHXj9TjixNfRm+u6vzXFn/xTe/Y25kc7+Inz8b2PxnfdLI45v/siI3KgF5rj6cnPDRhkraNGdMPcm2Pk6vHAb/Ho0eN3m9etfMd6EV++Ahgp4+6dw0R9Cumfzus2gYuNSmHMjnH+vEbHTvgFPXWuEePz58Kk/mM9n+6tGuLRuvvZeDzz3Zdj8NCTlmesy8hRzrdf8ywy0Fn8PJpxnLOvHr4D/Xg8X/g7GnW2Ey9tkBHL1P4y4LLrLCNuHv2/+PNc9aizLc38OGeOMZyNpGMQmArDmzZc5rfQJM8ja8Zr5bNY+YgT85Ctg/i2w7Jew8zXz2V3xiLH8AU7/Fmx+Fp69GR76FFz9tBFJnxde+Sac2AJXPwPjzoKF34YXvwbLfwE2B3z+SRh7FqSMMG0+8KH5foIR2Hd/A4VL4Or/GgsWzPfm/kXwzJfgsgfMeZZ+3gyurlpKXZHL7Df501D0TfO9yptuviNgPA2r/g5Tr4TP/MNYrQ9eYKx3n8fcLy76A8Slmf0nXginfh0OrYK0gsB3mdSR5nN668fmO5Q5DurK4KELzGtHPoFJl5gBTnqhGRA9dhk8eY3pb+VhOPPH5rusbOZx37uw8i/m8Zrn2/pFRhetdZ/8zZo1S0eTZcuWdbjPlB+/rn/8wuaovm9PEElfBgRH1unaX03U+sfJ5m/90t57b3et1nXl5v9nv6z13alaH/yo+fW1/zFtOrq+9bEndmj99Je0/t1krY9vDWxe9cpjWv/rnOb+/DhF64cv0frjh7R+5+da/3y41k9dH3our0frfyzW+pf5WpcfMNuOrNP6+Vu1vidH67/M07qxXmufT+tV/9B69T+1bnK3blNdudb/Olvre7JN+4LZ9rJpz6Znwn8WD15oXv/bqVrXV2h9dL1u+HmB1r+bonVNSei+T9+o9c9yQ7c/fpU5/p5srWtLzbYDq8y2D/9knjdUab30arPtd5O1bqg22921Wv9mjNYPXdR8vte+az67oo2t27p+qfns1y/V+o/TzbmevlHru9O0fuLz5rhDa5r3L96lq+6dbrYv/7X5HIPxNGq99SWtG+uat63+p2ln8c7mbe/8wmx7+x7T5mB8vtbnrS3V+u+nNn8XfprZ/P9r39Xa02T2e/bL5nOrPKq116v1H6Zq/e/zWvfbz7Jly8x7rf2P1r/I93/uOVo/ea3WP8lovg4f/tl8t8Kx801zzK8LtV7/hNYPX2yOW/bL1v365BGzf+DzatL653lav/zNoM/rX+b4/R+2fq+1/9H6J+nmmN9N0fqnWVpverq5LxZej9b/+azpw4GVzZ/NT7O0Lj/YvF/JbvM9/+j+1p95e3gatb5/ifme1ZWZ38i9483vzt+eEOrKtf7nmVr/YoTWe98Nf849y7Ve+gWtPY1RvScDH+swmhgNN/WAIdnlpKpB3NS9QuVhePxKbD6Pscg+/BOsfwymXdnxsT4f1JWaOR/LcjnyCVQVmZFs9knG3VZ5BJ6+wcwBnfvz5uO1hieuhP0fGOvh6DpY+B3jorQY55/n2vm/5jkqgB2vwxOfM3NRjlh4/Eq48S3Y/AyzP/4RxMSZec1Rp0JidqhruqnejKbLf2zcamAsmqNr4dL7m13iedPhkr+Y0fpjlxlXrivVzHeCsSYXfgemXuHv52F47Aoo2Qmf/RdkjQ/9vMafb0b8K/8Cky8NtfSPrDUuuJMuhh2vGndedRE2RyJ87vlm96nF6d8ybvCP/g5n/MB8xjtfgwkXwo5XjGv51K8biyo+s9nKiU2CK/4D6x83VqHf0iMmHk79f8bS2/eesTpX3w8zr2meswtm2pXN35H0QjOXuekpY2kv+R78ZQ48/xXjQqwrhQ//gEs5jWXXcu4SjBV30qdCt4092zzuetNYUQdXGWtw6udMn1sSznMSnw43LTNW4MFVUHsCHC7jtQhux6I7jUv45W+Y/pTvN96M9lAKZnzBuLJ3vGrc5Mm5ULrHWMkzvmDa3RbjzoKblxkL+bkvgz3WfGdnXtv6fWZeE7rN7jAenAMrzHOfz0wP5M0wnoKWzPgC5M83Vunhj+HaF8x8ektsdvPd/ecS85tKyILSXea7lBoUw5MxBr70v/Y/n3DYnfClt5rd+nFp8NWV5v9w0xpxqXDD69BU2/Z0UeGizk/9dIOhJcZxTqrqxU3d4/iFmKY6Nk79OXPnXGuCIpb/EioOtj1PW19uglsOrjRzdFOvhE/fZ9ykj11GIEg/McfcWNY9auYmj6yFBV9rnuPa9575G3++eb+CRSYwJJjELMibCbvegEV3NG9f+zAk58GX34PyA8bV9acZ0FhDRfpsMq5/tNk91pL5XzFut5V/hQvuNTey9/4PMieYecyWjDsbZt1g3NZg+nvyFfDOT+HF28zcZdIwc8N3xhsX4Zglrc9jsxmxevXbcOgjGDm/+bWVf4HYZLjkr8advexncMYP+Mh9EqflTm19ruyJRrg/+gfMut7c/LWG835hrsmaf5mAnL3LTXBUTFA0rVIw4+rW55z9RTPAePgi8zwm0bjZOyJ/Dpz9ExM4tPguI/gX/9kIzOt3mn2mfJY1SRexIJwQt0XaKMgcD7vfNK7YZ24y38kL7o38HGAEYMRs89cW6QVm4LD6H/7nhXDSRZGdPzkX5nyp+XnGGPN5REL2SXDj2+b7nD83dMDZEaNPNdMBtaXmWpfuNi7ptqZzMsfC5x4LdfuHIy4VPud3wTvjYMpnzEAtWrScXw8nwsHYHWDvQtxGDzG0xNjlGJqW8dYXjFUVl2YswuCRaDC1pbDlWWMxVB42N79hJ8OZP4ws2Kh4hxGQ7S+bAJern6LukP8HMu1zxprasLS1MIKZs3v6i7DvfSMCviZjhSmbmePLmWLmjyoOGBF+714zd3flYyYAY/U/TTu1huW/MgE8lz8ETlfb7R1/rtm3tsRY4Y21RvhnXmeeJ2TCpffBmz+GC+5lU3kui9sSYjAiPvUKWPsfOO2bxpo/sdVYxW1FKJ/zMzi02lg6l/zV3ODHnmkiRVf9Hdw1xiKc/JnWc9HBTP88LPu5mZ8dd47ZFptkgmdO+aoJhJl6ufkDPMuXt32uhXeY+co/TjNRyWPPMpb+/K8Yr0H1MTj/NyYQKBJiEszc7643ob7MWFhWwE9HLPia+bMYdzbcsccEHLlrIHMsje31pS3Gnm0GFv+51FjY17/UfsR3dzjvV8bjEJtoBlWdiVHoDo4YMxffWUadah43PwMr/wwp+caL0xGR9Ct7Inzh6c63aQgwtMQ4zsmhsrq+bkb0KN5hAhkc7eRNlh8wIufzewSSfwc3Lzcu1mDqyuDfZ5lgo7QCM7J2V8PHDxjr8dJ/NAfg1JWZCMacKeYH2NRgLJ/3/8+MeBfcbkb0qSPh0HJzTNooExm77lETULXpaTjlVnOj1T5484dGCC/6oxFjrY0QrL7fRJpe9bg534jZxpop2QVx6cbNOvFC086F3zbCdnCFCeJpT4jBiNbyX8Lut41rdM87JoI3OEJ28qXmDyCSm/6C203k75+mGzFMK2gOhAlHbCLc8kGoWCsFY84wf5ESk2Cib5f9zFjHFvZYmHdL5OcByJ0Kt35kPtNtL8FpXzfbx51rgpIKFzV/FyIla4L5iwZKGY9Bd9JKx50Fq/5qXKWff8q4l3sKmy3ywUd/IG+Gcbm/dofxqlz7QnPQltBjDC0xdjmpHijR1B43bH3RzHeFyxncswz+82nj8rr8kbYtrw//YKzL29dDzQkT8frUdeYHZom4t8lEhlYehmtfDJ0nObQanrkRHjzfzGHlTIaPH4TGahgx1+Qprn3YWCpTLjNWQGKrfHbD9C/Aczcbiy97kl+A3zau5LK9MOcmI8Rgbrjn/crMERcsbO3aDp4zm/9VY40/+lmTTpKU13p+LBy50yEh2ww2pl0J218xc7edFZpgsifCl981Qrb1BZNyEi7COZhoFd9YdIeJtrXHmAFOXanxULRnzbdFxhgzDx88F2+zwZLvRqetfc2oU83UwZTLwrv+hzKOWPMbOPiRicgeLmv/9AZDS4zjHAMnz/jd3xhLc94tJn8zGHcNvHi7GbVue8m4bBff2focVUeNJTrjC2buKr3ABA498yUzDxqbZNIRPPVmXuiSv7UOWMifa/II1/wTVvzFiOekT5vtK/9mAl8Kl5g5pYLT2+/TlM8ay7NwEaSOMoEhb91tRPHMH8FJLVxhNntkc0qjFpiBQdEGMzg55baOrWIw4jLubCOa+94zrtnx53XfCsiZbILWOlmIIyoEB5SljOj99x8oOGJNQJEQnk/fZ9LLupuHL0TM0BJjl5NqtwevT2O39d+SmPG1h+CTP5o53o/uM/M1wdba2z8xFWO++LqZV13+C+NaGn9O6Ik+/KOxkE79evO2ky8zgTh7l5v8Q5/XuLDn3hw++AaMK/W0b8DcL4O7qjlQas6NZr41JcJS5HYHzLqu+fkpt5qKQd21DJWC6182ru1IRDiYhd820bBWcFG4Ig6CMNQYSG71QcLQEmN/Fa6aBg8p8f10DkRrxu26z8wB3rzcVIp64Va45UOTJlK6x8yjzv2yiZrNnW5Sd16/07iMLdfzqvtMROyML7QuKjHr+mZ3cGeIiQ+tRuOIjVyI2yJaLtqWZfYiJb3QfM4vfs3MtXZmnlYQBCFK9I+q971EssuMPfp1RPXq+0mr2Axn+XNVL/6TmU9d/5h5fevz5tGKMHW6TERu2V4THepxw6vfMeI88UIT9Sq0jysZrngYvrG1OT9WEAShFxlaYuy3jCv767zxgZXwxvcoyZgDM6832woWmajl9Y+b51tfMMXSg9OTxp5lLLp3fw33LzE5jfO/akrl9VJd1UFBP1mRSRCEoceQuvsku/yLRfRHy7j8gCmmnjqKbSd9o1kYlDI5pEfXmupQRRtMrddglDLWsbsK6kpMqsZ5v+ybOtCCIAhCpxlaYhznd1P3RhWuqiJTalGHXdoZ9n8IT1wF2142xSH+fbbJ173yUbwt1wideqWJen7hVvP8pItbny9nsqka9dVV4csCCoIgCP2WoRXA1ZuW8Uu3w67/mdzZ834Vmmt6bLOpZNRYa2rPAqSMNDm+2RNh24nQcyVkmpSb7S+bqOm2VvkJV+tXEARB6PcMKcvYiqCurIuiGDdUmfSeYEp2GSHOnmTyc5d+3iwiAKbAxWOXm/q8t681+bkzrzOLEWRPbPt9pn/ePEZSlk4QBEEYUAwpyzgp1kGM3UZpbWP0TvrS7XBimykfaPHRfaYK0rUvwrYXzRq0Sz8PS75v6ig31pl1ddNGm7+TL+v4fcafBxf9yRRXFwRBEAYVQ0qMlVKkJ8RQWuOOzgm1NpWb6kpN/m/GGLPy0PrHTam9xCxTo9kRaxZN3/OOKdX4xdfMHG9nsNlDC2YIgiAIg4YhJcYAGYkx0bOMS3cbIQbY/ZYR47X/gaa60OL8M75gLOVNT8Onft/9QhmCIAjCoGJIzRkDZCTGRs8ytlbHiU02y8N5PaY61qjTzMo3wUy9Aq5+SoRYEARBaMWQE+PMhBhKaqJkGR9cZVb5mXYV7H/frP9ZecisnCMIgiAIETLkxDgjMYayaLmpD602qxeNO8esRvTad8wqJxMuiM75BUEQhCHBEBTjWOqbvNQ1drPwR10ZlOyA/Hkw+lSzGHdDhVnAQSpfCYIgCJ1gyIlxeoJZ1ai0u67qQ6vN48j54IwzNaSdCSZYSxAEQRA6wZCLps5MNGJcUuMmP70biygc+siUqMybaZ5f+H9QWwxxqd1vpCAIgjCkGHJinJFg1r3tlmVcVwYblprVk6xVkVJHmj9BEARB6CRDT4z9lnGXg7i0Ngs21BbDVY9HsWWCIAjCUGXoibHfMi6p7WKu8ep/msUdzv2FWbRBEARBELrJkAvgiouxkxBj75qbumwvvPkjGHs2zP9q9BsnCIIgDEmGnBgDpCd2oT611vDi7WB3wkV/BKV6pnGCIAjCkGPIuanBuKo7XZ967cOmytan/iAlLQVBEISoMiQt48zELpTEXPk3GDHHrD0sCIIgCFFkSIpxRkIsZZ0J4GqogpKdpuylbUh+ZIIgCEIPMiSVJSMxhtKaRrTWkR1QtAHQzQU+BEEQBCGKDEkxTk+IwePTVNVHWJ/66DrzmDe9x9okCIIgDF2GpBhnJnYy1/joOkgZCQmZPdgqQRAEYagyJMXYqsIVca7x0bUwXAp8CIIgCD3D0BRjfxWuiIK46sqgfL9U2xIEQRB6jCEpxs0rN0VgGRetN48ixoIgCEIPMSTFOC2hE4tFWMFbudN7rkGCIAjCkGZIVuBy2m3EOe1UNzS1vZPWUHEQ9iyD9DGyTrEgCILQYwxJMQZIjnO0ndqkNTx+Bez6n3k+58bea5ggCIIw5BiyYpzkclLVlmW8/wMjxPNugRnXQPak3m2cIAiCMKQYsmKc7HJQ3dCGZbzqbxCfCWfdDc64Xm2XIAiCMPQYkgFc0I5lXLIbdrwGc74kQiwIgiD0CkNWjJPjnOEt44/+btYslnliQRAEoZcYsmKc5HJQVd/CMvZ6YONTMOWzkJjdNw0TBEEQhhxDVoyTXcYyDlm5qWgDuKvMUomCIAiC0EtEJMZKqfOUUjuUUruVUneFeT1FKfWSUmqDUmqLUuqG6Dc1uiTHOWj0+nB7fM0b979nHkef3jeNEgRBEIYkHYqxUsoO/BU4H5gEXKWUapnrcyuwVWs9DVgM/FYpFRPltkaVJJcTIDSIa9/7kDURErP6qFWCIAjCUCQSy3gusFtrvVdr3QgsBS5psY8GkpRSCkgEyoAIFwvuG5JdJqsrUPjD2wQHV4lVLAiCIPQ6KmTONNwOSl0GnKe1vtH//Bpgntb6tqB9koAXgYlAEnCl1vqVMOe6GbgZICcnZ9bSpUuj1Q9qampITEyMeP8NxR5+/4mbH853MSbVTnLldmauu5PNk++kJGtB1NrVFTrbl/6M9KV/In3pn0hf+ifR7MuSJUs+0VrPbvWC1rrdP+By4F9Bz68B/txin8uA3wMKGAvsA5LbO++sWbN0NFm2bFmn9v94f6kedefLevmOE2bDu/dq/eNkrWtKotqurtDZvvRnpC/9E+lL/0T60j+JZl+Aj3UYTYzETX0YyA96PgI42mKfG4Bn/e+12y/GEyMeKvQB1pxxYLGI/e9D9mRIyOjDVgmCIAhDkUjEeA0wTilV4A/K+hzGJR3MQeBMAKVUDjAB2BvNhkabZCuAq94DnkY4+BGMPq2PWyUIgiAMRTqsTa219iilbgPeAOzAA1rrLUqpW/yv3wfcAzyklNqEcVXfqbUu6cF2d5skfwBXdUOTyS/21MOovp0rFgRBEIYmES0UobV+FXi1xbb7gv4/CgyoShnxMXbsNmVSmw6uNBtFjAVBEIQ+YMiu2qSUIslaualsJaSPkRKYgiAIQp8wZMthgr8kZp3bWMYjT+nr5giCIAhDlCEtxkkuBwnVe6G+HEaJGAuCIAh9w5AW42SXk/yaDeaJWMaCIAhCHzGkxTjJ5WBs/SZIyIb0wr5ujiAIgjBEGdJinBznZHLTZuOiVqqvmyMIgiAMUYa0GA+zVzKMEhgxt6+bIgiCIAxhhrQYj2naA4B32LQ+bokgCIIwlBnSYjzSvQuAmrTJfdwSQRAEYSgzpMU4p247e33DqNKuvm6KIAiCMIQZ0mKcUbWNzbrAlMQUBEEQhD5i6IpxbSlxdUfZ7BttSmIKgiAIQh8xdMW4aD0Am3QhVfViGQuCIAh9xxAWY1N5a4tvlFjGgiAIQp8ypMXYmzKaKhJlzlgQBEHoU4awGK9H5Zn84qp6sYwFQRCEvmNoinFtCZTvxzZ8BomxDirqG/u6RYIgCMIQZmiK8b73zOPo00lPiKGsVsRYEARB6DuGrhjHJkPudBFjQRAEoc8ZomL8Low6FewOMhJiKK0RMRYEQRD6jqEnxhWHoGwvFC4CEMtYEARB6HOGnhhb88UFCwG/GNc1orXuw0YJgiAIQ5mhKcbxmZA9CTBi3OjxUdvo7eOGCYIgCEOVoSXGWpv54oKFoBRgxBigTOaNBUEQhD5iaIlxxUGoLoLRpwY2ZSQaMS6tdfdVqwRBEIQhztASY389avJmBDalJ8QCSBCXIAiC0GcMPTFWdsieHNiUkWBZxiLGgiAIQt8wtMT42EbIPgmcrsCmwJyxiLEgCILQRwwtMS7aAMOmhmyKj7ET67BRLmIsCIIg9BFDR4yrj0HNccidFrJZKUV6Qoy4qQVBEIQ+Y+iIsRW81UKMQapwCYIgCH3LEBLjjYCCYVNavSSWsSAIgtCXDCExXg8ZYyA2qdVLGQkxlEmesSAIgtBHDCEx3hjWRQ0m11gqcAmCIAh9xdAQ49pSqDzYKpLaIiMxhtpGLw1NUp9aEARB6H2GhhjvW24eR50a9mUr17i8TqxjQRAEofcZGmK85x1wpcDwmWFftsS4VFzVgiAIQh8w+MVYa9izDAoXg80edhepwiUIgiD0JYNfjIt3QNURGHNGm7uIGAuCIAh9yeAX4z3vmMd2xFgWixAEQRD6kiEgxm9DxjhIHdnmLskuJ3abklxjQRAEoU8Y3GLc1AD7P4SxZ7a7m82myEiIkQAuQRAEoU8Y3GJ8bCN46mH06R3umpUUy4lqsYwFQRCE3mfwizG0WXkrmOykWIpFjAVBEIQ+YHCLcdFGiEuDlBEd7mos44ZeaJQgCIIghBKRGCulzlNK7VBK7VZK3dXGPouVUuuVUluUUu9Gt5ld5NhGUwJTqQ53zUqKpaSmEZ9P90LDBEEQBKGZDsVYKWUH/gqcD0wCrlJKTWqxTyrwN+BirfVk4PLoN7WTeJvg+FYYdnJEu2cnufD6tJTEFARBEHqdSCzjucBurfVerXUjsBS4pMU+nwee1VofBNBan4huM7tAyU7wuiOaLwZjGQMSxCUIgiD0OpGI8XDgUNDzw/5twYwH0pRSy5VSnyilro1WA7vMsU3msY2VmlpiibEEcQmCIAi9jSOCfcJNuLacWHUAs4AzgThgpVJqldZ6Z8iJlLoZuBkgJyeH5cuXd7rBbVFTUxNyvjG7XyHPFsP7W47A1mMdHn+izgfA+2vW4zvqjFq7ukLLvgxkpC/9E+lL/0T60j/pjb5EIsaHgfyg5yOAo2H2KdFa1wK1Sqn3gGlAiBhrre8H7geYPXu2Xrx4cReb3Zrly5cTcr79/we5U1m8pP2CHxa1bg/fee8N0ocXsnjxmKi1qyu06ssARvrSP5G+9E+kL/2T3uhLJG7qNcA4pVSBUioG+BzwYot9XgBOV0o5lFLxwDxgW3Sb2gm09kdSRxa8BZAQ6yAhxi5uakEQBKHX6dAy1lp7lFK3AW8AduABrfUWpdQt/tfv01pvU0q9DmwEfMC/tNabe7Lh7VJxEBoqITey+WKL7GQXxTUixoIgCELvEombGq31q8CrLbbd1+L5vcC90WtaNyjebh6zJ3fqsKzEWE5USeEPQRAEoXcZnBW4ineYx8xxnTosKylWLGNBEASh1xmcYlyyExKyID69U4dlSX1qQRAEoQ8YvGKcOaHTh2UlxVLd4KGhydsDjRIEQRCE8Aw+MdbauKmzxnf6UCn8IQiCIPQFg0+Ma0ugoQIyOy/G2YGSmBLEJQiCIPQeEUVTDyhKrOAtsYwFQRC6QlNTE4cPH6ahoeuGSUpKCtu29V25iWjSlb64XC5GjBiB0xlZRcfBJ8ZWJHVW1+aMQcRYEIShzeHDh0lKSmL06NGoCJagDUd1dTVJSUlRblnf0Nm+aK0pLS3l8OHDFBQURHTM4HNTl+wCZwIkt1zLomMyEmKxKVm5SRCEoU1DQwMZGRldFuKhjlKKjIyMTnkWBqEY7zD5xV34EtltiqykWIoqZc5YEIShjQhx9+js5zf4xLh4Z5dc1BajMhI4UFobxQYJgiAIQvsMLjF210DV4U5X3gqmMDOBvcUixoIgCH1JYmJiXzehVxlcYly62zx2IZLaojArgdLaRirrmqLUKEEQBEFon8ElxtXHzGPyiC6foiDTjMb2iataEAShz9Fac8cddzBlyhROPvlknnzySQCKiopYuHAh06dPZ8qUKbz//vt4vV6uv/76wL6///3v+7j1kTO4UptqT5jHxKwun6IgMwGAfSU1TM9PjUKjBEEQBi4/eWkLW49Wdfo4r9eL3W4P+9qkvGR+fFFkq+o9++yzrF+/ng0bNlBSUsKcOXNYuHAhjz/+OOeeey7f//738Xq91NXVsX79eo4cOcLmzWYF34qKik63u68YXJZxjV+ME7K7fIqR6fHYFOyTeWNBEIQ+54MPPuCqq67CbreTk5PDokWLWLNmDXPmzOHBBx/k7rvvZtOmTSQlJVFYWMjevXv52te+xuuvv05ycnJfNz9iBpllXAyxyeB0dfkUMQ4b+enx7C0RMRYEQYjUgm1JtIp+aK3Dbl+4cCHvvfcer7zyCtdccw133HEH1157LRs2bOCNN97gr3/9K0899RQPPPBAt9vQGww+yzih6y5qiwKJqBYEQegXLFy4kCeffBKv10txcTHvvfcec+fO5cCBA2RnZ3PTTTfxpS99ibVr11JSUoLP5+Ozn/0s99xzD2vXru3r5kfM4LOME7vuorYoyEzgo71laK1ZsaeUtPgYJuUNHHeHIAjCYOHSSy9l5cqVTJs2DaUUv/nNbxg2bBgPP/ww9957L06nk8TERB555BGOHDnCDTfcgM/nA+CXv/xlH7c+cgaXGNec6FbBD4vCrETqm7xsOFzJFx9aw6LxWdx/7ewoNFAQBEGIhJqaGsBUsrr33nu59957Q16/7rrruO6661odN5Cs4WAGl5u69kRULONCf0T1nU9vxO3xUSE5x4IgCEIPMmjEWPk8UF/erUhqCyu9acfxagAq60WMBUEQhJ5j0Iixs6nS/NONHGOLYckuXE4b8TF2zpiYLWIsCIIg9CiDZs44prHC/BMFy9hmU3xh3igKshLYV1zLyj2l3T6nIAiCILTFoLGMA2IchTljgB98ahJXzxtFSpyT+iYvjR5fVM4rCIIgCC0ZfGIchTzjYJLjnIDMGwuCIAg9x6ARY2dThfknSpaxRYqIsSAIgtDDDBoxjmmsAGcCxCRE9byWGFc1iBgLgiAMNjweT183ARhsYhyFSOqWiJtaEAShb/j0pz/NrFmzmDx5Mvfffz8Ar7/+OjNnzmTatGmceeaZgCkQcsMNN3DyySczdepUnnnmGQASExMD53r66ae5/vrrAbj++uv55je/yZIlS7jzzjtZvXo1CxYsYMaMGSxYsIAdO3YAZuWpb3/728yfP5+pU6fy5z//mbfffptLL700cN4333yTz3zmM93u6+CKpu4BMQ5YxiLGgiAMRV67C45t6vRhcV4P2NuQmGEnw/m/6vAcDzzwAOnp6dTX1zNnzhwuueQSbrrpJt577z0KCgooKysD4J577iElJYVNm0w7y8vLOzz3zp07eeutt7Db7VRVVfHee+/hcDh46623+N73vsczzzzD/fffz759+/jggw9IS0ujrKyMtLQ0br31VoqLi8nKyuLBBx/khhtuiPyDaYNBI8bOpkpImBL188qcsSAIQt/wpz/9ieeeew6AQ4cOcf/997Nw4UIKCgoASE9PB+Ctt95i6dKlgePS0tI6PPfll18eWG+5srKS6667jl27dqGUoqmpKXDeW265BYfDEfJ+11xzDY8++ig33HADK1eu5JFHHul2XweNGPe0ZVwpJTEFQRiKRGDBhqO+m0soLl++nLfeeouVK1cSHx/P4sWLmTZtWsCFHIzWGqVUq+3B2xoaGkJeS0hoji/64Q9/yJIlS3juuefYv38/ixcvbve8N9xwAxdddBEul4vLL788INbdYXDMGXs9OJuqolLwoyUxDhtxTrtYxoIgCL1IZWUlaWlpxMfHs337dlatWoXb7ebdd99l3759AAE39TnnnMNf/vKXwLGWmzonJ4dt27bh8/kCFnZb7zV8+HAAHnroocD2c845h/vuuy8Q5GW9X15eHnl5efzsZz8LzEN3l8EhxnWlKHTU05osUuKcIsaCIAi9yHnnnYfH42Hq1Kn88Ic/ZP78+WRlZXH//ffzmc98hmnTpnHllVcC8IMf/IDy8nKmTJnCtGnTWLZsGQC/+tWv+NSnPsUZZ5xBbm5um+/1ne98h+9+97uceuqpeL3ewPYbb7yRkSNHcsoppzBt2jQef/zxwGtXX301+fn5TJo0KSr9HRxu6toT5jHKBT8sRIwFQRB6l9jYWF577bWwr51//vkhzxMTE3n44Ydb7XfZZZdx2WWXtdoebP0CnHLKKezcuTPw/J577gHA4XDwu9/9jp/85CetXO4ffPABN910U0R9iYTBIcY1fjEWy1gQBEHoYWbNmkVCQgK//e1vo3bOwSHGoxawes6fmZs7rUdOnxzn4HB5fY+cWxAEQRhYfPLJJ1E/5+CYM3bGUZcwMurVtyyS45ySZywIwpBCa93XTRjQdPbzGxxi3MOIm1oQhKGEy+WitLRUBLmLaK0pLS3F5XJFfMzgcFP3MClxTmobvTR5fTjtMn4RBGFwM2LECA4fPkxxcXGXz9HQ0NApMerPdKUvLpeLESNGRLy/iHEEWIU/qhs8pCfE9HFrBEEQehan0xmoctVVli9fzowZM6LUor6lN/oiZl4ESElMQRAEoScRMY4AEWNBEAShJxExjgARY0EQBKEnETGOABFjQRAEoScRMY4AEWNBEAShJ4lIjJVS5ymldiildiul7mpnvzlKKa9SqnUx0AFMsl+MpfCHIAiC0BN0KMZKKTvwV+B8YBJwlVKq1TIV/v1+DbwR7Ub2NS6nnRiHTSxjQRAEoUeIxDKeC+zWWu/VWjcCS4FLwuz3NeAZ4EQU29dvSIlzUlknYiwIgiBEn0jEeDhwKOj5Yf+2AEqp4cClwH3Ra1r/QkpiCoIgCD2F6qj2qFLqcuBcrfWN/ufXAHO11l8L2ue/wG+11quUUg8BL2utnw5zrpuBmwFycnJmLV26NGodqampITExMWrna8mvVtfj8cEP5sf12HtY9HRfehPpS/9E+tI/kb70T6LZlyVLlnyitZ7d6gWtdbt/wCnAG0HPvwt8t8U++4D9/r8ajKv60+2dd9asWTqaLFu2LKrna8l3/rtBz7rnfz36HhY93ZfeRPrSP5G+9E+kL/2TaPYF+FiH0cRIalOvAcYppQqAI8DngM+3EPRAEdMgy/j5TgwW+j0jM+IpqWmkxu0hMVZKeguCIAjRo8M5Y621B7gNEyW9DXhKa71FKXWLUuqWnm5gf2FURjwAB0vr+rglgiAIwmAjIhNPa/0q8GqLbWGDtbTW13e/Wf2PUekJABwsq2VSXnIft0YQBEEYTEgFrggZmW4s4wNiGQuCIAhRRsQ4QlLinaTEOTlQJmIsCIIgRBcR404wKiOeQyLGgiAIQpQRMe4EI9PjxU0tCIIgRB0R404wKiOeIxX1NHl9fd0UQRAEYRAhYtwJRqUn4PVpjlbU93VTBEEQhEGEiHEnGJkhEdWCIAhC9BEx7gRW4Q+JqBYEQRCiiYhxJ8hJchHjsHGwtLavmyIIgiAMIkSMO4HNpiSiWhAEQYg6Isad5KTcZNYerMDna3/pSUEQBEGIFBHjTrJofBYlNW62Havq66YIgiAIgwQR406ycHwmAMt3FPdxSwRBEITBgohxJ8lOcjE5L5l3d4oYC4IgCNFBxLgLLBqfxdoD5VQ1NPV1UwRBEIRBgIhxF1g8IRuPT7Nid0lfN0UQBEEYBIgYd4EZI1NJinWIq1oQBEGICiLGXcBptzFrdBrrD1X2dVMEQRCEQYCIcRcZluyipMbd180QBEEQBgEixl0kMzGWstpGKf4hCIIgdBsR4y6SkRiD16epqJeIakEQBKF7iBh3kczEWICAq7q6oYnjVQ192SRBEARhgCJi3EUyEmOAZjH+xavbueqfq/qySYIgCMIARcS4i2QFLONGAPYU17C3uJaGJm9fNksQBEEYgIgYd5EMS4yrjWVcVFkPwMEyWV5REARB6Bwixl0kNc6J3aYorXXj82mOVZr54n0ltX3cMkEQBGGgIWLcRWw2RXpCDCXVjZTUuGnymhSn/SLGgiAIQicRMe4GmYmxlNa6OVrZHEW9v1TEWBAEQegcIsbdIDMxhuKaRooqzHxxYqxD3NSCIAhCpxEx7gaZibGU1jRbxnML0jlQKgFcgiAIQucQMe4GmYkxlNS4Kaqox+W0MT0/laLKBuobJb1JEARBiBwR426QkRhLQ5OPXSdqyEuJY3RmAgAHysRVLQiCIESOiHE3sEpibjpSSW6qi4IMI8YSUS0IgiB0BhHjbmCVxCyrbfRbxvEA7CuReWNBEAQhckSMu4FVEhMgNzWOJJeTzMQYsYwFQRCETiFi3A0yg8Q4L8UFwKiMBPaFyTVed7CcHzy/SdY/FgRBEFohYtwN0hNiAv/npsYBMDojIaxl/NhHB3l01UF2HK/utfYJgiAIAwMR424Q47CREucEmi3jMdkJnKh2U93QFLLvmv1lAKzcU9q7jRQEQRD6PSLG3cQK4rIs4zFZiQDsLW62jo9VNgSKgazcK2IsCIIghCJi3E0yE2NJdjlIjHUAzWK8p7gmsM9qv1U8KTeZj/aW4pV5Y0EQBCEIEeNuMiEnicl5KYHnozLicdhUiBiv2VdGQoydL55WQFWDh21FVX3RVEEQBKGf4ujrBgx0fnzRJIINXafdxsiMePacaHZTr95XxqzR6Zw+LhMw88ZThqe0PFWH7D5RTWFmIjab6na7BUEQhP6DWMbdxGG3EeMI/RjHZCUGLOPy2kZ2HK9m7ug0cpJdFGYmdGne+EBpLWf//j3e3n4iKu0WBEEQ+g8ixj3AmKxE9pfW4vH6+PhAOQBzCzIAmD8mg9X7ymjy+jp1zr0ltWhtRFkQBEEYXIgY9wBjshJo8moOldezfMcJYh02po4wbumzTsqmxu3hf1uOd+qcR/1rJh+vaoh6ewVBEIS+RcS4BxiTbSKqNx+p5MX1R7ng5FxcTjsAi8Znk58ex8Mr9nfqnEfKjRifqHZHta2CIAhC3xORGCulzlNK7VBK7VZK3RXm9auVUhv9fyuUUtOi39SBw5hMI8Z/XbabareHK+fkB16z2xTXzh/N6v1lbD1axeYjldz94hYq65vaOh0QmWW8v6SWhiZZS1kQBGGg0aEYK6XswF+B84FJwFVKqUktdtsHLNJaTwXuAe6PdkMHEinxTjITY9l+rJrRGfHMK0gPef2K2fnEOe18//lNXH7fSh5asZ+bHvm4XSE9WmFEuC3L2O3xcsGf3ufP7+yKXkcEQRCEXiESy3gusFtrvVdr3QgsBS4J3kFrvUJrXe5/ugoYEd1mDjzGZpu1ja+cMxKlQlORUuKdfHrGcNYdrGD8sCR+eslkVu8r45tPrW9zIYkjfsv4RFV4MT5SXk9do7fTc9GCIAgteWL1Qf4iA/teRWndfjUopdRlwHla6xv9z68B5mmtb2tj/28DE639W7x2M3AzQE5OzqylS5d2s/nN1NTUkJiYGLXzdZdHtrpZfsjD7xbHkRrbesxT5dasLPKwJN9BjF3x8p5Gnt7VxJ1zXOTH1of0xac1N/6vDruCJh/cd1Y8LkeowG8s9vC7T4xQ37swjqz4/hEO0N+uS3eQvvRPpC/R59419Ryu0fxxSXyXz9Ff+hINotmXJUuWfKK1nt1yeyRFP8JVmAir4EqpJcCXgNPCva61vh+/C3v27Nl68eLFEbx9ZCxfvpxonq+7nDSzgf0ltcwrzGhzn4uD/p85v4nnfvomtYkjSIwtCulLUWU9vjfeYdaoNNbsL2fC9LkUZCaEnOvQyv3wyRYA6lILWbxgdPQ60w3623Vpi+3HqnhlYxHfPHt8K0+GxUDpSyRIX/on/aUvf962gsrScmbMPZWUeGeXztFf+hINeqMvkZhPh4H8oOcjgKMtd1JKTQX+BVyitR7yqyHkJLvaFeKWJLucTBuRwvu7S1q9ZgVvzRiZBoQP4jpYVkesw0ZBZgLvSGGQTvP4Rwf58zsm4E4YGvxn5X5OVEuqYDjqGk38yu5iWfK1t4hEjNcA45RSBUqpGOBzwIvBOyilRgLPAtdorXdGv5lDg9PGZrLpcAW1TaGOh8P+tKbp+alA+CCug2V15KfHc8bEbFbuLaWuUUSlM2w+UglAZV37Ue3C4KC42s0PX9jCM58c6eum9Evq/feP3SdqOthTiBYdirHW2gPcBrwBbAOe0lpvUUrdopS6xb/bj4AM4G9KqfVKqY97rMWDmNPGZeHTsL0sNKraiqQOiHFYy7iekX4xbvT4+HD3kHdORIzH62Orf/GOjlLMhMFBrd8DIkV0wlPvz+wQMe49IlooQmv9KvBqi233Bf1/I9AqYEvoHNPzU4mPsbOltKUY15MS5yQ3xUWsw9bKMtZac6isjnkF6cwZnU6Sy8GLG45y9qSc3mz+gGVPcS0NTaY8aZWI8ZCg1m/5FVXW93FL+icBN7WIca/RP0JuBQBiHDbmF2awpaS1GOelxqGUIifZ1Wo0X17XRI3bQ356PDEOG1fMzue1TUVDatS/v6Q2kP7VWSwXNUBVg4jxUMASm2NtpAoOdeoDc8Yixr2FiHE/49SxmRyv0xwurwtsO1JRz/BUFwA5ybGtRPZgmdl3ZLpJQ7j2lFF4teaxVQd6qdV9z7f+u4GvL13XpWM3BYmxuKmHBgExFsu4FY0eHx6fJtZh43B5vVT16yVEjPsZs0aZiOmtR6sC2yzLGCA7ydXKTW2J8aiMeP9jAmdOzOaxjw7i9gyNH9KxygbWHqyguguW7eYjlUwclgSIGA8V6vxzxsXVbjydXEFtsGPNF0/OS0ZrAsvBCj2LiHE/ozDL5A/vKTZLJVY3NFHV4GkW4+TYVlW4DvnFOD+tOUH/hlMLKK1t5KUNRb3R7D6noq4Rr0+zel9Zp47z+jRbi6qYV5CO3aZEjIcItX7L2KehuEZc1cFYLuqpI1IBmTfuLUSM+xnJLicpsYq9/tGoNQ8abBnXuD2BaFCAg6V1ZCXFEhdjD2xbMCaD7KRYVoTJW7Y4UlE/KAJY3B5v4Ob6QTv9Dce+khrqGr1MGZ5CsstBVf3ATwn75EA5d7+4pc3SqgIhqX/HKodObEUkWJ/NpNxkbAr2iBj3CiLG/ZDcBBVwDe04ZpLux/mXZcxJjgVCc40PlNUG5ostlFIUZCZwKGjuORitNV98cA2f+dsKymsbo96H3qQiKDd4RSdTujYfMdMBJ49IISXOOSgs49+/uZOHVuxn1T5Jb2uLWnfz9I2IcSjWfHpynJOR6fESxNVLiBj3Q4Yl2NhTXIvWms1HKolx2BjrF+PsJBPIFZxrfMifY9yS/PT4wHxyS7YVVbPjeDVFlQ1855mNdFSjvCfw+TT3v7eny1HQFuV1ZjAxdUQKO45Xd6qq0q4T1ThsirFZiYNCjA+V1QW8A0+uORT187+/q7hL8/L9jRDLeAhlHUSCFbAVH2NnTFYie/1TZkLPImLcD8lNsFFZ30RZbSObj1RxUm4yTru5VJZlbN1A3B4vRyvryU+La3WekenxHK9yh42GfHHDUew2xa1LxvDm1uM8+tHBHuxReDYfreQXr27nivtWsr+k6z/4Mr9l/6mpuQCs3BO5RVhW20RqfAwOu43kKIqx16dZuvogxW0sedlTPPXxIWwKzp6Uw2ubj1FRFz2vR2VdE9c+sJpHV/X+dyXa1Lq9JMTYibHbxDJugWUZx8fYyU6OpXSAe84GCiLG/ZDcBLNQwe4TNWw+WsmUvOTAa/np8Tjtiu1+9/X2omq0hom5ya3OY1nLVjlNC601L204yunjMvnW2ROYOTKVR1d2nAZV1dDEtqLmKO8mry8QPBYJTV4f/3h3TyBAxHLBl9c1csU/VnbZQrbc1KeNzSIlzskHuyKfN66oayTVXwg/Oc4ZlTxjj9fH159cz13PbuL5db1XbtHj9fHfjw+zaHwWXz9rHI0eX1Tfv6yuEa3NPPtAp77JQ0Ksg5yUWLGMW2CJcVyMnZS4GCrrmvrEczbUEDHuh+QmmMuyfGcx1Q0epgxPCbzmcto5KTeZDYcqANhw2DxO85fKDCY/3VjLLQVz7cFyjlTUc/G0PGw2xZyCdPaV1HaY4vHtpzZwyV8+DOQ5/+ntXSz5v+URpz58cqCcX762nVc3mQjvnceriXHYeOrLp3Ci2s2rG7sW+W1ZxpmJMcwcmRqSN9wR5XWNpPnFOCXO2e0KXFpr/t+T63lpw1GUgqJetLre21XMsaoGrpyTz+S8FKaOSGHpmkNRu5FaVvaB0sgHYP2VWreX+Bg7uclxvXqNBgL1TcaFH+e0kxrvpNHrC6Q7CT2HiHE/JCNOEeOw8eJ6szjWlLyUkNenjUhl4+FKvD7N+kMVZCbGkpfianWefL9l3DKI68X1R4l12Dhn8jAAxmYl0uj1cai8bcv0o72l/G/rcRq9Ph5ZuZ8at4eHV+zH49P84a3IFiEvrTE3843+AcTO4zWMy05kyvAUkmId3bCMzXlT42MozErkQGldxAJUUWfc1GAi2Svru2cFHCit45WNRXx18RgKMhJ6tQrah7tLcTltnDHRlEG98ORcth+rpjxKi19U+AcqbcUhDCTqGj3ExzjISWld0S7a+Hx6QBXOqG80g/L4GAepcWagWiELqPQ4Isb9EJtSFGYmcKSiHqddMX5Y6KLW0/NTqXF72Ftcw8bDlUzPTwm7Bm9WYiwup42DQZZMjdvDc+uOcNakHBJjTWlyKzisrXxCn0/z81e3MSzZxZIJWTy66iAPfbiPqgYPiydk8fLGo2w/VhX22GBKa8386Ua/5brzeDUTckyxjeFpca3c6ZFSVttEYqyDGIeN0ZkJ1Dd5OR5hmcOKuqYQy7jJq7tlBVg5q/MLM8hJdvWqC/REtZthyS5iHOZnnetPhyuJUh6tNegpqmwYUOISjlq3l4RYO8OSYzlW2dCjbti/v7uHM3/7Lt4BkmpmBbfFxdgDUzgixj2PiHE/xSr+MT4niViHPeQ1yyX9/q4S9hTXMM2fnN8SpRT5aaER1Y+tOkBVg4ebTy8MbBvTgRi/vKmIjYcruePcCdx2xlgq65v47Zs7mTs6nT9cOZ3EGAe/f7PjlTMty3jr0SpKa9wUVTYw3l/5anhqXLcsY+umUZBhPrd9EQaEldc1BizjFL8V0J0grhJ/wFZmYiy5Ka5eDQ46UdVAVlJs4HlmYkxIm7pL8A25M7EC/RHLMh6WEofb4+tRsdl1vJojFfWs908t9XfqgwK4UuLMd6iiXoK4ehoR437KmCwjkC1d1ACFmQkkxTp49KMDaB1+vthiZHp8wP3c0OTlXx/s49SxGSHHJLuc5CTHtinGL204yoi0OC6dMZyZI9OYnp+K1nDzwkJS42O48fRC3thyvMPAKWtu1+3x8bJ/ftiyjEekxYXU4+4MZXWNpPkFdXSmcc3vL+1YjOsbvbg9voCQW2LcncIflhWamRQTcIH2VvGN4mp3IPUNzIAAoKQb0bCNnuY4gmDBGujzxrWNlmVsPq+e9GBY0cjv7izusfeIJnVNXpx2hdNuC/w2ZJ3vnkfEuJ9iWcZThreOkrbZFFPzUwL5f1NHtBZsi/z0eA6VmTnUZ9YeprjazVcXj22139jsRHafqG61XWvN2gPlzCvIwGZTKKX4wYUnce0pozhjYjYAX15USGFWAnc+s7HdHNTSWjfx/iph//3E5MAGLOO0OKobPK2imd0eb4diVl7XRFqCEeO8lDhiHLaILGMrP9kS8uQ447bvjmVcXNOIUpAeH8OwZBcen+611JDiancLy9gvxl20jB//6CBT7n6D5TtOAOZzcdjMdMiBTlrGL288yuubu1+a9VBZHX9dtrvbA5w6t2UZ+8W4Bz0Y1iD0Xf/n2N+pb/TicprfacBNPcDz7wcCIsb9lLkFGYzPSWTh+Kywr0/3W7ajM+IDbtZw5KfHU+P2UFzj5h/v7mXaiBQWjMlotd/YrMRAoZFg9pfWUVrbyOzRaYFts0en89NLpmDz35hdTjv/d/k0iirr+cWr29psS2lNI5PzkkmJc7L5SBWJsY5A4NnwVGPRHgmaN/b6NAt/s4wHPtzX5jkBymubI6JtNsWo9PiIxNiy9NJaWMbdclPXuEnz5y3n+K2u3gjiqm/0Uu32hIhxapwTu00F5uojRWvN3S9u4XvPbaLR42PXceMxqahrJDfVRVKsg4MReB6C+fPbu/nGkxu6/Vm8vLGIe9/Ywbu7umdl1jaaPOOAGPfgNSqrNQO0jUcqKR0AdbDrG72BQXOq5aYWy7jHETHupwxPjeN/31jEKP8caEuseeL2XNTQnGv8+zd3cbCsjtvPHBc22GtsdiI1bk+rm9LH+83CC9ZqUm0xc2QaN51eyBOrD4W1sMHclDISYgOW/PicxEBbhvuLlgSL8b6SGo5XuTt075UHuakBRmcmRFRExApIsubFoiHGpTXuwFxtb1hdFlZxkewgMbbZFOkJMZRUm376fDqiWuTbiqp5aMV+rp43kliHLVDRrLyuibT4GEZmxHfaMi6ucVPf5OXeN3Z06riWWGLW3eVB6xu9xMc6yE6KxWFTPRYhrrXxjMwvyEBrk37W36lr8hIfY7xELqeNGIdN5ox7ARHjAcqMkWnE2G3MLUhvdz9LjJ9YfZBp+akB13JL2griWnuwnGSXg7FZieEOC+GLpxWgFLy66VjY10trG8lIjAkS46TAa8P9kb/B88Zbi4yorz9U0cot+eHuEnafqKbJ66O6wRMixgWZCRwoq4vIvQ2QltByzrg7lnFjwD0c6XzkzY98zD/f29vl9wQCghlsGYNxVVvz2K9vOcapv3qHTYfbz8O2AumunJNPdnJsQOgr6ptIiXMyOiOhU3PGTV4fZbWNJLscPLP2MJs7kQfeEsvl/872E12OMWj0+Gj0+oh32nHabRRkJvTYykS1jV4aPT4Wjs8iIyGG5Tt6V4zrGzue5ml9jIc4v5taKUVqnFPmjHsBEeMBSlZSLG9/axGfmzOy3f1GBJXJ/ObZ48NaxdB2etPH+8uZNSot4JJuj5xkF7NHpQWKegTj9WnK6xrJSIjh5OGpQKgYZybGEOuwhURUW2s6Vzd42Btk6ZbWuPniQ2v45avbA+6zdL+gAozOSKDR4+NoB1ZgyznjJFd03NSWGGcmxmBT7bupG5q8vLXtOG9vP97qtWOVDSE1yNvjRMAyDs03z0yMCQRwbT9WjU/DX5a1nxd+zP+5DUtxkZUYGzh3pT/yfGRGPIfL6yJO1bGi6G9dMpa0+Bj++HZkeelgvjc1QSuUldS4A1MbT6zuWlnOQLSwP7VvXE5ij4lxWU1zQZqF47M6VR2uuzR5fSy6dxn3vbenU8fVN3lDVoBLjXeKm7oXEDEewOSnx2PvQCQTYh0MS3Yxa1QaC8dltrlfVmIsyS5HyE2poq6RXSdqmD26fes7mPOnmEITe1tU5arwl1JMT4jhlDEZLJ6QxZknNVvpSimGp4WmN20rqiLJf8MMTgt57KODuD0+NhyuDAhqaoib2h9RXdK+5dRcLMSIsN2mSIp1tBLjd3cW882n1vPjFfUdzvmVVDeLscNuIysptt0KT3uLa/Hp1oOgIxX1XPCn97n8HytxezrO6bWs17CWsf81Kx3pjS3HOVLTdrW1osoGHDZFZkIs2UmuEMs4Ld7JqPR4mryaoxGmolnHF2YlsmBMBruOh5/GCMdDK/az+N5lAeEvrWlkUl4yZ0zM5sk1h7qU71zrz6NN8AvO2OwkDpTW9kjutDVfn5EYw9jsREprG3stR3v9oQpOVLtZvr1z1nhd0JwxmHnjaLmptxVVMfOeNznt1+/w+X+uiniw2Rc0eny9ugypiPEQ4MEb5vD3L8xs0yoGI4ZjsxNZs78sYImsO1gBmPngSDlviqnq9drmUFe15V7MSIwlJc7JQzfMbTUfPjw1tPDH1qKqQHGS9YfKAWNJPrJyPzF2GyU17oD1nJ4Q6qYG2NdBkFFFXRPxMfaQPO7kFiUxX91UxHUPrObVTUUcqPKx1v+ZhKO+0ayrnJnU3JZhKXHtWsa7/PPrJTWNgajbhiYvX/7Px9S6PRworYtoYYYT1Q3YbYqMhNBgvszEGEpq3GitOVRWx8RhScQ57by8t+2b67HKBnKSXdhsiqwkYxn7fJrK+iZS45yMzDCDnUjnWYNd6MNT4zhaGXm614ZDFZTUNAYGQSU1bjISYrnp9EJKahr56ctbIzpPMFZRi4BlnJ2IT0eem94ZrGuanhAbuDa9FV1vWeHrD1dENKCzqG/0BtzUAClRtIyfWH2QWreHSbnJrNhTypr95VE5L5gVxbozBdKSpWsOMvFHr0etaE5HiBgPAU7KTW7lvgzHNaeMYk9xLZf85QOWrj7I35fvwWFTgcjtSMhLjWPGyFRea5HGYrkqW4pFMCPS4gIBXMXVboqr3UzOS2ZafkpgYPDi+qOU1DRy+5kmPcsK7rKsW4CcJBdxTnuHQVzldU2Bcn8WLZdRfGvbcdITYlhx15mAqRrWFoEc44Rm69Sq8NQWweezrON7Xt7K5iNV/O3qmZw+LpM/vb2rw9WXiqtN4FjL6YTMxFjcHh+1jV4OldcxZXgKn583ko+KvG1aJUWVDeT6XcHZSbFU1jdRUutGa0iJjwkMoiKdNw622vNS42j0+CIWJCtf/Jg/X7vMH3cwrzCDWxaN4fGPDvJRUefywq21jC3LeFyOmaLZ1QOu6sAgNCEmMGC0XNedpaKuka88+klEQXgAK/aU4LApGj0+NnYQJxBMa8s4OquZNXp8vLjhKOdMHsZvLpsKRDeK/QfPb+a3/+tegGAw+0vqcIQZ4PYUIsZCgEtnjOA/X5pLRV0Tdz27iZ0nqrn9zHEh80eRcMGUXDYfqQoJsAlYCIntiXE8pbWN1Dd6A6tDTcpLZnp+KtuPmXWK//7uHiYOS+LG0wtx2BTv+cU42DK22RSjMuL5cHcJL2042qboVARV37JIjnMEcp211qzYXcophRmkJ8SQ7lLtzi0GF/ywGNZBScxdx2tIdhkLbdeJajxeHy+sP8pls0Zw5kk5fO+Ck6hqaOKvy3a3eQ4wc8YtXdTQnGt8tKKe41Vu8tPiOXNitnGNt7HAx7GqhkAkuHXO3f70ptQ4J7nJLpz2yCOQiwNVyWLI8wfqReLi1loHrNVjlQ1UNTTh8Wky/H361jnjmTkylQc3uwPfr0iw3NRWxHBBZgI2Bbs74T6PFGsQmp4QQ4b/u1/WxWUt39x6nNc2H+PNra3jC1pS6/aw7mAFl80aAcAaf1ZEJPTUnPHyHSeoqGviMzOGkxLnJNZhC8QnRIPiandUo+L3l9YyKiOhXY9iNBExFkJYMCaTt7+1iFduP41PfnA2t585rvPnGGvymINduoG5s4TWgmFhRVQfqahnqyXGuclMz0/D69Nc9veVHCqr44efmoTLaWfCsKSA5ZHWQlTPmJjNzuPVfO2JdVz34Jqw71de1xiIpLYItoz3ltRyrKoh0J+8RFsHlrEVrNPcx5wUF9UNnpDF7IPZdaKGBWMySYixs+t4DVuOVlHj9gTyy0/KTeZTU/N46uPDIdWwWnKiyh3W+2EJgDXnnp8eF6hZfbSi9SBBa5P+ZEWCZ/vXz7b6nZbgxGZTDEtxRWyhFde4/TdfO3mpLv97d3xsWW0j1Q3mcztW1RD0+Zo+Oe02fvipSTR4jYsyUuosyzjWCE6sw87ojIQesYzLat3EOmzEx9hJ93/3yzqZ922xwr9O94ZDHVu5q/eV4fFpLpqWx5isBNbs64QYN3qJczoCz1PjY6hv8nZ7rvvZtUfITIzh9HGZKKVMudgIa8h3RF2jh7pGL4fL66M2z7u/pJbR/imZ3kDEWGhFanwMk/NSOgwOa4vxOUm4nLbAMo/QbCGkxTvbOKo51/hweR3biqrIS3GRGh8TcJMfLKvj3suncupYE4hmpUjFOe2BikEW3zlvIlt/eh7XzB/FruMmBaolFfVNrSzjYDFesdvMuZ06xrzf8ERjGbcVRRywjBOD3dRt5xo3NHk5UFrL+GFJ/gpoNXy0z9xw5welrF0yLY/K+iY+3NN2JG5xjZusxLYtY8vNPzI9PuCCLgojiFX1HhqafM2WcaJ53OkXKisnOy8lLqyg3v7EOpa2iHIOrgwWPODqiOCSpscqGwLzxsEDuqkjUolzwEq/UEVCXZNVe7lZcMZmJ3ZZjA+V1bUZF1BaazIIlFKk+79rpV1wU2utWeG//puOVHS4/we7S4hx2Jg1Ko25Bel8fKA8ouh3rbW/bnfQnHEEKX/PrzvC+X98v80BY0VdI+9sP8HF04bjsBvZyUl2Rc0ytj5Tt8cXWKylI576+BDf/u+GsK95vD4OltUxOjN8nYeeQMRYiDpOu43JeSkhYlzmr5Jl/RDDYd2o739vL2v2lTEpz5QCzUqK5TMzhnPPp6dw6YwRgf2n+guftCXwLqed6fmpeHw6rPuqIsycsbWMIhhLZHhqHKP8o+O8RBtuj6/N/FYrajkjMdRNDeHnxvYU1+DTJoBobHYSu05U89HeMgozE8hObrZyTx+fSVKso831nr0+TWmNO2DFBmOJ4LqDJlAmPz0el9NOUgwcDTNAKKoyN8fcFHMtrHMG3NT+z3p4alwry7qyvokXNxzlrW2hZR+Lq5sHCilxTuJj7GGt8pbs80fD222KY1UNQUGAzZ+v3aaYmG5vd6DSkjq35aZuFpxxOYnsL6lt1/vQkjX7y7j8vhWc/ptlXHX/qrAWWVltY2BqJjnOgcOmInapa60DWQl7ims5XuVmeGocu0/UUOtuf578w90lzBmdhstpZ87odKobPOw41rEb3u3x4dO0clND2yUx6xu9/OLVbWwrqgp4tFqyam8pjV4fF07NDWwzlnF05oyDg6ysrIH/bTnG6y0CSYN5+uPDPLP2cNjP8khFPR6fDiw80xuIGAs9wrQRqWw+WtmcklLrDpnXDUduioubFxaytaiKo5UNgXxkgN9dOZ1r5o8K2d+yjNsrB2oVM9nTwurx+TQVLSp3gRGLhiYfpTVuVu4tZcGYjOYqYYnm57LzeHgLqqTGTZLLERKdndNOFS5r/nl8ThLjchI5XuVmxZ5S5hWGliuNddg5e1IOb2w5FlYsSmvd+HRo9S0L6zPfebyaGIctIIrpLltYN7OVhmVZxsaqg53+qG9r8JKXGsexqoYQa8sqJtJysFIcNFBQSpGXGt6qbsn+klrsNsXkvGSOVwVZxi3iDial2zlUVh/xSlK1jVYAV7NlPC47CY9Pc6ATZT5/+Pxm9pfW8enpeewtqWX5zta1p62qc2D6npYQE7EYv7uzmDN++y4vbjgasIpvOr0An4YtR9tesrSyvontx6o5xf89muNPTfz4QMeuaisHOziauqOSmA+t2B/IRV97IHx09BH/4KswyNLMSXFxvNIdleUrS4K8Ddb67b96fTt3/HdD2Hr5Hq+PjUcq0Jqwy7/u9wcnimUsDHim5afQ0OQL5LOW1jS2O18M5mb1vQtOYvX3zmLpzfO58fSCdvc3y0va2hV5a8GNPcWhN9nqBg8+HRqFDaaymVKw6N7lVNQ1BeaLoVmMd7VR7rOkprGVq9hyCYcTn53Hq3HYFAWZCYzzDxrqm7zML2yd133h1FyqGjxhLcATVeFzjIHAyjs+baLVrWjrdJeiKIx1ag0arHY77DYyEmICN+KUIDH2+nQgbQlgw+EKwJQ0tW6wWmtOVIW60PNS4zosyAIm1WhEWhwj0uIoqjRzxtYiHMFMyjDCEamr2rKMg60/q+hNpK7qRo+PPcU1fHbmCO69fBo5ybE8+OH+VvuZ731zezM6Icar/fO8P31pK29sOcbw1DgunJoHwEb/Zx2O7X7rdMpwM1gdkRZHZmJMh5XXgMBa3vHhLOMwgWeV9U3c9+4elkzIIjfFxdqD4cX4WGU9sQ5byO9tWLKLRn91tmBe3VQUUuglEoLz/w+W1lPX6GFfSS3Vbg9PrjnUav/tx6ppaDL3ps1HwoixP3DQqlnQG4gYCz2CNc+7t9J84a2UlEiIcdiYX5hBQqyj3f2cdhuXzRrBwvFtFzNJdjnJToplT4vI4ZbVtyxOG5fJS7edxrT8FBJjHZw2tnmhjjiHCTrZ1Y5lnNlCjONjHOSmuAIrbAWz83gNozMTiHHYGJfdXI1sXkHrhTxOG2dc1a+EcVU3pw6FT1+z2pSf1nxjSXepsAOEosoGbIqwqz8luRyBaYZwgVjWtES12xNYhrK20Ut9kzfkfMMjtIz3ldQyOiOBnGQXxysbKK1tXoQjmLxERWZibMSu6tpGLzF2U3PZYkxWIjYFW45GlgK0t6SGJq/mpNwknHYb18wfxfu7SloVNCmrbQwZLKZ3QozXHawgOymWslo3H+4u5dSxGSY9LMXFhnaEdWtQJgKYQW5hVmLYZUV3HKsO8SjUWZZxmDnjcG7qp9YcorK+iW+fO4GZI9MCsQktOVblJjfFFRKZnBtmkY49xTV89bG1PNTB4jAtsdzUafFODpXXsa2oGq1N+tqDH+5vFTNiBTTGOGxhr/m+kloSYuxh4zB6ChFjoUcYmR5ParwzIMalLW5K0eLnl57MzQvHtLvPmKzEVmJs3VhaWsZgLIpHvzSPdT86u5W1OS4nqR3L2B2S1mTRVnDQruPVAYt4eFocLqeN0RnxARdxMLEOOwvHZ7Fqb2vrL9wiEcFYlll+enNp1AyXotrtaeXCO1ZZT1ZSLM4gwbPmr4M/q+ZArOYb6cbDlYGKaZarMFxlsOGpLkpq2q9EpbVmf2ktBZkJDEt2Udvo5UBpXdicT6UUC8ZksGJPaUQuz7pGD/GxoQF/cTF25hVk8NqmYxGdw5p/neBfAvSquSOJcdhCVhir9w9EgtP5InVTe32ajYcrOG/KMK49ZTRAUOBiKpvasYy3Hq0iMzE2JLq+ICOhVVETrTVffGgNP3phc0ibITS4rb01jbcdq2JYsovJeSnMGJnKkYr6sKmExyrrW32vc8IEN1opjZ1d+7mkppGkWAdjsxM5VFYXGJDcef5EjlTUtyrRu+5gBRkJMcwrSA/r8u/ttCYQMRZ6CKUU00aksq/SF1KXui+wIpWDb7LhymgGo5QKESSLcf5zhQvWCV4kouX77ykOPaa42s3+0jpO9s97222KC07O5fLZ+W32Y1xOIkcq6luJWFuLRFhkJoWxjONM31qW6iyqbGBYSlzINss6sOYOgaD0KGPhHq9q4FhVA2dPzgEIVFILJ8ZWrnF7ZUKLq93UNXpDBidbjla16V1ZMCaD4mp3q+mIcNS6vSHzxRYX++d+25uPtdh+rBqnXVGYaQZTGYmxXDUnnydWH+I1/42/OZ0v1E0dScGTXSeqqW30MmNkKnecO4EfXHgS50421e2m5qewv7SuzcUbthZVBaxii4KsBEpqGkPWC99XUhuSRghB1cmCLOPEWAd2mwpbEvNQWV2gItsMf6W+cK5qU0gm9HtlPQ+2jK1BztqDFZ0qNGItQpOfZtZv33q0ktR4J1+YN4oxWQn84a1dIX1ff6icGSNTmZyXws7j1a1iMfaX1AYq+fUWIsZCjzEtP5XD1T6OVtSjNYFiDb3NmKwEqhs8ISkPFXUdp1qFY3xOIg1NPq7+10dc+Y+VHPQHejR6fFTWN7UpxnWN3pB50pV+C9dKmwL43RXTuXXJ2DbfuzArEa1p5W48XuUm2eVold5lYYlpfnqzGGe4zIi/pbv4WGUDucmhFowVfBVsGSfGOkh2OQLHWy7qC0820bKH27GMLTEOXi7TYn9JLS9vPBpYGGS03zIGa6oj/HfIGtSEC8ZpScvUHYvzpwzDaVe8sP5Ih+fYXlTFmKzEEFf3dy84iZkjU/nGU+vZeLgipBSmRXpCDJX1TWFT7YJZ73f3Ts9PIyHWwY2nFwaur7V86vow1rG1/vSk3FAxHu2PCg6uSvehf479eJU78Huw5oyDv0vWyk3hArgOlNYxyv+9mjI8mRi7rZWr2ufTHA8qJGNhLaQSbBlbgxyvTwdSCyPBqgk/Ij2eoqoG1h+qZHJeMjab4heXnsyhsjq+9vg6vP6yrnuKa5men8rkvGSavDqkfkCT18fh8vpenS8GEWOhB1kwJgMNXPGPlQA94qaOhOaI6uYbUXmtf/nEdiKxw7FgTCYThyVR1+hh4+FK7nnF1Ea2rNNwlps1HxxcvWvlnhKSXI5AkE1E/bCC0U6EivGBIOskHJZlNjI9dM4YWhf+OFbZ+qYZsIxbfFbBUdEbD1ditylOHZtJYqwjyDI25w92mQ5vpwrXr1/fzm2Pr+P2J9YBpjpWcHsy2/gOWXO+O1uk7zR6fPxt+e4Qd3ydfy3jlqTGx7BwXBYvbyzqsHDEjmPVARe1hctp5x/XzCYjIZavPrY2YPmnt7CMoe3IZIt1BytIjXeGLToxY2QqLqeNd7a1rsS1p7iGRq+Pk3JD22YFMga7qj8MWkHKskib3dShg5WUeGerOeP6Ri8nqt2B1L9Yh53Jw5NbWcaltY00eXVgjtjCYbeRneQKEeOdx6s5Y2I2SS5Hm67qVzYWtXK5l9a6/ZZxHFobd7c1IJlXmMFPLpnMuzuL+f5zmwKBfjNGpgV+f1uDvCFHyk1aU1tryfcUIsZCjzG/MIPbZ8QGioe0/DH2FmP8azEHzxtX1DehlFkYojPkp8fz+tcX8sJtp3HbGWN5c+txPthVwo9f2IK9jTre4ZanXLGnlPmFGZ0qrGK5zVquiHXAP7/VFjNGpjEqIz7E7ZYaq7ApQtKbatweqt2eVmIcsIxbfFbDU+MCc8YbDlcwIScJl9POiLTmBT+Ka9w4bCrk2JxkF0q1LvyhtWb1vjLG5yRS3eAh1mFjeGpcYG4R2vauuJx2RmcmsKNFANVb247zm9d3hAS+1TV6iG/Di3Dx9DyKKhtCykc+88lhPglKC6qsa+JoZQMThyW3Oj4rKZZff3Yqh8vrAyVMM0ICuKwqXO27qtcfqmB6fmrYOcv4GAeLx2fz2uZjrQYNlqhMbuGmHpkej1IEAgm9Ps3KvaWc7l/Jzfrc6toQ43BrGlu5+8Eel5kj09h4uDLE7WuJ7bDk1r//nKBc47pGDwfL6piUm8JpYzN5d2dxq/n74mo3tz2xlj++tTNkuzVFFDzgnJzXPNC9et4ovryokKVrDvHVxz5BKZMaOSo9nsRYB5uPVrL2YDkPfriPD/wWubiphUHFzBwHb31zEY/fOI9ZoyJf/SmaDEt2ER9jDxHj/SW15CS5ulxlDOBLpxUwPDWOGx9Zw9vbT3D3RZNCbgAW6QkxZCTEBMT4cHkdB0rrWDCmddR0e8THOMhLcYX0o8nr40h5fbtl+04bl8m7dywJiU632xQ5ya4Qy9iqhtRy0NRsGYeKsWUZNzR5WX+wgmn+gYgRY3OjPlFl3IfBC1jEOGxkJ8W2sox3n6ihtLaRG08r5I2vL+Txm+bjsNtwOe2B6YT2IvIn5CS1ygF/21+AJHgeuNbtDZTCbMlZJ+WQEGPnV69vp77Ry/PrjvCt/27ghgfXBKKOLeGa2MIytjhtXCanjs0ILM4QGsBl+lFa62bHsWp++tLWVisqVTc0sfNENTPy2/69nH/yME5Uu/mkhRW6tagKl9NGgX8u28LltJOXEheY4th6tIrK+iY+O3MEyS4H2/2WsVWdrGU9+tT41ssoWjnZwQPBafmpuD2+kCDHosD3KnTOGCA3udky3nm8Bq1NUNyi8VkUVTa0Cnx8a9txtCZktSeP12diUhJjQwYGLefNv3v+STz71QXMHJnGovFZJLlMadeTcpN45pPDfOZvK/jJS1v5wfMmoG20WMbCYMPltLNgbGavRiYGY7MpCrMSQoJ7Pt5fxqzR3RscuJx27jp/Ig1NPq49ZRTX+KNewzEmKKLaqjFsRcd2hjHZiYH5VDCuXo9PMyq98zeO3Bb1pVfuNdZfS/drczR1azd1ZX0T//34ENVuDxdNM/PFI9LiOezPNS6uCb+ARV5qXCDi2mKVP692XmE6IzPiQwZvlnXcXq76+Jwk9getS+z1aZbtMGK8OSh9xcwZh0+bS4h18NsrprH+UAXXPbiau57dyLT8VLSG25euo8nrY4d/XnpibngxBvjOuRMBcNpVIMI8uP1ltY08sfogD3y4j1+8si3k2HUHTTGK6SNT2zz/mSflEOOwtYoS3lZUxYRhyWEHmYVZzRHVVhrYgrEZTByWHHDvN4Qp+gFmIHaiKrRAh2UZjwoSwJP9bt8tQbm7luUbLktgWJBlHPhchyUFarO/uyPUVf3GFlNR60hFc5GX8romtDZz0Dn+RUxiHbaQAiMWM0em8fRXFvDQDXMD2+YWpOP2+Lh5YSFvfXMhd543kduWjA3UQO8tRIyFIcH47CS2Hq3C59McqajnaGUDc6JgqV80LY83vr6QH180ud39xgVFdK/YXUJmYmwgrakzFGYmsCcoMtxaxnBUFwra57bI931x/RHGZScyISdUZEamx3P9gtGcOTE7ZLuVa/ynd3ZTmJUQqPg0Ii2OGreHiromDpbWhRXjOaPT+WhfWUiq1kd7SxmW7ApxNVo0ryLVjmU8LAmtm6cD1h8qp6y2kbwUF9uKqvD4g6ZqG9u2jAHOm5LLPZdMYfW+MlLjYvjXtbP5xWdOZt3BCm5+5GP+t/U4yS5HWLerxbT8VC6altcqPSawjGJtIx8fKMNhUzy88gAvbTga2OehFftJi3cyp53BYmKsg0Xjs3htU7Or2ufTJpI6t7X7HIzbdV9xLVprPthVwvicRLKTXEwYlsSO49X+utStU5vAiNiJanfIQPBAaR1JLkeIx8Ry+24KWle4qLIBpz38UoQ5yWYhlVq3hx3HanA5bYxMjycvNY7xOYkh88bVDU2s2F3Kaf5BrFUUJbgmvN2mGJEWz8Tc5HZL7wZz+5njWP39s/jeBScxNjuJrywew7fPndDrxoOIsTAkWDg+i5IaN+sPV/Cxfz5w9ujWla66woRhSR26u8dmJ1JZ38TO4zW8v6skpMxmZyjMSqTWHzgD4V2FkZKX4qKosgGtzQBlzf5yLp6W16pddpvi7osntyoNaAViFVe7uXreqMBxI/wpVP/95BB7S2o566ScVu/9/84cx8j0eL793w3UuD1orfloXxnzCtPDfi7DIrSMoTkY6e1tJ7DbFDctLKShyRcQkjp325axxRfmj+L+a2bx+E3zyEqK5aJpeXznvAl8cqCc93eVMDE3ucPr99vLp/HsVxeEbLPc7YfL69lWVM2Npxcyc2Qqdz2zkW1FVeyv9PLO9hPceHphh2284ORhHKtq4O3txvr/7Zs7qKhr4pQ2pj9GZyRQ7fawcm8pH+4p4ZxJJlVq/LAkqhs8HK1soK7JQ4zD1ur7vMhvqS4PslQPltUxKiM+5HOw2RST8pJDPBHHKhvISXa1WmsbQgt/7DhexficpMB+i8ZnsXpfWSDdavmOYhq9Pm47Yywpcc6AGLdcK/2u8ydyxzkT2v3sgol12PssuDQYEWNhSLBkYjZOu+KNzcf4eH85CTH2Nuf8egIrovrqf31EjdvDDaeO7tJ5WgajHSitw+W0tVnwoz3yUuNwe0w5wpf9ltnF0/M6dTxArMPGZ2cOD2wf4V99649v7SIzMZbPBL1mkRDr4LeXT+NIRT13PbORHcerKa52h60+Fvxe7c0Zj86IJ8ZuC9TRfnvbCeaMTgtMB2w5WonPp6lr8pIQwRrd50weRmFWs/fiq4vHsvr7Z/Hnq2ZwdweeEDBz48mu0Hl2h7886TvbT+D1aeYXpvO3q2eR5HJyw4NreHJHI8kuB9ecMqqNszZz9qRhFGYmcMujn3Dr42v567I9XDV3JBcFLcYQTIE/ovquZzaREOPgS6eZcrPW72DnsWrqG71h077y0+MZk5UQYqkeLKsL68U4eXgK24qqAnXLiyrr2wzetKYfXt5QZCLUg7wyi8Zn0+j1Bbwnb2w5RkZCDHNGpzNndDqr97ewjP2/gXMnD+O0cZ2fAuprRIyFIUFKnJMFYzJ5fcsx1uwvY+aotIjdWNHAiqguq3Xzl8/PDBRI6Cwta23vL61jVHpCWKujI6wiIPe+sYPn1h1hWn5qpyzs7KRYXE4bF03LC5lPts5b2+jli6eNbjP/efbodL59zgRe3ljE5X836W/zwtTlBrh63kjuv8aIVls47DYKsxLYeaya3Sdq2HG8mrNOyqEwMwGX08bmI1U0eLxoTdjUpkhwOe1cNC2vVXBQZ0iPN8F8SsHMUWkMS3HxwPVzqG5oYluZj+tPLWgl4uFIjHXwwm2nct7kYbyysYiF47O455LJbVrs1hzqwbI6vnjqaNL81qDlUdjuF+OW88UWi8Zns2pvKfWNXrw+zeHyOkaGiVWYMjyZhiYfRbVGjI+FKSRjMT0/lZkjU/n9WzspqWkMiVeYPTqNOKedd3cUU1ztZtn2E5w9KQe7TTG/MJ19JbWcqGpoFuMOat/3d7r2jRSEAch5U4bx3Wc3AXD+lPDWQ0+RkxzLhSfnctakbM6e1NptGylWZPjegGVc2+WVZRZPyOL6BaN5ZOV+fBp+9KlJnTreYbfx9C0LWs1XJ8c5SIp1oDEpJe1x65KxTMpN5o6nN5AcFxc26AZMStM5/gpU7TFhWBKr9pby/5auI8nl4FNT83DYbZyUm8zmI5XUNBiXZySWcU+RnhDD3pJaJuQkBUR3Ul4y/7hmNve++DFf7ITXJMnl5C+fn8G1+0YxdURqh0uUOmyK+Bg7Xzq9MLA9Jc5JboqLFXtKiHPaW0VSWyyekMUDH+5j1b5SxmYl0uTVYWMVpvgzCg5UedFaU1TZwDmTw1vGcTF2nvnKAj7cXcpLG46GLLHocto5ZUwGy3cWc7zKTZNPc6O/3XP9631/tK+MkppGnHZFctzAlrOB3XpB6ARnT8rhe89tQmvaDY7pCZRS/PXqmd0+j82/ytOe4lp8/nWaF0/I6vjAMDjsNu6+eDKXzRrBc+uOcNnsER0f1IJwRUuUUnx21ggKMhMCiwy0x5KJ2bz9rcXUN3q7HTQzPieJF9Yf5XiVm39fNzsQ+DUlL4Xn1x3hF6+ayOXuWLbdxZqfbJnqd9q4TDyzXO0uCRoOpVSrZTfD4bDbuHreSCYPT2l1Xa6ck88f3toFGMs2HHML0nE5bby7o5gYv+iPCuOmLsxKJM5pZ3+Vj4q6JtweX0iueLj2nzYuM6xredH4LN7ZfoIDpXXced7EgIdpUm4ySbEOnlt3xJ86GNtn2RrRQsRYGDJkJsYyZ3Q6nxwobzdtpL8zYVgSb209zq4TNbg9PkZ2Mx9yyvCUTlUCi4S7L+54TjWYlDhnRMLdEZbI3rZkLGcGBY5NGZ7Mf1Yd4Pn1R/nW2eOZNSo6wXtdwZr3nt3LA0KAn1wyJez2r581npOHp3DXs5vCzgOD31ItzOD59UcCeeThKr/Z/UFcB6oqA1XIulrwxwocmzYihZuCllR12G3cfuY4fv7qNhJjHV3KJuhviBgLQ4rvnDuBrUVVHUaq9me+dFoBz607wveeMy739gp+DDUWjcvi8RvntbIUp/rrOV9w8jBuO6Pt+t+9gWUZz+7DAUE4zjwphw/vzMLXzqpV3z53Aj96YQtvbTuBy2kLW8gDTBDX44fL+dPbxtoOl2McCaMzE/jNZ6eyYGxGKxf8l04rYPnOE3y4uzRsTfiBxsC9IwlCF5g9Oj1qKU19xeS8FC6dMZxn15oFDXq7UlB/xmZTLAhTTOWk3GQe+eJc5haET53qTS6dMZzEWGcg6rw/EbzwRTgm56XwzFcWsONYNXWNnjZT+uYXpvPQiv18uKeE08Zmditz4Yo54Vcys9kUv718Ouf98b2Q5UEHKhGJsVLqPOCPgB34l9b6Vy1eV/7XLwDqgOu11muj3FZBEPx8+5wJvLKxCK+vdQF+ITxWVae+Zmx2EmOzey+tridoWaWtJedNyeXvZ8Vz3pmLe3TwMyzFxZvfWNRuEZeBQodirJSyA38FzgYOA2uUUi9qrbcG7XY+MM7/Nw/4u/9REIQeIC81jjvOncCmI5W9mqIlCJES51C94oVoax3vgUYklvFcYLfWei+AUmopcAkQLMaXAI9oU6NvlVIqVSmVq7Uuan06QRCiwY1B6SmCIAxsIhlSDwcOBT0/7N/W2X0EQRAEQQhDJJZxOD9Dy3C7SPZBKXUzcLP/aY1SakcE7x8pmUBJh3sNDKQv/RPpS/9E+tI/kb6EJ2wlnEjE+DAQHM42AjjahX3QWt8P3B/Be3YapdTHWuvZPXHu3kb60j+RvvRPpC/9E+lL54jETb0GGKeUKlBKxQCfA15ssc+LwLXKMB+olPliQRAEQYiMDi1jrbVHKXUb8AYmtekBrfUWpdQt/tfvA17FpDXtxqQ23dBzTRYEQRCEwUVEecZa61cxghu87b6g/zVwa3Sb1ml6xP3dR0hf+ifSl/6J9KV/In3pBEq3U/pMEARBEISeR6oFCIIgCEIfMyjEWCl1nlJqh1Jqt1Lqrr5uT2dQSuUrpZYppbYppbYopf6ff/vdSqkjSqn1/r8L+rqtkaCU2q+U2uRv88f+belKqTeVUrv8j72/XE0nUUpNCPrs1yulqpRSXx8o10Up9YBS6oRSanPQtjavg1Lqu/7fzw6l1Ll90+rwtNGXe5VS25VSG5VSzymlUv3bRyul6oOuz31tnrgPaKMvbX6nBuB1eTKoH/uVUuv92/v7dWnrPtx7vxmt9YD+wwSV7QEKgRhgAzCpr9vVifbnAjP9/ycBO4FJwN3At/u6fV3oz34gs8W23wB3+f+/C/h1X7ezk32yA8cw+YED4roAC4GZwOaOroP/+7YBiAUK/L8ne1/3oYO+nAM4/P//Oqgvo4P3629/bfQl7HdqIF6XFq//FvjRALkubd2He+03Mxgs40C5Tq11I2CV6xwQaK2LtH9RDa11NbCNwVe97BLgYf//DwOf7rumdIkzgT1a6wN93ZBI0Vq/B5S12NzWdbgEWKq1dmut92GyIub2RjsjIVxftNb/01p7/E9XYWob9HvauC5tMeCui4V/8aArgCd6tVFdpJ37cK/9ZgaDGA+aUpxKqdHADOAj/6bb/G64BwaCa9ePBv6nlPrEX3ENIEf78879j9l91rqu8TlCbyoD8bpA29dhoP+Gvgi8FvS8QCm1Tin1rlLq9L5qVCcJ950ayNfldOC41npX0LYBcV1a3Id77TczGMQ4olKc/R2lVCLwDPB1rXUVZuWrMcB0oAjj8hkInKq1nolZyetWpdTCvm5Qd1Cm0M3FwH/9mwbqdWmPAfsbUkp9H/AAj/k3FQEjtdYzgG8CjyulkvuqfRHS1ndqwF4X4CpCB7AD4rqEuQ+3uWuYbd26NoNBjCMqxdmfUUo5MV+Ax7TWzwJorY9rrb1aax/wT/qRe6o9tNZH/Y8ngOcw7T6ulMoF8D+e6LsWdprzgbVa6+MwcK+Ln7auw4D8DSmlrgM+BVyt/RN5frdhqf//TzBzeeP7rpUd0853aqBeFwfwGeBJa9tAuC7h7sP04m9mMIhxJOU6+y3+uZV/A9u01r8L2p4btNulwOaWx/Y3lFIJSqkk639MkM1mzPW4zr/bdcALfdPCLhEywh+I1yWItq7Di8DnlFKxSqkCzLrkq/ugfRGjlDoPuBO4WGtdF7Q9S5k12FFKFWL6srdvWhkZ7XynBtx18XMWsF1rfdja0N+vS1v3YXrzN9PXUWxRioS7ABP9tgf4fl+3p5NtPw3j3tgIrPf/XQD8B9jk3/4ikNvXbY2gL4WYCMMNwBbrWgAZwNvALv9jel+3NcL+xAOlQErQtgFxXTADiCKgCTOK/1J71wH4vv/3swM4v6/bH0FfdmPm7KzfzH3+fT/r/+5tANYCF/V1+yPoS5vfqYF2XfzbHwJuabFvf78ubd2He+03IxW4BEEQBKGPGQxuakEQBEEY0IgYC4IgCEIfI2IsCIIgCH2MiLEgCIIg9DEixoIgCILQx4gYC4IgCEIfI2IsCIIgCH2MiLEgCIIg9DH/H/rG2vytMMgjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#####################################################GO HERE FOR RECORDING############################3\n",
    "######################################################################################################\n",
    "input_dim = X.shape[1]\n",
    "hidden_layers = [256,100]\n",
    "init_activation = 'relu'\n",
    "activation_funcs = ['relu','relu']\n",
    "optimizer = 'adam'\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = 200\n",
    "(X, Y, model) = train_mlp(X,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "history = model.fit(X,Y,epochs=epochs,)\n",
    "results = model.evaluate(X_test,Y_test)\n",
    "print(\"test loss, test acc:\", results)\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "f72d6acd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3274863971775696\n",
      "0.2079803224924843\n"
     ]
    }
   ],
   "source": [
    "# The example for how to train is complete! Let's see what the baseline accuracy of guessing the most common class is:\n",
    "counts = []\n",
    "for i in range(16):\n",
    "    counts.append(0)\n",
    "for i in Y_test:\n",
    "    counts[int(i)]+=1\n",
    "print(counts[0]/sum(counts))\n",
    "print(counts[1]/sum(counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "5fb5b8b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Next step is to make the separate arrays to test. \n",
    "X_chroma_cens = X[:,:84]\n",
    "X_chroma_cens_test = X_test[:,:84]\n",
    "X_chroma_cqt = X[:,84:168]\n",
    "X_chroma_cqt_test = X_test[:,84:168]\n",
    "X_chroma_stft = X[:,168:252]\n",
    "X_chroma_stft_test = X_test[:,168:252]\n",
    "\n",
    "X_mfcc = X[:,252:392]\n",
    "X_mfcc_test = X_test[:,252:392]\n",
    "\n",
    "X_rmse = X[:,393:399]\n",
    "X_rmse_test = X_test[:,393:399]\n",
    "\n",
    "X_spectral_bandwidth = X[:,399:406]\n",
    "X_spectral_bandwidth_test = X_test[:,399:406]\n",
    "\n",
    "X_spectral_centroid = X[:,406:413]\n",
    "X_spectral_centroid_test = X_test[:,406:413]\n",
    "\n",
    "X_spectral_contrast = X[:,413:462]\n",
    "X_spectral_contrast_test = X_test[:,413:462]\n",
    "\n",
    "X_spectral_rolloff = X[:,462:469]\n",
    "X_spectral_rolloff_test = X_test[:,462:469]\n",
    "\n",
    "X_tonnetz = X[:,469:511]\n",
    "X_tonnetz_test = X_test[:,469:511]\n",
    "\n",
    "X_zcr = X[:,511:518]\n",
    "X_zcr_test = X_test[:,511:518]\n",
    "\n",
    "X_dates = X[:,518].reshape(X_dates.shape[0],1)\n",
    "X_test_dates = X_test[:,518].reshape(X_test.shape[0],1)\n",
    "\n",
    "X_duration = X[:,519].reshape(X_duration.shape[0],1)\n",
    "X_test_duration = X_test[:,519].reshape(X_test.shape[0],1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4a6c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the mlp, we want to collapse the chroma time series "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "838c2fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "293/293 [==============================] - 4s 11ms/step - loss: 2.7106 - accuracy: 0.1067\n",
      "Epoch 2/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.6217 - accuracy: 0.1029\n",
      "Epoch 3/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.5691 - accuracy: 0.1033\n",
      "Epoch 4/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.5378 - accuracy: 0.1017\n",
      "Epoch 5/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.5183 - accuracy: 0.0994\n",
      "Epoch 6/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.5060 - accuracy: 0.0970\n",
      "Epoch 7/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4977 - accuracy: 0.0990\n",
      "Epoch 8/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4921 - accuracy: 0.1055\n",
      "Epoch 9/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4880 - accuracy: 0.1042\n",
      "Epoch 10/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4851 - accuracy: 0.0982\n",
      "Epoch 11/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4830 - accuracy: 0.1019\n",
      "Epoch 12/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4814 - accuracy: 0.1034\n",
      "Epoch 13/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4802 - accuracy: 0.0999\n",
      "Epoch 14/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4793 - accuracy: 0.1040\n",
      "Epoch 15/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4785 - accuracy: 0.1047\n",
      "Epoch 16/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4780 - accuracy: 0.1056\n",
      "Epoch 17/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4776 - accuracy: 0.1000\n",
      "Epoch 18/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4772 - accuracy: 0.1047\n",
      "Epoch 19/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4770 - accuracy: 0.1047\n",
      "Epoch 20/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4767 - accuracy: 0.1054\n",
      "Epoch 21/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4766 - accuracy: 0.0976\n",
      "Epoch 22/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4764 - accuracy: 0.1030\n",
      "Epoch 23/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4763 - accuracy: 0.0985\n",
      "Epoch 24/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4763 - accuracy: 0.1012\n",
      "Epoch 25/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4762 - accuracy: 0.1040\n",
      "Epoch 26/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4761 - accuracy: 0.1040\n",
      "Epoch 27/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4761 - accuracy: 0.1028\n",
      "Epoch 28/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4760 - accuracy: 0.1057\n",
      "Epoch 29/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4760 - accuracy: 0.1047\n",
      "Epoch 30/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4760 - accuracy: 0.1009\n",
      "Epoch 31/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1060\n",
      "Epoch 32/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1000\n",
      "Epoch 33/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4759 - accuracy: 0.1048\n",
      "Epoch 34/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1017\n",
      "Epoch 35/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1036\n",
      "Epoch 36/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1045\n",
      "Epoch 37/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1005\n",
      "Epoch 38/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.0968\n",
      "Epoch 39/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.0994\n",
      "Epoch 40/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.0971\n",
      "Epoch 41/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.0995\n",
      "Epoch 42/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1016\n",
      "Epoch 43/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4759 - accuracy: 0.1019\n",
      "Epoch 44/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1034\n",
      "Epoch 45/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1020\n",
      "Epoch 46/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1041\n",
      "Epoch 47/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1014\n",
      "Epoch 48/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1046\n",
      "Epoch 49/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1032\n",
      "Epoch 50/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1036\n",
      "Epoch 51/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1013\n",
      "Epoch 52/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1044\n",
      "Epoch 53/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1009\n",
      "Epoch 54/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1015\n",
      "Epoch 55/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1044\n",
      "Epoch 56/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1020\n",
      "Epoch 57/200\n",
      "293/293 [==============================] - 2s 9ms/step - loss: 2.4758 - accuracy: 0.0988\n",
      "Epoch 58/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1040\n",
      "Epoch 59/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1066\n",
      "Epoch 60/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.0995\n",
      "Epoch 61/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1054\n",
      "Epoch 62/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1002\n",
      "Epoch 63/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1053\n",
      "Epoch 64/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1028\n",
      "Epoch 65/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1010\n",
      "Epoch 66/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1050\n",
      "Epoch 67/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1000\n",
      "Epoch 68/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1001\n",
      "Epoch 69/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1033\n",
      "Epoch 70/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1031\n",
      "Epoch 71/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1023\n",
      "Epoch 72/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1008\n",
      "Epoch 73/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.0983\n",
      "Epoch 74/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1003\n",
      "Epoch 75/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.0993\n",
      "Epoch 76/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1026\n",
      "Epoch 77/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1013\n",
      "Epoch 78/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1027\n",
      "Epoch 79/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4758 - accuracy: 0.1018\n",
      "Epoch 80/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.1036\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1071\n",
      "Epoch 82/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1027\n",
      "Epoch 83/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1023\n",
      "Epoch 84/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1026\n",
      "Epoch 85/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1030\n",
      "Epoch 86/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1027\n",
      "Epoch 87/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.0994\n",
      "Epoch 88/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.0996\n",
      "Epoch 89/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.0998\n",
      "Epoch 90/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1025\n",
      "Epoch 91/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1042\n",
      "Epoch 92/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4759 - accuracy: 0.1028\n",
      "Epoch 93/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4758 - accuracy: 0.0970\n",
      "Epoch 94/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1016\n",
      "Epoch 95/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1010\n",
      "Epoch 96/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1033\n",
      "Epoch 97/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1038\n",
      "Epoch 98/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1047\n",
      "Epoch 99/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0993\n",
      "Epoch 100/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0998\n",
      "Epoch 101/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0957\n",
      "Epoch 102/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1016\n",
      "Epoch 103/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1004\n",
      "Epoch 104/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1008\n",
      "Epoch 105/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1041\n",
      "Epoch 106/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1011\n",
      "Epoch 107/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4758 - accuracy: 0.1019\n",
      "Epoch 108/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4758 - accuracy: 0.1021\n",
      "Epoch 109/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1044\n",
      "Epoch 110/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.0999\n",
      "Epoch 111/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1000\n",
      "Epoch 112/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1047\n",
      "Epoch 113/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1025\n",
      "Epoch 114/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1004\n",
      "Epoch 115/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0989\n",
      "Epoch 116/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1004\n",
      "Epoch 117/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0996\n",
      "Epoch 118/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1027\n",
      "Epoch 119/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1015\n",
      "Epoch 120/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1028\n",
      "Epoch 121/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1020\n",
      "Epoch 122/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.0985\n",
      "Epoch 123/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1018\n",
      "Epoch 124/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1045\n",
      "Epoch 125/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1005\n",
      "Epoch 126/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0988\n",
      "Epoch 127/200\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 2.4758 - accuracy: 0.1004\n",
      "Epoch 128/200\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 2.4758 - accuracy: 0.1000\n",
      "Epoch 129/200\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 2.4758 - accuracy: 0.1042\n",
      "Epoch 130/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1001\n",
      "Epoch 131/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0987\n",
      "Epoch 132/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0992\n",
      "Epoch 133/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0994\n",
      "Epoch 134/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1018\n",
      "Epoch 135/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1031\n",
      "Epoch 136/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1026\n",
      "Epoch 137/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1059\n",
      "Epoch 138/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1039\n",
      "Epoch 139/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1019\n",
      "Epoch 140/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1019\n",
      "Epoch 141/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1001\n",
      "Epoch 142/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.1038\n",
      "Epoch 143/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1032\n",
      "Epoch 144/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1028\n",
      "Epoch 145/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1064\n",
      "Epoch 146/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4759 - accuracy: 0.1023\n",
      "Epoch 147/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0994\n",
      "Epoch 148/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0993\n",
      "Epoch 149/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1019\n",
      "Epoch 150/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1056\n",
      "Epoch 151/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1015\n",
      "Epoch 152/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0985\n",
      "Epoch 153/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1020\n",
      "Epoch 154/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1018\n",
      "Epoch 155/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.0990\n",
      "Epoch 156/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4759 - accuracy: 0.0989\n",
      "Epoch 157/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1043\n",
      "Epoch 158/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1009\n",
      "Epoch 159/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1033\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0994\n",
      "Epoch 161/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1027\n",
      "Epoch 162/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1030\n",
      "Epoch 163/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1041\n",
      "Epoch 164/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4759 - accuracy: 0.1045\n",
      "Epoch 165/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.0972\n",
      "Epoch 166/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1004\n",
      "Epoch 167/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1009\n",
      "Epoch 168/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1043\n",
      "Epoch 169/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1001\n",
      "Epoch 170/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.0998\n",
      "Epoch 171/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1048\n",
      "Epoch 172/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1000\n",
      "Epoch 173/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1018\n",
      "Epoch 174/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.0988\n",
      "Epoch 175/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1011\n",
      "Epoch 176/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.1050\n",
      "Epoch 177/200\n",
      "293/293 [==============================] - 2s 9ms/step - loss: 2.4758 - accuracy: 0.0958\n",
      "Epoch 178/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1060\n",
      "Epoch 179/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1044\n",
      "Epoch 180/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1028\n",
      "Epoch 181/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.0996\n",
      "Epoch 182/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1012\n",
      "Epoch 183/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1023\n",
      "Epoch 184/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4759 - accuracy: 0.1039\n",
      "Epoch 185/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.1039\n",
      "Epoch 186/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1036\n",
      "Epoch 187/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.1038\n",
      "Epoch 188/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1001\n",
      "Epoch 189/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0963\n",
      "Epoch 190/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1011\n",
      "Epoch 191/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1035\n",
      "Epoch 192/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0982\n",
      "Epoch 193/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1013\n",
      "Epoch 194/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1025\n",
      "Epoch 195/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1004\n",
      "Epoch 196/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.1055\n",
      "Epoch 197/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1044\n",
      "Epoch 198/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4759 - accuracy: 0.0958\n",
      "Epoch 199/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1011\n",
      "Epoch 200/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4758 - accuracy: 0.1005\n",
      "1258/1258 [==============================] - 6s 5ms/step - loss: 2.2896 - accuracy: 0.3275\n",
      "test loss, test acc: [2.2895894050598145, 0.32748639583587646]\n"
     ]
    }
   ],
   "source": [
    "#input_dim = X_dates.shape[1]\n",
    "# need to do 1 instead because that axis has dimension 0\n",
    "input_dim = 1\n",
    "hidden_layers = [1,1]\n",
    "init_activation = 'relu'\n",
    "activation_funcs = ['relu','relu']\n",
    "optimizer = 'adam'\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = 200\n",
    "(X_dates, Y, model) = train_mlp(X_dates,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "history = model.fit(X_dates,Y,epochs=epochs,)\n",
    "results = model.evaluate(X_test_dates,Y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "698ebb26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "293/293 [==============================] - 6s 8ms/step - loss: 2.7112 - accuracy: 0.1046\n",
      "Epoch 2/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.6222 - accuracy: 0.1045\n",
      "Epoch 3/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.5695 - accuracy: 0.1024\n",
      "Epoch 4/200\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 2.5382 - accuracy: 0.1007\n",
      "Epoch 5/200\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 2.5188 - accuracy: 0.1029\n",
      "Epoch 6/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.5063 - accuracy: 0.1004\n",
      "Epoch 7/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4979 - accuracy: 0.1028\n",
      "Epoch 8/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4922 - accuracy: 0.1041\n",
      "Epoch 9/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4881 - accuracy: 0.1042\n",
      "Epoch 10/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4851 - accuracy: 0.1071\n",
      "Epoch 11/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4830 - accuracy: 0.1013\n",
      "Epoch 12/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4814 - accuracy: 0.1008\n",
      "Epoch 13/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4802 - accuracy: 0.1028\n",
      "Epoch 14/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4793 - accuracy: 0.1023\n",
      "Epoch 15/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4785 - accuracy: 0.1043\n",
      "Epoch 16/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4780 - accuracy: 0.0982\n",
      "Epoch 17/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4775 - accuracy: 0.1005\n",
      "Epoch 18/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4772 - accuracy: 0.1008\n",
      "Epoch 19/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4769 - accuracy: 0.1015\n",
      "Epoch 20/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4767 - accuracy: 0.1011\n",
      "Epoch 21/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4765 - accuracy: 0.1018\n",
      "Epoch 22/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4764 - accuracy: 0.1009\n",
      "Epoch 23/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4763 - accuracy: 0.1067\n",
      "Epoch 24/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4762 - accuracy: 0.1001\n",
      "Epoch 25/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4761 - accuracy: 0.1021\n",
      "Epoch 26/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4761 - accuracy: 0.1005\n",
      "Epoch 27/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4761 - accuracy: 0.1011\n",
      "Epoch 28/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4760 - accuracy: 0.0995\n",
      "Epoch 29/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4760 - accuracy: 0.1004\n",
      "Epoch 30/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4760 - accuracy: 0.0995\n",
      "Epoch 31/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4759 - accuracy: 0.0989\n",
      "Epoch 32/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.1030\n",
      "Epoch 33/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4759 - accuracy: 0.1069\n",
      "Epoch 34/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4759 - accuracy: 0.1038\n",
      "Epoch 35/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4759 - accuracy: 0.1009\n",
      "Epoch 36/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.1001\n",
      "Epoch 37/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4759 - accuracy: 0.0997\n",
      "Epoch 38/200\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 2.4759 - accuracy: 0.1050\n",
      "Epoch 39/200\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 2.4758 - accuracy: 0.0993\n",
      "Epoch 40/200\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 2.4759 - accuracy: 0.1051\n",
      "Epoch 41/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1034\n",
      "Epoch 42/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1029\n",
      "Epoch 43/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1017\n",
      "Epoch 44/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1013\n",
      "Epoch 45/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1017\n",
      "Epoch 46/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1055\n",
      "Epoch 47/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.1050\n",
      "Epoch 48/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.1013\n",
      "Epoch 49/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1012\n",
      "Epoch 50/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1027\n",
      "Epoch 51/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1044\n",
      "Epoch 52/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4758 - accuracy: 0.1043\n",
      "Epoch 53/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.0971\n",
      "Epoch 54/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4759 - accuracy: 0.1036\n",
      "Epoch 55/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1047\n",
      "Epoch 56/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0995\n",
      "Epoch 57/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1016\n",
      "Epoch 58/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0980\n",
      "Epoch 59/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1034\n",
      "Epoch 60/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1035\n",
      "Epoch 61/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4758 - accuracy: 0.1002\n",
      "Epoch 62/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.0986\n",
      "Epoch 63/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.0993\n",
      "Epoch 64/200\n",
      "293/293 [==============================] - 2s 9ms/step - loss: 2.4758 - accuracy: 0.0996\n",
      "Epoch 65/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1038\n",
      "Epoch 66/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1048\n",
      "Epoch 67/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1028\n",
      "Epoch 68/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1011\n",
      "Epoch 69/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1019\n",
      "Epoch 70/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.0980\n",
      "Epoch 71/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4758 - accuracy: 0.1062\n",
      "Epoch 72/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4758 - accuracy: 0.1008\n",
      "Epoch 73/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4758 - accuracy: 0.1004\n",
      "Epoch 74/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4758 - accuracy: 0.1035\n",
      "Epoch 75/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4758 - accuracy: 0.1029\n",
      "Epoch 76/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0995\n",
      "Epoch 77/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1020\n",
      "Epoch 78/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1017\n",
      "Epoch 79/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1017\n",
      "Epoch 80/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1021\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.0980\n",
      "Epoch 82/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0994\n",
      "Epoch 83/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1050\n",
      "Epoch 84/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0982\n",
      "Epoch 85/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1021\n",
      "Epoch 86/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1030\n",
      "Epoch 87/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1038\n",
      "Epoch 88/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1019\n",
      "Epoch 89/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4759 - accuracy: 0.1047\n",
      "Epoch 90/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0989\n",
      "Epoch 91/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1030\n",
      "Epoch 92/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0974\n",
      "Epoch 93/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0985\n",
      "Epoch 94/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0974\n",
      "Epoch 95/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1057\n",
      "Epoch 96/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1043\n",
      "Epoch 97/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.0990\n",
      "Epoch 98/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1025\n",
      "Epoch 99/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1023\n",
      "Epoch 100/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0997\n",
      "Epoch 101/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1023\n",
      "Epoch 102/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0969\n",
      "Epoch 103/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1028\n",
      "Epoch 104/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1044\n",
      "Epoch 105/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1034\n",
      "Epoch 106/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1065\n",
      "Epoch 107/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1003\n",
      "Epoch 108/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.1045\n",
      "Epoch 109/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1023\n",
      "Epoch 110/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1011\n",
      "Epoch 111/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1025\n",
      "Epoch 112/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1045\n",
      "Epoch 113/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.1023\n",
      "Epoch 114/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1030\n",
      "Epoch 115/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1056\n",
      "Epoch 116/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1046\n",
      "Epoch 117/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1035\n",
      "Epoch 118/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1013\n",
      "Epoch 119/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1030\n",
      "Epoch 120/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4759 - accuracy: 0.1016\n",
      "Epoch 121/200\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 2.4759 - accuracy: 0.1013\n",
      "Epoch 122/200\n",
      "293/293 [==============================] - 3s 11ms/step - loss: 2.4758 - accuracy: 0.1015\n",
      "Epoch 123/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1015\n",
      "Epoch 124/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1001\n",
      "Epoch 125/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1013\n",
      "Epoch 126/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1012\n",
      "Epoch 127/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1029\n",
      "Epoch 128/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0976\n",
      "Epoch 129/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1000\n",
      "Epoch 130/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1036\n",
      "Epoch 131/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1017\n",
      "Epoch 132/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0994\n",
      "Epoch 133/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1033\n",
      "Epoch 134/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.0997\n",
      "Epoch 135/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1014\n",
      "Epoch 136/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0986\n",
      "Epoch 137/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.0998\n",
      "Epoch 138/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1044\n",
      "Epoch 139/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1011\n",
      "Epoch 140/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1048\n",
      "Epoch 141/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1047\n",
      "Epoch 142/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1011\n",
      "Epoch 143/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1014\n",
      "Epoch 144/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1030\n",
      "Epoch 145/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1039\n",
      "Epoch 146/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0996\n",
      "Epoch 147/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1023\n",
      "Epoch 148/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1061\n",
      "Epoch 149/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1008\n",
      "Epoch 150/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1004\n",
      "Epoch 151/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.0994\n",
      "Epoch 152/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.0984\n",
      "Epoch 153/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1047\n",
      "Epoch 154/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1023\n",
      "Epoch 155/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1026\n",
      "Epoch 156/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1024\n",
      "Epoch 157/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1015\n",
      "Epoch 158/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4759 - accuracy: 0.1027\n",
      "Epoch 159/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1036\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1008\n",
      "Epoch 161/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1017\n",
      "Epoch 162/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1003\n",
      "Epoch 163/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1054\n",
      "Epoch 164/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1059\n",
      "Epoch 165/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1027\n",
      "Epoch 166/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0989\n",
      "Epoch 167/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1013\n",
      "Epoch 168/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1030\n",
      "Epoch 169/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1021\n",
      "Epoch 170/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1032\n",
      "Epoch 171/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1017\n",
      "Epoch 172/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1002\n",
      "Epoch 173/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1026\n",
      "Epoch 174/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.1002\n",
      "Epoch 175/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1027\n",
      "Epoch 176/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1028\n",
      "Epoch 177/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1018\n",
      "Epoch 178/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1030\n",
      "Epoch 179/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0994\n",
      "Epoch 180/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1031\n",
      "Epoch 181/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1029\n",
      "Epoch 182/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1026\n",
      "Epoch 183/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0993\n",
      "Epoch 184/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1028\n",
      "Epoch 185/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1021\n",
      "Epoch 186/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1014\n",
      "Epoch 187/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1032\n",
      "Epoch 188/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1031\n",
      "Epoch 189/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1041\n",
      "Epoch 190/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1026\n",
      "Epoch 191/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0994\n",
      "Epoch 192/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1029\n",
      "Epoch 193/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.4758 - accuracy: 0.1027\n",
      "Epoch 194/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.1061\n",
      "Epoch 195/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1043\n",
      "Epoch 196/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.4758 - accuracy: 0.0999\n",
      "Epoch 197/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.0996\n",
      "Epoch 198/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.4758 - accuracy: 0.1032\n",
      "Epoch 199/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 2.4758 - accuracy: 0.0994\n",
      "Epoch 200/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.4758 - accuracy: 0.1040\n",
      "1258/1258 [==============================] - 7s 6ms/step - loss: 2.2895 - accuracy: 0.0268\n",
      "test loss, test acc: [2.2895092964172363, 0.026783274486660957]\n"
     ]
    }
   ],
   "source": [
    "#input_dim = X_dates.shape[1]\n",
    "# need to do 1 instead because that axis has dimension 0\n",
    "\n",
    "input_dim = 1\n",
    "hidden_layers = [1,1]\n",
    "init_activation = 'relu'\n",
    "activation_funcs = ['relu','relu']\n",
    "optimizer = 'adam'\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = 200\n",
    "(X_duration, Y, model) = train_mlp(X_duration,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "history = model.fit(X_duration,Y,epochs=epochs,)\n",
    "results = model.evaluate(X_test_duration,Y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "9bf4f9c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.6486 - accuracy: 0.1535\n",
      "Epoch 2/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.5147 - accuracy: 0.1604\n",
      "Epoch 3/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4500 - accuracy: 0.1608\n",
      "Epoch 4/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.4116 - accuracy: 0.1647\n",
      "Epoch 5/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3860 - accuracy: 0.1681\n",
      "Epoch 6/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3674 - accuracy: 0.1745\n",
      "Epoch 7/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3556 - accuracy: 0.1792\n",
      "Epoch 8/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3440 - accuracy: 0.1800\n",
      "Epoch 9/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3336 - accuracy: 0.1742\n",
      "Epoch 10/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3264 - accuracy: 0.1806\n",
      "Epoch 11/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3201 - accuracy: 0.1789\n",
      "Epoch 12/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3151 - accuracy: 0.1802\n",
      "Epoch 13/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3091 - accuracy: 0.1930\n",
      "Epoch 14/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.3046 - accuracy: 0.2016\n",
      "Epoch 15/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3024 - accuracy: 0.1964\n",
      "Epoch 16/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2972 - accuracy: 0.1968\n",
      "Epoch 17/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2930 - accuracy: 0.1961\n",
      "Epoch 18/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2900 - accuracy: 0.2049\n",
      "Epoch 19/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2903 - accuracy: 0.1954\n",
      "Epoch 20/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2851 - accuracy: 0.1966\n",
      "Epoch 21/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2845 - accuracy: 0.2061\n",
      "Epoch 22/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2827 - accuracy: 0.2030\n",
      "Epoch 23/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2792 - accuracy: 0.1969\n",
      "Epoch 24/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2760 - accuracy: 0.1933\n",
      "Epoch 25/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2773 - accuracy: 0.2023\n",
      "Epoch 26/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2741 - accuracy: 0.2059\n",
      "Epoch 27/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2730 - accuracy: 0.2002\n",
      "Epoch 28/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2702 - accuracy: 0.2023\n",
      "Epoch 29/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2699 - accuracy: 0.1988\n",
      "Epoch 30/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2670 - accuracy: 0.2013\n",
      "Epoch 31/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2686 - accuracy: 0.2059\n",
      "Epoch 32/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2658 - accuracy: 0.1988\n",
      "Epoch 33/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2617 - accuracy: 0.2010\n",
      "Epoch 34/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2647 - accuracy: 0.1985\n",
      "Epoch 35/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2639 - accuracy: 0.1999\n",
      "Epoch 36/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2611 - accuracy: 0.2023\n",
      "Epoch 37/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2605 - accuracy: 0.2019\n",
      "Epoch 38/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2598 - accuracy: 0.2010\n",
      "Epoch 39/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2586 - accuracy: 0.1961\n",
      "Epoch 40/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2562 - accuracy: 0.2006\n",
      "Epoch 41/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2556 - accuracy: 0.2010\n",
      "Epoch 42/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2554 - accuracy: 0.1981\n",
      "Epoch 43/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2551 - accuracy: 0.2024\n",
      "Epoch 44/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2533 - accuracy: 0.2060\n",
      "Epoch 45/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2522 - accuracy: 0.2006\n",
      "Epoch 46/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2503 - accuracy: 0.2089\n",
      "Epoch 47/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2513 - accuracy: 0.2041\n",
      "Epoch 48/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2495 - accuracy: 0.2094\n",
      "Epoch 49/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2496 - accuracy: 0.2046\n",
      "Epoch 50/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2477 - accuracy: 0.2054\n",
      "Epoch 51/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2505 - accuracy: 0.2044\n",
      "Epoch 52/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2467 - accuracy: 0.2022\n",
      "Epoch 53/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2457 - accuracy: 0.2019\n",
      "Epoch 54/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2473 - accuracy: 0.2072\n",
      "Epoch 55/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2446 - accuracy: 0.2065\n",
      "Epoch 56/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2489 - accuracy: 0.2055\n",
      "Epoch 57/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2430 - accuracy: 0.2110\n",
      "Epoch 58/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2409 - accuracy: 0.2113\n",
      "Epoch 59/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2427 - accuracy: 0.2067\n",
      "Epoch 60/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2424 - accuracy: 0.2027\n",
      "Epoch 61/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2435 - accuracy: 0.2042\n",
      "Epoch 62/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2395 - accuracy: 0.2114\n",
      "Epoch 63/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2390 - accuracy: 0.2072\n",
      "Epoch 64/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2421 - accuracy: 0.2048\n",
      "Epoch 65/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2354 - accuracy: 0.2096\n",
      "Epoch 66/200\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 2.2374 - accuracy: 0.2103\n",
      "Epoch 67/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2391 - accuracy: 0.2088\n",
      "Epoch 68/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2359 - accuracy: 0.2103\n",
      "Epoch 69/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2341 - accuracy: 0.2106\n",
      "Epoch 70/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2363 - accuracy: 0.2156\n",
      "Epoch 71/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2363 - accuracy: 0.2050\n",
      "Epoch 72/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2339 - accuracy: 0.2084\n",
      "Epoch 73/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2353 - accuracy: 0.2141\n",
      "Epoch 74/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2336 - accuracy: 0.2083\n",
      "Epoch 75/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2338 - accuracy: 0.2104\n",
      "Epoch 76/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2323 - accuracy: 0.2155\n",
      "Epoch 77/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2330 - accuracy: 0.2101\n",
      "Epoch 78/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2326 - accuracy: 0.2120\n",
      "Epoch 79/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2314 - accuracy: 0.2099\n",
      "Epoch 80/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2333 - accuracy: 0.2091\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2281 - accuracy: 0.2105\n",
      "Epoch 82/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2288 - accuracy: 0.2098\n",
      "Epoch 83/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2300 - accuracy: 0.2164\n",
      "Epoch 84/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2306 - accuracy: 0.2100\n",
      "Epoch 85/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2292 - accuracy: 0.2083\n",
      "Epoch 86/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2315 - accuracy: 0.2075\n",
      "Epoch 87/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2279 - accuracy: 0.2108\n",
      "Epoch 88/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2256 - accuracy: 0.2147\n",
      "Epoch 89/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2263 - accuracy: 0.2130\n",
      "Epoch 90/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2253 - accuracy: 0.2100\n",
      "Epoch 91/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2259 - accuracy: 0.2108\n",
      "Epoch 92/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2253 - accuracy: 0.2118\n",
      "Epoch 93/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2235 - accuracy: 0.2163\n",
      "Epoch 94/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2251 - accuracy: 0.2117\n",
      "Epoch 95/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2276 - accuracy: 0.2078\n",
      "Epoch 96/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2262 - accuracy: 0.2108\n",
      "Epoch 97/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2268 - accuracy: 0.2139\n",
      "Epoch 98/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2236 - accuracy: 0.2138\n",
      "Epoch 99/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2242 - accuracy: 0.2104\n",
      "Epoch 100/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2242 - accuracy: 0.2159\n",
      "Epoch 101/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2245 - accuracy: 0.2103\n",
      "Epoch 102/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2237 - accuracy: 0.2154\n",
      "Epoch 103/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2248 - accuracy: 0.2134\n",
      "Epoch 104/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2228 - accuracy: 0.2105\n",
      "Epoch 105/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2224 - accuracy: 0.2138\n",
      "Epoch 106/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2234 - accuracy: 0.2179\n",
      "Epoch 107/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2215 - accuracy: 0.2150\n",
      "Epoch 108/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2212 - accuracy: 0.2136\n",
      "Epoch 109/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2212 - accuracy: 0.2157\n",
      "Epoch 110/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2201 - accuracy: 0.2156\n",
      "Epoch 111/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2185 - accuracy: 0.2160\n",
      "Epoch 112/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2187 - accuracy: 0.2173\n",
      "Epoch 113/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2203 - accuracy: 0.2177\n",
      "Epoch 114/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2211 - accuracy: 0.2091\n",
      "Epoch 115/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2173 - accuracy: 0.2139\n",
      "Epoch 116/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2223 - accuracy: 0.2167\n",
      "Epoch 117/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2216 - accuracy: 0.2108\n",
      "Epoch 118/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2178 - accuracy: 0.2150\n",
      "Epoch 119/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2204 - accuracy: 0.2135\n",
      "Epoch 120/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2172 - accuracy: 0.2159\n",
      "Epoch 121/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2191 - accuracy: 0.2157\n",
      "Epoch 122/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2167 - accuracy: 0.2154\n",
      "Epoch 123/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2164 - accuracy: 0.2139\n",
      "Epoch 124/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2154 - accuracy: 0.2129\n",
      "Epoch 125/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2152 - accuracy: 0.2140\n",
      "Epoch 126/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2162 - accuracy: 0.2142\n",
      "Epoch 127/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2150 - accuracy: 0.2134\n",
      "Epoch 128/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2179 - accuracy: 0.2150\n",
      "Epoch 129/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2145 - accuracy: 0.2185\n",
      "Epoch 130/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2115 - accuracy: 0.2144\n",
      "Epoch 131/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2131 - accuracy: 0.2120\n",
      "Epoch 132/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2149 - accuracy: 0.2132\n",
      "Epoch 133/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2127 - accuracy: 0.2152\n",
      "Epoch 134/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2116 - accuracy: 0.2121\n",
      "Epoch 135/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2128 - accuracy: 0.2130\n",
      "Epoch 136/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2097 - accuracy: 0.2149\n",
      "Epoch 137/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2116 - accuracy: 0.2148\n",
      "Epoch 138/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2111 - accuracy: 0.2144\n",
      "Epoch 139/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2119 - accuracy: 0.2180\n",
      "Epoch 140/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2095 - accuracy: 0.2113\n",
      "Epoch 141/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2116 - accuracy: 0.2177\n",
      "Epoch 142/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2101 - accuracy: 0.2087\n",
      "Epoch 143/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2107 - accuracy: 0.2133\n",
      "Epoch 144/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2102 - accuracy: 0.2202\n",
      "Epoch 145/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2097 - accuracy: 0.2207\n",
      "Epoch 146/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2058 - accuracy: 0.2207\n",
      "Epoch 147/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2145 - accuracy: 0.2183\n",
      "Epoch 148/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2053 - accuracy: 0.2177\n",
      "Epoch 149/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2068 - accuracy: 0.2181\n",
      "Epoch 150/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2059 - accuracy: 0.2202\n",
      "Epoch 151/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2084 - accuracy: 0.2164\n",
      "Epoch 152/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2086 - accuracy: 0.2162\n",
      "Epoch 153/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2072 - accuracy: 0.2179\n",
      "Epoch 154/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2068 - accuracy: 0.2166\n",
      "Epoch 155/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2049 - accuracy: 0.2197\n",
      "Epoch 156/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2055 - accuracy: 0.2230\n",
      "Epoch 157/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2080 - accuracy: 0.2192\n",
      "Epoch 158/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2046 - accuracy: 0.2188\n",
      "Epoch 159/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2037 - accuracy: 0.2144\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2063 - accuracy: 0.2137\n",
      "Epoch 161/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2053 - accuracy: 0.2170\n",
      "Epoch 162/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2038 - accuracy: 0.2180\n",
      "Epoch 163/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2029 - accuracy: 0.2136\n",
      "Epoch 164/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2068 - accuracy: 0.2210\n",
      "Epoch 165/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2017 - accuracy: 0.2230\n",
      "Epoch 166/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2032 - accuracy: 0.2159\n",
      "Epoch 167/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2018 - accuracy: 0.2149\n",
      "Epoch 168/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2038 - accuracy: 0.2212\n",
      "Epoch 169/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2089 - accuracy: 0.2167\n",
      "Epoch 170/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2038 - accuracy: 0.2146\n",
      "Epoch 171/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2045 - accuracy: 0.2180\n",
      "Epoch 172/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2018 - accuracy: 0.2208\n",
      "Epoch 173/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2027 - accuracy: 0.2145\n",
      "Epoch 174/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1993 - accuracy: 0.2188\n",
      "Epoch 175/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1982 - accuracy: 0.2188\n",
      "Epoch 176/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1994 - accuracy: 0.2267\n",
      "Epoch 177/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1981 - accuracy: 0.2252\n",
      "Epoch 178/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2010 - accuracy: 0.2187\n",
      "Epoch 179/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1993 - accuracy: 0.2249\n",
      "Epoch 180/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2033 - accuracy: 0.2195\n",
      "Epoch 181/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1978 - accuracy: 0.2205\n",
      "Epoch 182/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1946 - accuracy: 0.2232\n",
      "Epoch 183/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1982 - accuracy: 0.2184\n",
      "Epoch 184/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1995 - accuracy: 0.2175\n",
      "Epoch 185/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2003 - accuracy: 0.2269\n",
      "Epoch 186/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1951 - accuracy: 0.2230\n",
      "Epoch 187/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1984 - accuracy: 0.2202\n",
      "Epoch 188/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1962 - accuracy: 0.2245\n",
      "Epoch 189/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1957 - accuracy: 0.2190\n",
      "Epoch 190/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1953 - accuracy: 0.2214\n",
      "Epoch 191/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1980 - accuracy: 0.2210\n",
      "Epoch 192/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1996 - accuracy: 0.2223\n",
      "Epoch 193/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2014 - accuracy: 0.2169\n",
      "Epoch 194/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1959 - accuracy: 0.2221\n",
      "Epoch 195/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1974 - accuracy: 0.2238\n",
      "Epoch 196/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1930 - accuracy: 0.2196\n",
      "Epoch 197/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1932 - accuracy: 0.2217\n",
      "Epoch 198/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1955 - accuracy: 0.2199\n",
      "Epoch 199/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1935 - accuracy: 0.2260\n",
      "Epoch 200/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1918 - accuracy: 0.2288\n",
      "1258/1258 [==============================] - 3s 2ms/step - loss: 2.4839 - accuracy: 0.2384\n",
      "test loss, test acc: [2.4838757514953613, 0.23839101195335388]\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_zcr.shape[1]\n",
    "hidden_layers = [4,2]\n",
    "init_activation = 'relu'\n",
    "activation_funcs = ['relu','relu']\n",
    "optimizer = 'adam'\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = 200\n",
    "(X_zcr, Y, model) = train_mlp(X_zcr,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "history = model.fit(X_zcr,Y,epochs=epochs,)\n",
    "results = model.evaluate(X_zcr_test,Y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "dfd495f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.6066 - accuracy: 0.1372\n",
      "Epoch 2/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4173 - accuracy: 0.1547\n",
      "Epoch 3/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3258 - accuracy: 0.1738\n",
      "Epoch 4/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2982 - accuracy: 0.2016\n",
      "Epoch 5/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2930 - accuracy: 0.2076\n",
      "Epoch 6/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2817 - accuracy: 0.2248\n",
      "Epoch 7/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2757 - accuracy: 0.2236\n",
      "Epoch 8/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2696 - accuracy: 0.2487\n",
      "Epoch 9/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2648 - accuracy: 0.2412\n",
      "Epoch 10/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2627 - accuracy: 0.2485\n",
      "Epoch 11/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2593 - accuracy: 0.2517\n",
      "Epoch 12/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2506 - accuracy: 0.2570\n",
      "Epoch 13/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2465 - accuracy: 0.2620\n",
      "Epoch 14/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2397 - accuracy: 0.2630\n",
      "Epoch 15/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2296 - accuracy: 0.2624\n",
      "Epoch 16/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2206 - accuracy: 0.2655\n",
      "Epoch 17/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2169 - accuracy: 0.2674\n",
      "Epoch 18/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2132 - accuracy: 0.2682\n",
      "Epoch 19/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2088 - accuracy: 0.2681\n",
      "Epoch 20/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2041 - accuracy: 0.2651\n",
      "Epoch 21/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2020 - accuracy: 0.2682\n",
      "Epoch 22/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1980 - accuracy: 0.2698\n",
      "Epoch 23/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1953 - accuracy: 0.2697\n",
      "Epoch 24/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1930 - accuracy: 0.2677\n",
      "Epoch 25/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1889 - accuracy: 0.2737\n",
      "Epoch 26/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1873 - accuracy: 0.2715\n",
      "Epoch 27/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1865 - accuracy: 0.2733\n",
      "Epoch 28/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1814 - accuracy: 0.2750\n",
      "Epoch 29/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1813 - accuracy: 0.2739\n",
      "Epoch 30/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1777 - accuracy: 0.2744\n",
      "Epoch 31/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1746 - accuracy: 0.2776\n",
      "Epoch 32/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1768 - accuracy: 0.2744\n",
      "Epoch 33/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1726 - accuracy: 0.2774\n",
      "Epoch 34/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1693 - accuracy: 0.2753\n",
      "Epoch 35/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1683 - accuracy: 0.2740\n",
      "Epoch 36/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1660 - accuracy: 0.2815\n",
      "Epoch 37/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1684 - accuracy: 0.2772\n",
      "Epoch 38/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1638 - accuracy: 0.2771\n",
      "Epoch 39/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1626 - accuracy: 0.2798\n",
      "Epoch 40/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1616 - accuracy: 0.2839\n",
      "Epoch 41/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1584 - accuracy: 0.2839\n",
      "Epoch 42/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1578 - accuracy: 0.2805\n",
      "Epoch 43/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1558 - accuracy: 0.2876\n",
      "Epoch 44/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1598 - accuracy: 0.2826\n",
      "Epoch 45/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1555 - accuracy: 0.2829\n",
      "Epoch 46/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1512 - accuracy: 0.2877\n",
      "Epoch 47/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1508 - accuracy: 0.2787\n",
      "Epoch 48/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1497 - accuracy: 0.2858\n",
      "Epoch 49/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1533 - accuracy: 0.2823\n",
      "Epoch 50/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1515 - accuracy: 0.2842\n",
      "Epoch 51/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1444 - accuracy: 0.2863\n",
      "Epoch 52/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1462 - accuracy: 0.2832\n",
      "Epoch 53/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1454 - accuracy: 0.2871\n",
      "Epoch 54/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1452 - accuracy: 0.2864\n",
      "Epoch 55/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1466 - accuracy: 0.2862\n",
      "Epoch 56/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1444 - accuracy: 0.2835\n",
      "Epoch 57/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1448 - accuracy: 0.2893\n",
      "Epoch 58/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1454 - accuracy: 0.2895\n",
      "Epoch 59/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1416 - accuracy: 0.2871\n",
      "Epoch 60/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1408 - accuracy: 0.2879\n",
      "Epoch 61/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1411 - accuracy: 0.2876\n",
      "Epoch 62/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1387 - accuracy: 0.2917\n",
      "Epoch 63/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1357 - accuracy: 0.2916\n",
      "Epoch 64/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1378 - accuracy: 0.2902\n",
      "Epoch 65/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1409 - accuracy: 0.2878\n",
      "Epoch 66/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1363 - accuracy: 0.2901\n",
      "Epoch 67/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1368 - accuracy: 0.2920\n",
      "Epoch 68/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1351 - accuracy: 0.2869\n",
      "Epoch 69/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1329 - accuracy: 0.2895\n",
      "Epoch 70/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1327 - accuracy: 0.2937\n",
      "Epoch 71/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1324 - accuracy: 0.2927\n",
      "Epoch 72/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1309 - accuracy: 0.2905\n",
      "Epoch 73/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1304 - accuracy: 0.2939\n",
      "Epoch 74/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1297 - accuracy: 0.2907\n",
      "Epoch 75/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1283 - accuracy: 0.2891\n",
      "Epoch 76/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1259 - accuracy: 0.2982\n",
      "Epoch 77/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1285 - accuracy: 0.2935\n",
      "Epoch 78/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1311 - accuracy: 0.2894\n",
      "Epoch 79/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1265 - accuracy: 0.2953\n",
      "Epoch 80/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1254 - accuracy: 0.2980\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1272 - accuracy: 0.2934\n",
      "Epoch 82/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1249 - accuracy: 0.2932\n",
      "Epoch 83/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1247 - accuracy: 0.2933\n",
      "Epoch 84/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1222 - accuracy: 0.2993\n",
      "Epoch 85/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1233 - accuracy: 0.2919\n",
      "Epoch 86/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1214 - accuracy: 0.2929\n",
      "Epoch 87/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1232 - accuracy: 0.2959\n",
      "Epoch 88/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1209 - accuracy: 0.2992\n",
      "Epoch 89/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1229 - accuracy: 0.2971\n",
      "Epoch 90/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1196 - accuracy: 0.2986\n",
      "Epoch 91/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1194 - accuracy: 0.2979\n",
      "Epoch 92/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1182 - accuracy: 0.2945\n",
      "Epoch 93/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1204 - accuracy: 0.2932\n",
      "Epoch 94/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1164 - accuracy: 0.2996\n",
      "Epoch 95/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1186 - accuracy: 0.2956\n",
      "Epoch 96/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1163 - accuracy: 0.2998\n",
      "Epoch 97/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1129 - accuracy: 0.2970\n",
      "Epoch 98/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1167 - accuracy: 0.2977\n",
      "Epoch 99/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1158 - accuracy: 0.3002\n",
      "Epoch 100/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1158 - accuracy: 0.3036\n",
      "Epoch 101/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1156 - accuracy: 0.3026\n",
      "Epoch 102/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1137 - accuracy: 0.2976\n",
      "Epoch 103/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1106 - accuracy: 0.3000\n",
      "Epoch 104/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1122 - accuracy: 0.2943\n",
      "Epoch 105/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1146 - accuracy: 0.2994\n",
      "Epoch 106/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1114 - accuracy: 0.3009\n",
      "Epoch 107/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1125 - accuracy: 0.2999\n",
      "Epoch 108/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1126 - accuracy: 0.2970\n",
      "Epoch 109/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1108 - accuracy: 0.3022\n",
      "Epoch 110/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1143 - accuracy: 0.2996\n",
      "Epoch 111/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1096 - accuracy: 0.2986\n",
      "Epoch 112/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1080 - accuracy: 0.2999\n",
      "Epoch 113/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1091 - accuracy: 0.2970\n",
      "Epoch 114/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1064 - accuracy: 0.3002\n",
      "Epoch 115/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1089 - accuracy: 0.3030\n",
      "Epoch 116/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1096 - accuracy: 0.2999\n",
      "Epoch 117/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1044 - accuracy: 0.3069\n",
      "Epoch 118/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1060 - accuracy: 0.3016\n",
      "Epoch 119/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1067 - accuracy: 0.2992\n",
      "Epoch 120/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1042 - accuracy: 0.3033\n",
      "Epoch 121/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1057 - accuracy: 0.3040\n",
      "Epoch 122/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1064 - accuracy: 0.3024\n",
      "Epoch 123/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1037 - accuracy: 0.3011\n",
      "Epoch 124/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1019 - accuracy: 0.3027\n",
      "Epoch 125/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1025 - accuracy: 0.3010\n",
      "Epoch 126/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1007 - accuracy: 0.3042\n",
      "Epoch 127/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1030 - accuracy: 0.2997\n",
      "Epoch 128/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0998 - accuracy: 0.3024\n",
      "Epoch 129/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1006 - accuracy: 0.3017\n",
      "Epoch 130/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1040 - accuracy: 0.3051\n",
      "Epoch 131/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1002 - accuracy: 0.3040\n",
      "Epoch 132/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0979 - accuracy: 0.3022\n",
      "Epoch 133/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0985 - accuracy: 0.3035\n",
      "Epoch 134/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0969 - accuracy: 0.3021\n",
      "Epoch 135/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0947 - accuracy: 0.3069\n",
      "Epoch 136/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0964 - accuracy: 0.3066\n",
      "Epoch 137/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1008 - accuracy: 0.3054\n",
      "Epoch 138/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0967 - accuracy: 0.3097\n",
      "Epoch 139/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0960 - accuracy: 0.3100\n",
      "Epoch 140/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0999 - accuracy: 0.3097\n",
      "Epoch 141/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0954 - accuracy: 0.3085\n",
      "Epoch 142/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.0926 - accuracy: 0.3086\n",
      "Epoch 143/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.0963 - accuracy: 0.3056\n",
      "Epoch 144/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0968 - accuracy: 0.3075\n",
      "Epoch 145/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.0941 - accuracy: 0.3037\n",
      "Epoch 146/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.0936 - accuracy: 0.3060\n",
      "Epoch 147/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0922 - accuracy: 0.3090\n",
      "Epoch 148/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0947 - accuracy: 0.3058\n",
      "Epoch 149/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0924 - accuracy: 0.3059\n",
      "Epoch 150/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0922 - accuracy: 0.3063\n",
      "Epoch 151/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0962 - accuracy: 0.3053\n",
      "Epoch 152/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.0948 - accuracy: 0.3083\n",
      "Epoch 153/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.0914 - accuracy: 0.3074\n",
      "Epoch 154/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0903 - accuracy: 0.3083\n",
      "Epoch 155/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0867 - accuracy: 0.3120\n",
      "Epoch 156/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0892 - accuracy: 0.3075\n",
      "Epoch 157/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0884 - accuracy: 0.3076\n",
      "Epoch 158/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0871 - accuracy: 0.3058\n",
      "Epoch 159/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.0888 - accuracy: 0.3084\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0881 - accuracy: 0.3103\n",
      "Epoch 161/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0898 - accuracy: 0.3101\n",
      "Epoch 162/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0861 - accuracy: 0.3070\n",
      "Epoch 163/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0839 - accuracy: 0.3114\n",
      "Epoch 164/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0854 - accuracy: 0.3094\n",
      "Epoch 165/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0867 - accuracy: 0.3066\n",
      "Epoch 166/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0858 - accuracy: 0.3068\n",
      "Epoch 167/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.0816 - accuracy: 0.3110\n",
      "Epoch 168/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0834 - accuracy: 0.3098\n",
      "Epoch 169/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0847 - accuracy: 0.3147\n",
      "Epoch 170/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0824 - accuracy: 0.3114\n",
      "Epoch 171/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0819 - accuracy: 0.3100\n",
      "Epoch 172/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.0844 - accuracy: 0.3086\n",
      "Epoch 173/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0856 - accuracy: 0.3104\n",
      "Epoch 174/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0817 - accuracy: 0.3085\n",
      "Epoch 175/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0821 - accuracy: 0.3105\n",
      "Epoch 176/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0798 - accuracy: 0.3162\n",
      "Epoch 177/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.0814 - accuracy: 0.3139\n",
      "Epoch 178/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0806 - accuracy: 0.3124\n",
      "Epoch 179/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0834 - accuracy: 0.3104\n",
      "Epoch 180/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0808 - accuracy: 0.3128\n",
      "Epoch 181/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0765 - accuracy: 0.3123\n",
      "Epoch 182/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0778 - accuracy: 0.3152\n",
      "Epoch 183/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0787 - accuracy: 0.3132\n",
      "Epoch 184/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0768 - accuracy: 0.3127\n",
      "Epoch 185/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0780 - accuracy: 0.3112\n",
      "Epoch 186/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0785 - accuracy: 0.3127\n",
      "Epoch 187/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0766 - accuracy: 0.3117\n",
      "Epoch 188/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0777 - accuracy: 0.3121\n",
      "Epoch 189/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0755 - accuracy: 0.3097\n",
      "Epoch 190/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0748 - accuracy: 0.3142\n",
      "Epoch 191/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0752 - accuracy: 0.3117\n",
      "Epoch 192/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0747 - accuracy: 0.3137\n",
      "Epoch 193/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0728 - accuracy: 0.3129\n",
      "Epoch 194/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0775 - accuracy: 0.3174\n",
      "Epoch 195/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0732 - accuracy: 0.3156\n",
      "Epoch 196/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0728 - accuracy: 0.3132\n",
      "Epoch 197/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0737 - accuracy: 0.3163\n",
      "Epoch 198/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0697 - accuracy: 0.3189\n",
      "Epoch 199/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0691 - accuracy: 0.3163\n",
      "Epoch 200/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0707 - accuracy: 0.3147\n",
      "1258/1258 [==============================] - 3s 2ms/step - loss: 5.5431 - accuracy: 0.0068\n",
      "test loss, test acc: [5.543056488037109, 0.00683246785774827]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dim = X_spectral_rolloff.shape[1]\n",
    "hidden_layers = [4,2]\n",
    "init_activation = 'relu'\n",
    "activation_funcs = ['relu','relu']\n",
    "optimizer = 'adam'\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = 200\n",
    "(X_spectral_rolloff, Y, model) = train_mlp(X_spectral_rolloff,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "history = model.fit(X_spectral_rolloff,Y,epochs=epochs,)\n",
    "results = model.evaluate(X_spectral_rolloff_test,Y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "50c5a965",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.6371 - accuracy: 0.1448\n",
      "Epoch 2/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.4742 - accuracy: 0.1960\n",
      "Epoch 3/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3838 - accuracy: 0.2239\n",
      "Epoch 4/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3374 - accuracy: 0.2337\n",
      "Epoch 5/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2999 - accuracy: 0.2350\n",
      "Epoch 6/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2800 - accuracy: 0.2396\n",
      "Epoch 7/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2615 - accuracy: 0.2403\n",
      "Epoch 8/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2470 - accuracy: 0.2415\n",
      "Epoch 9/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2355 - accuracy: 0.2526\n",
      "Epoch 10/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2284 - accuracy: 0.2533\n",
      "Epoch 11/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2161 - accuracy: 0.2567\n",
      "Epoch 12/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2080 - accuracy: 0.2618\n",
      "Epoch 13/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.2053 - accuracy: 0.2562\n",
      "Epoch 14/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.1999 - accuracy: 0.2594\n",
      "Epoch 15/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.1922 - accuracy: 0.2595\n",
      "Epoch 16/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1874 - accuracy: 0.2586\n",
      "Epoch 17/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1836 - accuracy: 0.2656\n",
      "Epoch 18/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1777 - accuracy: 0.2629\n",
      "Epoch 19/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1745 - accuracy: 0.2699\n",
      "Epoch 20/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1749 - accuracy: 0.2631\n",
      "Epoch 21/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.1689 - accuracy: 0.2678\n",
      "Epoch 22/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1669 - accuracy: 0.2670\n",
      "Epoch 23/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1627 - accuracy: 0.2697\n",
      "Epoch 24/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1625 - accuracy: 0.2706\n",
      "Epoch 25/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1614 - accuracy: 0.2710\n",
      "Epoch 26/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1583 - accuracy: 0.2713\n",
      "Epoch 27/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1566 - accuracy: 0.2779\n",
      "Epoch 28/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1534 - accuracy: 0.2759\n",
      "Epoch 29/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1520 - accuracy: 0.2739\n",
      "Epoch 30/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1492 - accuracy: 0.2726\n",
      "Epoch 31/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1513 - accuracy: 0.2778\n",
      "Epoch 32/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1468 - accuracy: 0.2731\n",
      "Epoch 33/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1463 - accuracy: 0.2784\n",
      "Epoch 34/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1449 - accuracy: 0.2754\n",
      "Epoch 35/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1438 - accuracy: 0.2793\n",
      "Epoch 36/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1433 - accuracy: 0.2760\n",
      "Epoch 37/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1418 - accuracy: 0.2769\n",
      "Epoch 38/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1397 - accuracy: 0.2760\n",
      "Epoch 39/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1391 - accuracy: 0.2811\n",
      "Epoch 40/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1366 - accuracy: 0.2789\n",
      "Epoch 41/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1367 - accuracy: 0.2784\n",
      "Epoch 42/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1349 - accuracy: 0.2813\n",
      "Epoch 43/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1351 - accuracy: 0.2814\n",
      "Epoch 44/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1343 - accuracy: 0.2855\n",
      "Epoch 45/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1338 - accuracy: 0.2783\n",
      "Epoch 46/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1320 - accuracy: 0.2822\n",
      "Epoch 47/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1316 - accuracy: 0.2795\n",
      "Epoch 48/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1305 - accuracy: 0.2827\n",
      "Epoch 49/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1303 - accuracy: 0.2813\n",
      "Epoch 50/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1280 - accuracy: 0.2823\n",
      "Epoch 51/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1273 - accuracy: 0.2832\n",
      "Epoch 52/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1274 - accuracy: 0.2823\n",
      "Epoch 53/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1245 - accuracy: 0.2815\n",
      "Epoch 54/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1271 - accuracy: 0.2826\n",
      "Epoch 55/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1217 - accuracy: 0.2812\n",
      "Epoch 56/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1245 - accuracy: 0.2850\n",
      "Epoch 57/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.1222 - accuracy: 0.2861\n",
      "Epoch 58/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1232 - accuracy: 0.2847\n",
      "Epoch 59/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1220 - accuracy: 0.2844\n",
      "Epoch 60/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1210 - accuracy: 0.2848\n",
      "Epoch 61/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1207 - accuracy: 0.2831\n",
      "Epoch 62/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1163 - accuracy: 0.2886\n",
      "Epoch 63/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1201 - accuracy: 0.2862\n",
      "Epoch 64/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1162 - accuracy: 0.2863\n",
      "Epoch 65/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1169 - accuracy: 0.2871\n",
      "Epoch 66/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1156 - accuracy: 0.2883\n",
      "Epoch 67/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1132 - accuracy: 0.2904\n",
      "Epoch 68/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1141 - accuracy: 0.2898\n",
      "Epoch 69/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1124 - accuracy: 0.2910\n",
      "Epoch 70/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1124 - accuracy: 0.2938\n",
      "Epoch 71/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1112 - accuracy: 0.2899\n",
      "Epoch 72/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1105 - accuracy: 0.2916\n",
      "Epoch 73/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1116 - accuracy: 0.2898\n",
      "Epoch 74/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1104 - accuracy: 0.2888\n",
      "Epoch 75/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1072 - accuracy: 0.2909\n",
      "Epoch 76/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1085 - accuracy: 0.2913\n",
      "Epoch 77/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1077 - accuracy: 0.2905\n",
      "Epoch 78/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1078 - accuracy: 0.2971\n",
      "Epoch 79/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1056 - accuracy: 0.2920\n",
      "Epoch 80/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1065 - accuracy: 0.2925\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1052 - accuracy: 0.2958\n",
      "Epoch 82/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1059 - accuracy: 0.2981\n",
      "Epoch 83/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1031 - accuracy: 0.2948\n",
      "Epoch 84/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1053 - accuracy: 0.2941\n",
      "Epoch 85/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1038 - accuracy: 0.2952\n",
      "Epoch 86/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1029 - accuracy: 0.2916\n",
      "Epoch 87/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1006 - accuracy: 0.2916\n",
      "Epoch 88/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1018 - accuracy: 0.2937\n",
      "Epoch 89/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1020 - accuracy: 0.2969\n",
      "Epoch 90/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.1034 - accuracy: 0.2977\n",
      "Epoch 91/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0978 - accuracy: 0.2928\n",
      "Epoch 92/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0982 - accuracy: 0.2969\n",
      "Epoch 93/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0968 - accuracy: 0.2961\n",
      "Epoch 94/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0990 - accuracy: 0.2974\n",
      "Epoch 95/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0988 - accuracy: 0.3015\n",
      "Epoch 96/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0983 - accuracy: 0.2966\n",
      "Epoch 97/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0967 - accuracy: 0.2954\n",
      "Epoch 98/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0957 - accuracy: 0.2993\n",
      "Epoch 99/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0930 - accuracy: 0.3036\n",
      "Epoch 100/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0957 - accuracy: 0.3005\n",
      "Epoch 101/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0919 - accuracy: 0.2964\n",
      "Epoch 102/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0903 - accuracy: 0.3014\n",
      "Epoch 103/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0918 - accuracy: 0.2993\n",
      "Epoch 104/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0972 - accuracy: 0.2975\n",
      "Epoch 105/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0926 - accuracy: 0.2996\n",
      "Epoch 106/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.0898 - accuracy: 0.3028\n",
      "Epoch 107/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.0933 - accuracy: 0.2980\n",
      "Epoch 108/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0922 - accuracy: 0.3056\n",
      "Epoch 109/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0910 - accuracy: 0.3012\n",
      "Epoch 110/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0918 - accuracy: 0.3022\n",
      "Epoch 111/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0894 - accuracy: 0.3053\n",
      "Epoch 112/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0870 - accuracy: 0.3030\n",
      "Epoch 113/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0936 - accuracy: 0.3004\n",
      "Epoch 114/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0894 - accuracy: 0.3057\n",
      "Epoch 115/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0895 - accuracy: 0.3012\n",
      "Epoch 116/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0896 - accuracy: 0.3045\n",
      "Epoch 117/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0890 - accuracy: 0.3048\n",
      "Epoch 118/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0876 - accuracy: 0.3063\n",
      "Epoch 119/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0872 - accuracy: 0.3024\n",
      "Epoch 120/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0859 - accuracy: 0.3058\n",
      "Epoch 121/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0846 - accuracy: 0.3025\n",
      "Epoch 122/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0853 - accuracy: 0.3037\n",
      "Epoch 123/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0869 - accuracy: 0.2993\n",
      "Epoch 124/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0837 - accuracy: 0.3001\n",
      "Epoch 125/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0820 - accuracy: 0.3036\n",
      "Epoch 126/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0826 - accuracy: 0.3040\n",
      "Epoch 127/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0831 - accuracy: 0.3081\n",
      "Epoch 128/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0818 - accuracy: 0.3048\n",
      "Epoch 129/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0812 - accuracy: 0.3031\n",
      "Epoch 130/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0797 - accuracy: 0.3020\n",
      "Epoch 131/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0798 - accuracy: 0.3063\n",
      "Epoch 132/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0805 - accuracy: 0.3007\n",
      "Epoch 133/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0805 - accuracy: 0.3098\n",
      "Epoch 134/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0828 - accuracy: 0.3053\n",
      "Epoch 135/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0802 - accuracy: 0.3098\n",
      "Epoch 136/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0777 - accuracy: 0.3031\n",
      "Epoch 137/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0766 - accuracy: 0.3040\n",
      "Epoch 138/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0756 - accuracy: 0.3070\n",
      "Epoch 139/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0790 - accuracy: 0.3053\n",
      "Epoch 140/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0788 - accuracy: 0.3098\n",
      "Epoch 141/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0785 - accuracy: 0.3071\n",
      "Epoch 142/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0793 - accuracy: 0.3089\n",
      "Epoch 143/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0787 - accuracy: 0.3038\n",
      "Epoch 144/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0789 - accuracy: 0.3036\n",
      "Epoch 145/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0765 - accuracy: 0.3078\n",
      "Epoch 146/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0736 - accuracy: 0.3088\n",
      "Epoch 147/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0752 - accuracy: 0.3140\n",
      "Epoch 148/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0755 - accuracy: 0.3094\n",
      "Epoch 149/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0732 - accuracy: 0.3110\n",
      "Epoch 150/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0736 - accuracy: 0.3055\n",
      "Epoch 151/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0706 - accuracy: 0.3112\n",
      "Epoch 152/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0721 - accuracy: 0.3076\n",
      "Epoch 153/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0721 - accuracy: 0.3122\n",
      "Epoch 154/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0695 - accuracy: 0.3061\n",
      "Epoch 155/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0701 - accuracy: 0.3091\n",
      "Epoch 156/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0705 - accuracy: 0.3086\n",
      "Epoch 157/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0706 - accuracy: 0.3082\n",
      "Epoch 158/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0686 - accuracy: 0.3119\n",
      "Epoch 159/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0692 - accuracy: 0.3136\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0675 - accuracy: 0.3135\n",
      "Epoch 161/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0686 - accuracy: 0.3149\n",
      "Epoch 162/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0664 - accuracy: 0.3076\n",
      "Epoch 163/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0685 - accuracy: 0.3134\n",
      "Epoch 164/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0650 - accuracy: 0.3107\n",
      "Epoch 165/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0635 - accuracy: 0.3104\n",
      "Epoch 166/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0716 - accuracy: 0.3107\n",
      "Epoch 167/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0675 - accuracy: 0.3087\n",
      "Epoch 168/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0632 - accuracy: 0.3100\n",
      "Epoch 169/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0668 - accuracy: 0.3115\n",
      "Epoch 170/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0654 - accuracy: 0.3142\n",
      "Epoch 171/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0606 - accuracy: 0.3166\n",
      "Epoch 172/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0623 - accuracy: 0.3144\n",
      "Epoch 173/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0636 - accuracy: 0.3152\n",
      "Epoch 174/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0604 - accuracy: 0.3159\n",
      "Epoch 175/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0618 - accuracy: 0.3179\n",
      "Epoch 176/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0611 - accuracy: 0.3147\n",
      "Epoch 177/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0650 - accuracy: 0.3120\n",
      "Epoch 178/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0585 - accuracy: 0.3122\n",
      "Epoch 179/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0576 - accuracy: 0.3143\n",
      "Epoch 180/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0677 - accuracy: 0.3096\n",
      "Epoch 181/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0645 - accuracy: 0.3165\n",
      "Epoch 182/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0566 - accuracy: 0.3158\n",
      "Epoch 183/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0611 - accuracy: 0.3146\n",
      "Epoch 184/200\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 2.0564 - accuracy: 0.3154\n",
      "Epoch 185/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0591 - accuracy: 0.3156\n",
      "Epoch 186/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0539 - accuracy: 0.3161\n",
      "Epoch 187/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0562 - accuracy: 0.3171\n",
      "Epoch 188/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.0582 - accuracy: 0.3160\n",
      "Epoch 189/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0543 - accuracy: 0.3161\n",
      "Epoch 190/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0612 - accuracy: 0.3171\n",
      "Epoch 191/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0571 - accuracy: 0.3169\n",
      "Epoch 192/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0525 - accuracy: 0.3186\n",
      "Epoch 193/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0537 - accuracy: 0.3140\n",
      "Epoch 194/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0563 - accuracy: 0.3156\n",
      "Epoch 195/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0555 - accuracy: 0.3174\n",
      "Epoch 196/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0505 - accuracy: 0.3206\n",
      "Epoch 197/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0522 - accuracy: 0.3220\n",
      "Epoch 198/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0515 - accuracy: 0.3189\n",
      "Epoch 199/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0508 - accuracy: 0.3177\n",
      "Epoch 200/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.0536 - accuracy: 0.3186\n",
      "1258/1258 [==============================] - 3s 2ms/step - loss: 40187.5273 - accuracy: 0.0153\n",
      "test loss, test acc: [40187.52734375, 0.015255037695169449]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dim = X_spectral_centroid.shape[1]\n",
    "hidden_layers = [4,2]\n",
    "init_activation = 'relu'\n",
    "activation_funcs = ['relu','relu']\n",
    "optimizer = 'adam'\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = 200\n",
    "(X_spectral_centroid, Y, model) = train_mlp(X_spectral_centroid,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "history = model.fit(X_spectral_centroid,Y,epochs=epochs,)\n",
    "results = model.evaluate(X_spectral_centroid_test,Y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "ab6f84ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.6832 - accuracy: 0.1043\n",
      "Epoch 2/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.5345 - accuracy: 0.1521\n",
      "Epoch 3/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.4514 - accuracy: 0.1557\n",
      "Epoch 4/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.4097 - accuracy: 0.1712\n",
      "Epoch 5/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3837 - accuracy: 0.1773\n",
      "Epoch 6/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3680 - accuracy: 0.1786\n",
      "Epoch 7/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3564 - accuracy: 0.1810\n",
      "Epoch 8/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3486 - accuracy: 0.1865\n",
      "Epoch 9/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3400 - accuracy: 0.1865\n",
      "Epoch 10/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3373 - accuracy: 0.1791\n",
      "Epoch 11/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3321 - accuracy: 0.1877\n",
      "Epoch 12/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3301 - accuracy: 0.1809\n",
      "Epoch 13/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3248 - accuracy: 0.1845\n",
      "Epoch 14/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3225 - accuracy: 0.1893\n",
      "Epoch 15/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3205 - accuracy: 0.1883\n",
      "Epoch 16/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.3181 - accuracy: 0.1829\n",
      "Epoch 17/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3156 - accuracy: 0.1891\n",
      "Epoch 18/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3135 - accuracy: 0.1896\n",
      "Epoch 19/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3141 - accuracy: 0.1862\n",
      "Epoch 20/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.3103 - accuracy: 0.1918\n",
      "Epoch 21/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3093 - accuracy: 0.1919\n",
      "Epoch 22/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3076 - accuracy: 0.1968\n",
      "Epoch 23/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3085 - accuracy: 0.1877\n",
      "Epoch 24/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3063 - accuracy: 0.1903\n",
      "Epoch 25/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3061 - accuracy: 0.1899\n",
      "Epoch 26/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3041 - accuracy: 0.1957\n",
      "Epoch 27/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3038 - accuracy: 0.1925\n",
      "Epoch 28/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3030 - accuracy: 0.1893\n",
      "Epoch 29/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3011 - accuracy: 0.1985\n",
      "Epoch 30/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3009 - accuracy: 0.1922\n",
      "Epoch 31/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.3004 - accuracy: 0.1918\n",
      "Epoch 32/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2999 - accuracy: 0.1983\n",
      "Epoch 33/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2983 - accuracy: 0.1941\n",
      "Epoch 34/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2985 - accuracy: 0.1972\n",
      "Epoch 35/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2975 - accuracy: 0.1951\n",
      "Epoch 36/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2980 - accuracy: 0.1987\n",
      "Epoch 37/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2980 - accuracy: 0.1916\n",
      "Epoch 38/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2935 - accuracy: 0.1986\n",
      "Epoch 39/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2956 - accuracy: 0.1910\n",
      "Epoch 40/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2952 - accuracy: 0.1953\n",
      "Epoch 41/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2938 - accuracy: 0.1985\n",
      "Epoch 42/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2921 - accuracy: 0.1993\n",
      "Epoch 43/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2920 - accuracy: 0.1984\n",
      "Epoch 44/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2920 - accuracy: 0.1962\n",
      "Epoch 45/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2924 - accuracy: 0.1976\n",
      "Epoch 46/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2929 - accuracy: 0.1986\n",
      "Epoch 47/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2900 - accuracy: 0.2011\n",
      "Epoch 48/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2872 - accuracy: 0.1954\n",
      "Epoch 49/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2915 - accuracy: 0.1965\n",
      "Epoch 50/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2885 - accuracy: 0.1957\n",
      "Epoch 51/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2880 - accuracy: 0.1976\n",
      "Epoch 52/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2884 - accuracy: 0.1992\n",
      "Epoch 53/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2860 - accuracy: 0.2013\n",
      "Epoch 54/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2854 - accuracy: 0.2001\n",
      "Epoch 55/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2864 - accuracy: 0.1949\n",
      "Epoch 56/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2846 - accuracy: 0.1992\n",
      "Epoch 57/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2844 - accuracy: 0.2021\n",
      "Epoch 58/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2850 - accuracy: 0.1956\n",
      "Epoch 59/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2837 - accuracy: 0.1980\n",
      "Epoch 60/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2831 - accuracy: 0.2022\n",
      "Epoch 61/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2826 - accuracy: 0.1966\n",
      "Epoch 62/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2831 - accuracy: 0.2024\n",
      "Epoch 63/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2849 - accuracy: 0.1927\n",
      "Epoch 64/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2827 - accuracy: 0.1976\n",
      "Epoch 65/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2813 - accuracy: 0.1966\n",
      "Epoch 66/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2793 - accuracy: 0.2057\n",
      "Epoch 67/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2833 - accuracy: 0.1946\n",
      "Epoch 68/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2805 - accuracy: 0.1987\n",
      "Epoch 69/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2798 - accuracy: 0.2003\n",
      "Epoch 70/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2775 - accuracy: 0.2019\n",
      "Epoch 71/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2808 - accuracy: 0.1980\n",
      "Epoch 72/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2804 - accuracy: 0.1935\n",
      "Epoch 73/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2772 - accuracy: 0.2033\n",
      "Epoch 74/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2771 - accuracy: 0.1997\n",
      "Epoch 75/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2771 - accuracy: 0.2036\n",
      "Epoch 76/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2758 - accuracy: 0.2046\n",
      "Epoch 77/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2765 - accuracy: 0.1990\n",
      "Epoch 78/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2772 - accuracy: 0.1973\n",
      "Epoch 79/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2758 - accuracy: 0.2000\n",
      "Epoch 80/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2765 - accuracy: 0.1996\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2750 - accuracy: 0.1963\n",
      "Epoch 82/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2743 - accuracy: 0.1952\n",
      "Epoch 83/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2730 - accuracy: 0.1973\n",
      "Epoch 84/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2740 - accuracy: 0.2009\n",
      "Epoch 85/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2737 - accuracy: 0.1992\n",
      "Epoch 86/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2756 - accuracy: 0.1997\n",
      "Epoch 87/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2740 - accuracy: 0.2037\n",
      "Epoch 88/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2729 - accuracy: 0.1963\n",
      "Epoch 89/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2719 - accuracy: 0.2010\n",
      "Epoch 90/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2718 - accuracy: 0.1983\n",
      "Epoch 91/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2723 - accuracy: 0.2014\n",
      "Epoch 92/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2701 - accuracy: 0.1965\n",
      "Epoch 93/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2704 - accuracy: 0.2024\n",
      "Epoch 94/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2712 - accuracy: 0.2034\n",
      "Epoch 95/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2698 - accuracy: 0.2010\n",
      "Epoch 96/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2698 - accuracy: 0.1998\n",
      "Epoch 97/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2707 - accuracy: 0.2010\n",
      "Epoch 98/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2681 - accuracy: 0.2067\n",
      "Epoch 99/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2701 - accuracy: 0.1987\n",
      "Epoch 100/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2692 - accuracy: 0.1938\n",
      "Epoch 101/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2676 - accuracy: 0.2038\n",
      "Epoch 102/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2668 - accuracy: 0.1991\n",
      "Epoch 103/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2681 - accuracy: 0.1976\n",
      "Epoch 104/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2694 - accuracy: 0.2033\n",
      "Epoch 105/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2662 - accuracy: 0.2033\n",
      "Epoch 106/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2663 - accuracy: 0.1997\n",
      "Epoch 107/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2662 - accuracy: 0.2076\n",
      "Epoch 108/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2665 - accuracy: 0.2059\n",
      "Epoch 109/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2674 - accuracy: 0.1965\n",
      "Epoch 110/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2650 - accuracy: 0.2015\n",
      "Epoch 111/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2657 - accuracy: 0.2031\n",
      "Epoch 112/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2656 - accuracy: 0.2040\n",
      "Epoch 113/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2647 - accuracy: 0.2009\n",
      "Epoch 114/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2643 - accuracy: 0.2036\n",
      "Epoch 115/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2652 - accuracy: 0.2008\n",
      "Epoch 116/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2649 - accuracy: 0.2050\n",
      "Epoch 117/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2646 - accuracy: 0.2002\n",
      "Epoch 118/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2622 - accuracy: 0.2026\n",
      "Epoch 119/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2640 - accuracy: 0.1988\n",
      "Epoch 120/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2640 - accuracy: 0.1978\n",
      "Epoch 121/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2639 - accuracy: 0.2045\n",
      "Epoch 122/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2626 - accuracy: 0.1995\n",
      "Epoch 123/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2629 - accuracy: 0.2034\n",
      "Epoch 124/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2636 - accuracy: 0.1996\n",
      "Epoch 125/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2622 - accuracy: 0.2049\n",
      "Epoch 126/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2621 - accuracy: 0.1981\n",
      "Epoch 127/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2608 - accuracy: 0.2053\n",
      "Epoch 128/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2606 - accuracy: 0.2063\n",
      "Epoch 129/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2627 - accuracy: 0.2004\n",
      "Epoch 130/200\n",
      "293/293 [==============================] - 2s 6ms/step - loss: 2.2607 - accuracy: 0.2027\n",
      "Epoch 131/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2608 - accuracy: 0.1968\n",
      "Epoch 132/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2635 - accuracy: 0.2037\n",
      "Epoch 133/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2581 - accuracy: 0.2021\n",
      "Epoch 134/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2592 - accuracy: 0.1962\n",
      "Epoch 135/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2597 - accuracy: 0.2049\n",
      "Epoch 136/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2603 - accuracy: 0.1968\n",
      "Epoch 137/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2593 - accuracy: 0.2012\n",
      "Epoch 138/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2595 - accuracy: 0.2030\n",
      "Epoch 139/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2569 - accuracy: 0.2086\n",
      "Epoch 140/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2577 - accuracy: 0.2009\n",
      "Epoch 141/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2592 - accuracy: 0.2015\n",
      "Epoch 142/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2598 - accuracy: 0.2039\n",
      "Epoch 143/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2571 - accuracy: 0.2030\n",
      "Epoch 144/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2565 - accuracy: 0.2057\n",
      "Epoch 145/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2580 - accuracy: 0.2075\n",
      "Epoch 146/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2554 - accuracy: 0.2054\n",
      "Epoch 147/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2564 - accuracy: 0.2055\n",
      "Epoch 148/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2559 - accuracy: 0.2033\n",
      "Epoch 149/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2600 - accuracy: 0.2022\n",
      "Epoch 150/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2578 - accuracy: 0.1975\n",
      "Epoch 151/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2553 - accuracy: 0.2000\n",
      "Epoch 152/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2594 - accuracy: 0.2012\n",
      "Epoch 153/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2557 - accuracy: 0.1969\n",
      "Epoch 154/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2549 - accuracy: 0.2007\n",
      "Epoch 155/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2549 - accuracy: 0.2056\n",
      "Epoch 156/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2532 - accuracy: 0.2060\n",
      "Epoch 157/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2544 - accuracy: 0.2076\n",
      "Epoch 158/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2532 - accuracy: 0.2067\n",
      "Epoch 159/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2529 - accuracy: 0.2057\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 1s 5ms/step - loss: 2.2534 - accuracy: 0.2040\n",
      "Epoch 161/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2547 - accuracy: 0.2029\n",
      "Epoch 162/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2528 - accuracy: 0.2030\n",
      "Epoch 163/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2520 - accuracy: 0.2067\n",
      "Epoch 164/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2516 - accuracy: 0.2042\n",
      "Epoch 165/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2515 - accuracy: 0.2048\n",
      "Epoch 166/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2537 - accuracy: 0.2000\n",
      "Epoch 167/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2513 - accuracy: 0.2060\n",
      "Epoch 168/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2501 - accuracy: 0.2064\n",
      "Epoch 169/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2541 - accuracy: 0.2032\n",
      "Epoch 170/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2510 - accuracy: 0.2045\n",
      "Epoch 171/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2508 - accuracy: 0.2092\n",
      "Epoch 172/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2513 - accuracy: 0.2050\n",
      "Epoch 173/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2497 - accuracy: 0.2012\n",
      "Epoch 174/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2492 - accuracy: 0.2105\n",
      "Epoch 175/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2498 - accuracy: 0.2023\n",
      "Epoch 176/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2490 - accuracy: 0.2070\n",
      "Epoch 177/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2471 - accuracy: 0.1982\n",
      "Epoch 178/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2553 - accuracy: 0.2054\n",
      "Epoch 179/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2508 - accuracy: 0.2036\n",
      "Epoch 180/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2481 - accuracy: 0.2072\n",
      "Epoch 181/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2474 - accuracy: 0.2136\n",
      "Epoch 182/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2463 - accuracy: 0.2039\n",
      "Epoch 183/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2491 - accuracy: 0.2107\n",
      "Epoch 184/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2483 - accuracy: 0.2030\n",
      "Epoch 185/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2478 - accuracy: 0.2052\n",
      "Epoch 186/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2492 - accuracy: 0.2045\n",
      "Epoch 187/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2485 - accuracy: 0.2040\n",
      "Epoch 188/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2460 - accuracy: 0.2046\n",
      "Epoch 189/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2482 - accuracy: 0.2032\n",
      "Epoch 190/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2453 - accuracy: 0.2077\n",
      "Epoch 191/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2450 - accuracy: 0.2052\n",
      "Epoch 192/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2465 - accuracy: 0.2071\n",
      "Epoch 193/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2463 - accuracy: 0.2050\n",
      "Epoch 194/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2474 - accuracy: 0.2080\n",
      "Epoch 195/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2481 - accuracy: 0.2063\n",
      "Epoch 196/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2466 - accuracy: 0.2094\n",
      "Epoch 197/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2443 - accuracy: 0.2100\n",
      "Epoch 198/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2445 - accuracy: 0.2098\n",
      "Epoch 199/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2447 - accuracy: 0.2074\n",
      "Epoch 200/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.2471 - accuracy: 0.2088\n",
      "1258/1258 [==============================] - 3s 2ms/step - loss: 2815.1785 - accuracy: 0.0063\n",
      "test loss, test acc: [2815.178466796875, 0.0062610250897705555]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dim = X_spectral_bandwidth.shape[1]\n",
    "hidden_layers = [4,2]\n",
    "init_activation = 'relu'\n",
    "activation_funcs = ['relu','relu']\n",
    "optimizer = 'adam'\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = 200\n",
    "(X_spectral_bandwidth, Y, model) = train_mlp(X_spectral_bandwidth,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "history = model.fit(X_spectral_bandwidth,Y,epochs=epochs,)\n",
    "results = model.evaluate(X_spectral_bandwidth_test,Y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "807cab31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.7116 - accuracy: 0.1069\n",
      "Epoch 2/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.6226 - accuracy: 0.0992\n",
      "Epoch 3/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.5700 - accuracy: 0.1054\n",
      "Epoch 4/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.5384 - accuracy: 0.1019\n",
      "Epoch 5/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.5188 - accuracy: 0.1028\n",
      "Epoch 6/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.5063 - accuracy: 0.1040\n",
      "Epoch 7/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.4980 - accuracy: 0.0998\n",
      "Epoch 8/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.4923 - accuracy: 0.1023\n",
      "Epoch 9/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.4881 - accuracy: 0.1029\n",
      "Epoch 10/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.4852 - accuracy: 0.1059\n",
      "Epoch 11/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.4830 - accuracy: 0.1031\n",
      "Epoch 12/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.4814 - accuracy: 0.1053\n",
      "Epoch 13/200\n",
      "293/293 [==============================] - 1s 3ms/step - loss: 2.4802 - accuracy: 0.1040\n",
      "Epoch 14/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4793 - accuracy: 0.1015\n",
      "Epoch 15/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4786 - accuracy: 0.1053\n",
      "Epoch 16/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4780 - accuracy: 0.1010\n",
      "Epoch 17/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4776 - accuracy: 0.1020\n",
      "Epoch 18/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4772 - accuracy: 0.1012\n",
      "Epoch 19/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4770 - accuracy: 0.1014\n",
      "Epoch 20/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4767 - accuracy: 0.0980\n",
      "Epoch 21/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4766 - accuracy: 0.0978\n",
      "Epoch 22/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4764 - accuracy: 0.1027\n",
      "Epoch 23/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4763 - accuracy: 0.1053\n",
      "Epoch 24/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4762 - accuracy: 0.1018\n",
      "Epoch 25/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4762 - accuracy: 0.0988\n",
      "Epoch 26/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4761 - accuracy: 0.1048\n",
      "Epoch 27/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4761 - accuracy: 0.1029\n",
      "Epoch 28/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4760 - accuracy: 0.1015\n",
      "Epoch 29/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4760 - accuracy: 0.0968\n",
      "Epoch 30/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4760 - accuracy: 0.1047\n",
      "Epoch 31/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1040\n",
      "Epoch 32/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1018\n",
      "Epoch 33/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4759 - accuracy: 0.1011\n",
      "Epoch 34/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.0963\n",
      "Epoch 35/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1014\n",
      "Epoch 36/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1002\n",
      "Epoch 37/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1056\n",
      "Epoch 38/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1027\n",
      "Epoch 39/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1038\n",
      "Epoch 40/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.0976\n",
      "Epoch 41/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1049\n",
      "Epoch 42/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1008\n",
      "Epoch 43/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1041\n",
      "Epoch 44/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1014\n",
      "Epoch 45/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0999\n",
      "Epoch 46/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1030\n",
      "Epoch 47/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4759 - accuracy: 0.1028\n",
      "Epoch 48/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1015\n",
      "Epoch 49/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0987\n",
      "Epoch 50/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1025\n",
      "Epoch 51/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1024\n",
      "Epoch 52/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1038\n",
      "Epoch 53/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4759 - accuracy: 0.1019\n",
      "Epoch 54/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4759 - accuracy: 0.0987\n",
      "Epoch 55/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1015\n",
      "Epoch 56/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1011\n",
      "Epoch 57/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1011\n",
      "Epoch 58/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4759 - accuracy: 0.1034\n",
      "Epoch 59/200\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 2.4758 - accuracy: 0.1030\n",
      "Epoch 60/200\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 2.4758 - accuracy: 0.0992\n",
      "Epoch 61/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1013\n",
      "Epoch 62/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1038\n",
      "Epoch 63/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0978\n",
      "Epoch 64/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1017\n",
      "Epoch 65/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1021\n",
      "Epoch 66/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4759 - accuracy: 0.1017\n",
      "Epoch 67/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1031\n",
      "Epoch 68/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1021\n",
      "Epoch 69/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1054\n",
      "Epoch 70/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1042\n",
      "Epoch 71/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0995\n",
      "Epoch 72/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1000\n",
      "Epoch 73/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1042\n",
      "Epoch 74/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1058\n",
      "Epoch 75/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1013\n",
      "Epoch 76/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1011\n",
      "Epoch 77/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1002\n",
      "Epoch 78/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.0973\n",
      "Epoch 79/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1046\n",
      "Epoch 80/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0972\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0977\n",
      "Epoch 82/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1021\n",
      "Epoch 83/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1010\n",
      "Epoch 84/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1027\n",
      "Epoch 85/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1023\n",
      "Epoch 86/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1058\n",
      "Epoch 87/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1020\n",
      "Epoch 88/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1040\n",
      "Epoch 89/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1050\n",
      "Epoch 90/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1033\n",
      "Epoch 91/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.0984\n",
      "Epoch 92/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1015\n",
      "Epoch 93/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1061\n",
      "Epoch 94/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0957\n",
      "Epoch 95/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1031\n",
      "Epoch 96/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1065\n",
      "Epoch 97/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1017\n",
      "Epoch 98/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1025\n",
      "Epoch 99/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1008\n",
      "Epoch 100/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1013\n",
      "Epoch 101/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1029\n",
      "Epoch 102/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0972\n",
      "Epoch 103/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4759 - accuracy: 0.1042\n",
      "Epoch 104/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1039\n",
      "Epoch 105/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1005\n",
      "Epoch 106/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1025\n",
      "Epoch 107/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1030\n",
      "Epoch 108/200\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 2.4758 - accuracy: 0.1024\n",
      "Epoch 109/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1042\n",
      "Epoch 110/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.0979\n",
      "Epoch 111/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.0987\n",
      "Epoch 112/200\n",
      "293/293 [==============================] - 2s 5ms/step - loss: 2.4758 - accuracy: 0.1023\n",
      "Epoch 113/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4759 - accuracy: 0.1025\n",
      "Epoch 114/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.0997\n",
      "Epoch 115/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1010\n",
      "Epoch 116/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1025\n",
      "Epoch 117/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1016\n",
      "Epoch 118/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1007\n",
      "Epoch 119/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1025\n",
      "Epoch 120/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1000\n",
      "Epoch 121/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1030\n",
      "Epoch 122/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1018\n",
      "Epoch 123/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0996\n",
      "Epoch 124/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1042\n",
      "Epoch 125/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1008\n",
      "Epoch 126/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1026\n",
      "Epoch 127/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1032\n",
      "Epoch 128/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0981\n",
      "Epoch 129/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1013\n",
      "Epoch 130/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0979\n",
      "Epoch 131/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1031\n",
      "Epoch 132/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1021\n",
      "Epoch 133/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1049\n",
      "Epoch 134/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1003\n",
      "Epoch 135/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1009\n",
      "Epoch 136/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1020\n",
      "Epoch 137/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1018\n",
      "Epoch 138/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0999\n",
      "Epoch 139/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0994\n",
      "Epoch 140/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1011\n",
      "Epoch 141/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1029\n",
      "Epoch 142/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1015\n",
      "Epoch 143/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1017\n",
      "Epoch 144/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.0977\n",
      "Epoch 145/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1013\n",
      "Epoch 146/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4759 - accuracy: 0.1025\n",
      "Epoch 147/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1031\n",
      "Epoch 148/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1026\n",
      "Epoch 149/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0971\n",
      "Epoch 150/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0968\n",
      "Epoch 151/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0983\n",
      "Epoch 152/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1046\n",
      "Epoch 153/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1035\n",
      "Epoch 154/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0976\n",
      "Epoch 155/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1040\n",
      "Epoch 156/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1018\n",
      "Epoch 157/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1055\n",
      "Epoch 158/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1045\n",
      "Epoch 159/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1028\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1049\n",
      "Epoch 161/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1026\n",
      "Epoch 162/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1009\n",
      "Epoch 163/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1007\n",
      "Epoch 164/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1032\n",
      "Epoch 165/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1003\n",
      "Epoch 166/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1025\n",
      "Epoch 167/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1016\n",
      "Epoch 168/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1017\n",
      "Epoch 169/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1046\n",
      "Epoch 170/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1054\n",
      "Epoch 171/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1001\n",
      "Epoch 172/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1004\n",
      "Epoch 173/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1010\n",
      "Epoch 174/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1045\n",
      "Epoch 175/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1017\n",
      "Epoch 176/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1012\n",
      "Epoch 177/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0985\n",
      "Epoch 178/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1017\n",
      "Epoch 179/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1024\n",
      "Epoch 180/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.0988\n",
      "Epoch 181/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1069\n",
      "Epoch 182/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1019\n",
      "Epoch 183/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1015\n",
      "Epoch 184/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1010\n",
      "Epoch 185/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.0983\n",
      "Epoch 186/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1034\n",
      "Epoch 187/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1032\n",
      "Epoch 188/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1051\n",
      "Epoch 189/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1028\n",
      "Epoch 190/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1035\n",
      "Epoch 191/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1039\n",
      "Epoch 192/200\n",
      "293/293 [==============================] - 1s 5ms/step - loss: 2.4758 - accuracy: 0.1016\n",
      "Epoch 193/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1049\n",
      "Epoch 194/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1034\n",
      "Epoch 195/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4759 - accuracy: 0.1034\n",
      "Epoch 196/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1008\n",
      "Epoch 197/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1062\n",
      "Epoch 198/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.0977\n",
      "Epoch 199/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1071\n",
      "Epoch 200/200\n",
      "293/293 [==============================] - 1s 4ms/step - loss: 2.4758 - accuracy: 0.1053\n",
      "1258/1258 [==============================] - 3s 2ms/step - loss: 2.2909 - accuracy: 0.0331\n",
      "test loss, test acc: [2.2909414768218994, 0.03306914493441582]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dim = X_rmse.shape[1]\n",
    "hidden_layers = [4,2]\n",
    "init_activation = 'relu'\n",
    "activation_funcs = ['relu','relu']\n",
    "optimizer = 'adam'\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = 200\n",
    "(X_rmse, Y, model) = train_mlp(X_rmse,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "history = model.fit(X_rmse,Y,epochs=epochs,)\n",
    "results = model.evaluate(X_rmse_test,Y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "7f6ebe7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we do mfcc, acknowledging the subintervals\n",
    "start = 0\n",
    "increment = 20\n",
    "#kurtosis, max, mean, medain, min, skew, std\n",
    " \n",
    "#X_mfcc_collapse_kurtosis = np.average(X_mfcc[:,0::increment])\n",
    "# ABOVE IS WRONG\n",
    "\n",
    "X_mfcc_collapse_kurtosis = np.average(X_mfcc[:,start:start+increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "X_mfcc_test_collapse_kurtosis = np.average(X_mfcc_test[:,start:start+increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "X_mfcc_collapse_max = np.average(X_mfcc[:,start+increment:start+2*increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "X_mfcc_test_collapse_max = np.average(X_mfcc_test[:,start+increment:start+2*increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "X_mfcc_collapse_mean = np.average(X_mfcc[:,start+2*increment:start+3*increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "X_mfcc_test_collapse_mean = np.average(X_mfcc_test[:,start+2*increment:start+3*increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "X_mfcc_collapse_median = np.average(X_mfcc[:,start+3*increment:start+4*increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "X_mfcc_test_collapse_median = np.average(X_mfcc_test[:,start+3*increment:start+4*increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "X_mfcc_collapse_min = np.average(X_mfcc[:,start+4*increment:start+5*increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "X_mfcc_test_collapse_min = np.average(X_mfcc_test[:,start+4*increment:start+5*increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "X_mfcc_collapse_skew = np.average(X_mfcc[:,start+5*increment:start+6*increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "X_mfcc_test_collapse_skew = np.average(X_mfcc_test[:,start+5*increment:start+6*increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "X_mfcc_collapse_std = np.average(X_mfcc[:,start+6*increment:start+7*increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "X_mfcc_test_collapse_std = np.average(X_mfcc_test[:,start+6*increment:start+7*increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "\n",
    "#X_mfcc_collapse_kurtosis = np.average(X_mfcc[:,start:start+increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "#X_mfcc_test_collapse_kurtosis = np.average(X_mfcc_test[:,start:start+increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "#X_mfcc_collapse_max = np.average(X_mfcc[:,start+increment:start+2*increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "#X_mfcc_test_collapse_max = np.average(X_mfcc_test[:,start+increment:start+2*increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "#X_mfcc_collapse_mean = np.average(X_mfcc[:,start+2*increment:start+3*increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "#X_mfcc_test_collapse_mean = np.average(X_mfcc_test[:,start+2*increment:start+3*increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "#X_mfcc_collapse_median = np.average(X_mfcc[:,start+3*increment:start+4*increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "#X_mfcc_test_collapse_median = np.average(X_mfcc_test[:,start+3*increment:start+4*increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "#X_mfcc_collapse_min = np.average(X_mfcc[:,start+4*increment:start+5*increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "#X_mfcc_test_collapse_min = np.average(X_mfcc_test[:,start+4*increment:start+5*increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "#X_mfcc_collapse_skew = np.average(X_mfcc[:,start+5*increment:start+6*increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "#X_mfcc_test_collapse_skew = np.average(X_mfcc_test[:,start+5*increment:start+6*increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "#X_mfcc_collapse_std = np.average(X_mfcc[:,start+6*increment:start+7*increment],axis=1).reshape(X_mfcc.shape[0],1)\n",
    "#X_mfcc_test_collapse_std = np.average(X_mfcc_test[:,start+6*increment:start+7*increment],axis=1).reshape(X_mfcc_test.shape[0],1)\n",
    "\n",
    "X_mfcc_merge = np.concatenate([X_mfcc_collapse_kurtosis,X_mfcc_collapse_max,\n",
    "                                 X_mfcc_collapse_mean,X_mfcc_collapse_median,\n",
    "                                 X_mfcc_collapse_min, X_mfcc_collapse_skew,\n",
    "                                 X_mfcc_collapse_std],axis=1)\n",
    "X_mfcc_merge_test = np.concatenate([X_mfcc_test_collapse_kurtosis,X_mfcc_test_collapse_max,\n",
    "                                 X_mfcc_test_collapse_mean,X_mfcc_test_collapse_median,\n",
    "                                 X_mfcc_test_collapse_min, X_mfcc_test_collapse_skew,\n",
    "                                 X_mfcc_test_collapse_std],axis=1)     \n",
    "#print(X_tonnetz_merge.shape)\n",
    "#print(X_tonnetz_merge_test.shape)\n",
    "#print(7*increment)\n",
    "#print(X_tonnetz.shape)\n",
    "\n",
    "#print(X_tonnetz[:,start:start+increment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "d60b1ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "293/293 [==============================] - 6s 15ms/step - loss: 2.0968 - accuracy: 0.3332\n",
      "Epoch 2/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 1.7646 - accuracy: 0.4307\n",
      "Epoch 3/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 1.6572 - accuracy: 0.4623\n",
      "Epoch 4/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 1.5891 - accuracy: 0.4809\n",
      "Epoch 5/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 1.5468 - accuracy: 0.4970\n",
      "Epoch 6/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 1.4807 - accuracy: 0.5207\n",
      "Epoch 7/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 1.4360 - accuracy: 0.5283\n",
      "Epoch 8/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 1.3920 - accuracy: 0.5389\n",
      "Epoch 9/20\n",
      "293/293 [==============================] - 5s 16ms/step - loss: 1.3381 - accuracy: 0.5582\n",
      "Epoch 10/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 1.2887 - accuracy: 0.5677\n",
      "Epoch 11/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 1.2299 - accuracy: 0.5864\n",
      "Epoch 12/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 1.1991 - accuracy: 0.6002\n",
      "Epoch 13/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 1.1513 - accuracy: 0.6150\n",
      "Epoch 14/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 1.1129 - accuracy: 0.6226\n",
      "Epoch 15/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 1.0648 - accuracy: 0.6388\n",
      "Epoch 16/20\n",
      "293/293 [==============================] - 5s 15ms/step - loss: 1.0245 - accuracy: 0.6576\n",
      "Epoch 17/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 0.9585 - accuracy: 0.6740\n",
      "Epoch 18/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 0.9263 - accuracy: 0.6861\n",
      "Epoch 19/20\n",
      "293/293 [==============================] - 4s 15ms/step - loss: 0.8746 - accuracy: 0.7061\n",
      "Epoch 20/20\n",
      "293/293 [==============================] - 5s 15ms/step - loss: 0.8342 - accuracy: 0.7193\n",
      "1258/1258 [==============================] - 10s 7ms/step - loss: 441.9711 - accuracy: 0.0378\n",
      "test loss, test acc: [441.97113037109375, 0.03781460225582123]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeMAAAEzCAYAAAACSWsXAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAABwR0lEQVR4nO2dd3xb1fn/30fDlve2YydOYmeShOxFgAz2KFBaRilltUBpofy6KHTT0s23e1HassoIlL0pI2ElIYHsvbeTeG/LlnR+fxxdWbJlW7bl/bxfL79kXd17dY6udD/nec7zPEdprREEQRAEoe+w9XUDBEEQBGGoI2IsCIIgCH2MiLEgCIIg9DEixoIgCILQx4gYC4IgCEIfI2IsCIIgCH1Mh2KslHpAKXVCKbW5jdeVUupPSqndSqmNSqmZ0W+mIAiCIAxeIrGMHwLOa+f184Fx/r+bgb93v1mCIAiCMHToUIy11u8BZe3scgnwiDasAlKVUrnRaqAgCIIgDHaiMWc8HDgU9Pywf5sgCIIgCBHgiMI5VJhtYWtsKqVuxriyiYuLm5Wfnx+Ftzf4fD5strbHFo1eOFrrIzteEe8I1+T+Q0d9GUhIX3oGh6eGWHc5oKmLH4FWnWtXT/dFaR8ohQ57e4guLfuitNf/eYS+t8NTi8/mxGeL6fE2tYfSXhzeOpocibRsY1evi9IetOr4dm7zedBKoZU99Hg0Nm8Ddq8brz0Wrz0u7PF2nxu7pxZQ+GwxeBwJbe4X01CKQqOVjQZXVkTtC3surxsAn80R0m6Hpxa7tx6brwmPI5EmZ1KXzh8J0fy97Ny5s0RrndVyezTE+DAQrKojgKPhdtRa3w/cDzB79mz98ccfR+HtDcuXL2fx4sVtvn6orI7Tf7OM31w2lStmR28Q0BN01JeBRL/qS20pPHsjlOyC616E9MJOHd7tvmx5DrImQvZJXT8HwDM3waanIG08lO+HORfDhb/t1CkCfSnZDev+AwdXwsxrYdrnoTM3nY/uh6QcmHhR83ENlfC3U6CpDubfCvO+DK7kts9RvBNW/BE8brj4z+AMLwQd9kVreOceeP+3YI+B3Glw7i8hfw68dTd88HtzQPJw+PxTMGxK2yetr4DDa8x3JGOM2VZxyGwr3gGjToHCxe03rGwv+HyQOTZ0u3X90nNg/lfBXQ0VB6D8ABWlxaRe/icYMavjjrurYfX9sPG/ULwNUkfCvK/A7BvCf4Ylu+D+xea6FCyE075h+lB9HB44F8qPm/3S8+D2da2PX/8EvPT/wNtoNQA+/28Yf27ofpVH4J9LaHSnETNiuvnMcgrg+lfAERu6b0Ml/O+HUH0M7E5Y9B1z3QCObYL//QD2Lm/ef/hs079NT8PeZeCMB2eq6dOtb0Fqvnl/RywkZDYfV30M3rsXyvbBiDlw0qdg2MnmNZ8PKg+BsoGvydwnYuIhZ3Lg8Gjex5RSB8Jtj4YYvwjcppRaCswDKrXWRVE4b1RJjnMCUFXf1MctEfqE41vg8c9BzXFzo3r4YrjhVXMD6w4+X/ONMLadkfnG/5qBgLLDKV+FhXeAK6Xz77f5GXMjP+0bcMYPzc1q1d/gpIuhcFHnzrVhKTx3i7kJpY2CF26FdY/C5x6H+PTQPq6+HyZ/GpKGNW8/sAJeu8P8nz0Jzv+1ucm/9ROoLjL/L/sZHPgQrn0+9L0PrIBPHjLCVrTB3Dw9bqgtMe9/fDN4Gsw5ADY+Zfr5hWdD22ahNbz1Y/jwj3Dy5ZCUC1ueh4cuhCmfhQ2Pw4xrIH8uvHYnfPJg+AHMgRXwzs/M4ET7AAUTLoDGGtj3bvN+yg5X/gcmXtj6HJuehg//YMQkJgn+3wZIyDCv1ZbA1udhzJlQeRhe/bbZHp8BaaOJqy+CB86Bs+42A5lwAyOtzcDuje9D9VEYuQDO/BHsehPe+C5sfQGufir0+9VYB09dZz7nuTfDpv/CI5+Gxd+FbS+Z38UVj8CxzfDeb4x4BV/rVX+H1++C0afD5Q+Z39C/z4HnvwpfWWEGZNb7LP08NNaxfvovmHvhteY6/Pc6ePUOuPhPoX15/3ew9hEjjJWH4ZFL4LqXYPdb8PY9ZhB37i8gbbT5rqz7j/mexiTBBf8Hs78IVUfgr/PMdZ13Myz9AsQkmPOkF5pB2Ae/A28TZIyFd39tnl/xCIw8BZ78Aux/v/XnPPtLcM7PjDD3Ah2KsVLqCWAxkKmUOgz8GHACaK3vA14FLgB2A3XADT3V2O6QFOtAKahq8PR1U4YWWhvL5/gmmPRpsNk7PCTqNFQaIfY1wRdfA5sTHr4IHv0s3LoaVCdcqT6vEZeqo1C6GzY8CZUHjaANmwqf/XdrS6hsL7z8DcifB1kTYMWfYc2/jUgsvMMIYSRUH4NXvgXDZ8GSH5jP8owfws434KXb4bZPwB7mJ334E2MtXvhbSDaxlUlVu+D978Po00ybE7Jg/aPG8vngd+YmZLHnHXj9TjixNfRm+u6vzXFn/xTe/Y25kc7+Inz8b2PxnfdLI45v/siI3KgF5rj6cnPDRhkraNGdMPcm2Pk6vHAb/Ho0eN3m9etfMd6EV++Ahgp4+6dw0R9Cumfzus2gYuNSmHMjnH+vEbHTvgFPXWuEePz58Kk/mM9n+6tGuLRuvvZeDzz3Zdj8NCTlmesy8hRzrdf8ywy0Fn8PJpxnLOvHr4D/Xg8X/g7GnW2Ey9tkBHL1P4y4LLrLCNuHv2/+PNc9aizLc38OGeOMZyNpGMQmArDmzZc5rfQJM8ja8Zr5bNY+YgT85Ctg/i2w7Jew8zXz2V3xiLH8AU7/Fmx+Fp69GR76FFz9tBFJnxde+Sac2AJXPwPjzoKF34YXvwbLfwE2B3z+SRh7FqSMMG0+8KH5foIR2Hd/A4VL4Or/GgsWzPfm/kXwzJfgsgfMeZZ+3gyurlpKXZHL7Df501D0TfO9yptuviNgPA2r/g5Tr4TP/MNYrQ9eYKx3n8fcLy76A8Slmf0nXginfh0OrYK0gsB3mdSR5nN668fmO5Q5DurK4KELzGtHPoFJl5gBTnqhGRA9dhk8eY3pb+VhOPPH5rusbOZx37uw8i/m8Zrn2/pFRhetdZ/8zZo1S0eTZcuWdbjPlB+/rn/8wuaovm9PEElfBgRH1unaX03U+sfJ5m/90t57b3et1nXl5v9nv6z13alaH/yo+fW1/zFtOrq+9bEndmj99Je0/t1krY9vDWxe9cpjWv/rnOb+/DhF64cv0frjh7R+5+da/3y41k9dH3our0frfyzW+pf5WpcfMNuOrNP6+Vu1vidH67/M07qxXmufT+tV/9B69T+1bnK3blNdudb/Olvre7JN+4LZ9rJpz6Znwn8WD15oXv/bqVrXV2h9dL1u+HmB1r+bonVNSei+T9+o9c9yQ7c/fpU5/p5srWtLzbYDq8y2D/9knjdUab30arPtd5O1bqg22921Wv9mjNYPXdR8vte+az67oo2t27p+qfns1y/V+o/TzbmevlHru9O0fuLz5rhDa5r3L96lq+6dbrYv/7X5HIPxNGq99SWtG+uat63+p2ln8c7mbe/8wmx7+x7T5mB8vtbnrS3V+u+nNn8XfprZ/P9r39Xa02T2e/bL5nOrPKq116v1H6Zq/e/zWvfbz7Jly8x7rf2P1r/I93/uOVo/ea3WP8lovg4f/tl8t8Kx801zzK8LtV7/hNYPX2yOW/bL1v365BGzf+DzatL653lav/zNoM/rX+b4/R+2fq+1/9H6J+nmmN9N0fqnWVpverq5LxZej9b/+azpw4GVzZ/NT7O0Lj/YvF/JbvM9/+j+1p95e3gatb5/ifme1ZWZ38i9483vzt+eEOrKtf7nmVr/YoTWe98Nf849y7Ve+gWtPY1RvScDH+swmhgNN/WAIdnlpKpB3NS9QuVhePxKbD6Pscg+/BOsfwymXdnxsT4f1JWaOR/LcjnyCVQVmZFs9knG3VZ5BJ6+wcwBnfvz5uO1hieuhP0fGOvh6DpY+B3jorQY55/n2vm/5jkqgB2vwxOfM3NRjlh4/Eq48S3Y/AyzP/4RxMSZec1Rp0JidqhruqnejKbLf2zcamAsmqNr4dL7m13iedPhkr+Y0fpjlxlXrivVzHeCsSYXfgemXuHv52F47Aoo2Qmf/RdkjQ/9vMafb0b8K/8Cky8NtfSPrDUuuJMuhh2vGndedRE2RyJ87vlm96nF6d8ybvCP/g5n/MB8xjtfgwkXwo5XjGv51K8biyo+s9nKiU2CK/4D6x83VqHf0iMmHk79f8bS2/eesTpX3w8zr2meswtm2pXN35H0QjOXuekpY2kv+R78ZQ48/xXjQqwrhQ//gEs5jWXXcu4SjBV30qdCt4092zzuetNYUQdXGWtw6udMn1sSznMSnw43LTNW4MFVUHsCHC7jtQhux6I7jUv45W+Y/pTvN96M9lAKZnzBuLJ3vGrc5Mm5ULrHWMkzvmDa3RbjzoKblxkL+bkvgz3WfGdnXtv6fWZeE7rN7jAenAMrzHOfz0wP5M0wnoKWzPgC5M83Vunhj+HaF8x8ektsdvPd/ecS85tKyILSXea7lBoUw5MxBr70v/Y/n3DYnfClt5rd+nFp8NWV5v9w0xpxqXDD69BU2/Z0UeGizk/9dIOhJcZxTqrqxU3d4/iFmKY6Nk79OXPnXGuCIpb/EioOtj1PW19uglsOrjRzdFOvhE/fZ9ykj11GIEg/McfcWNY9auYmj6yFBV9rnuPa9575G3++eb+CRSYwJJjELMibCbvegEV3NG9f+zAk58GX34PyA8bV9acZ0FhDRfpsMq5/tNk91pL5XzFut5V/hQvuNTey9/4PMieYecyWjDsbZt1g3NZg+nvyFfDOT+HF28zcZdIwc8N3xhsX4Zglrc9jsxmxevXbcOgjGDm/+bWVf4HYZLjkr8advexncMYP+Mh9EqflTm19ruyJRrg/+gfMut7c/LWG835hrsmaf5mAnL3LTXBUTFA0rVIw4+rW55z9RTPAePgi8zwm0bjZOyJ/Dpz9ExM4tPguI/gX/9kIzOt3mn2mfJY1SRexIJwQt0XaKMgcD7vfNK7YZ24y38kL7o38HGAEYMRs89cW6QVm4LD6H/7nhXDSRZGdPzkX5nyp+XnGGPN5REL2SXDj2+b7nD83dMDZEaNPNdMBtaXmWpfuNi7ptqZzMsfC5x4LdfuHIy4VPud3wTvjYMpnzEAtWrScXw8nwsHYHWDvQtxGDzG0xNjlGJqW8dYXjFUVl2YswuCRaDC1pbDlWWMxVB42N79hJ8OZP4ws2Kh4hxGQ7S+bAJern6LukP8HMu1zxprasLS1MIKZs3v6i7DvfSMCviZjhSmbmePLmWLmjyoOGBF+714zd3flYyYAY/U/TTu1huW/MgE8lz8ETlfb7R1/rtm3tsRY4Y21RvhnXmeeJ2TCpffBmz+GC+5lU3kui9sSYjAiPvUKWPsfOO2bxpo/sdVYxW1FKJ/zMzi02lg6l/zV3ODHnmkiRVf9Hdw1xiKc/JnWc9HBTP88LPu5mZ8dd47ZFptkgmdO+aoJhJl6ufkDPMuXt32uhXeY+co/TjNRyWPPMpb+/K8Yr0H1MTj/NyYQKBJiEszc7643ob7MWFhWwE9HLPia+bMYdzbcsccEHLlrIHMsje31pS3Gnm0GFv+51FjY17/UfsR3dzjvV8bjEJtoBlWdiVHoDo4YMxffWUadah43PwMr/wwp+caL0xGR9Ct7Inzh6c63aQgwtMQ4zsmhsrq+bkb0KN5hAhkc7eRNlh8wIufzewSSfwc3Lzcu1mDqyuDfZ5lgo7QCM7J2V8PHDxjr8dJ/NAfg1JWZCMacKeYH2NRgLJ/3/8+MeBfcbkb0qSPh0HJzTNooExm77lETULXpaTjlVnOj1T5484dGCC/6oxFjrY0QrL7fRJpe9bg534jZxpop2QVx6cbNOvFC086F3zbCdnCFCeJpT4jBiNbyX8Lut41rdM87JoI3OEJ28qXmDyCSm/6C203k75+mGzFMK2gOhAlHbCLc8kGoWCsFY84wf5ESk2Cib5f9zFjHFvZYmHdL5OcByJ0Kt35kPtNtL8FpXzfbx51rgpIKFzV/FyIla4L5iwZKGY9Bd9JKx50Fq/5qXKWff8q4l3sKmy3ywUd/IG+Gcbm/dofxqlz7QnPQltBjDC0xdjmpHijR1B43bH3RzHeFyxncswz+82nj8rr8kbYtrw//YKzL29dDzQkT8frUdeYHZom4t8lEhlYehmtfDJ0nObQanrkRHjzfzGHlTIaPH4TGahgx1+Qprn3YWCpTLjNWQGKrfHbD9C/Aczcbiy97kl+A3zau5LK9MOcmI8Rgbrjn/crMERcsbO3aDp4zm/9VY40/+lmTTpKU13p+LBy50yEh2ww2pl0J218xc7edFZpgsifCl981Qrb1BZNyEi7COZhoFd9YdIeJtrXHmAFOXanxULRnzbdFxhgzDx88F2+zwZLvRqetfc2oU83UwZTLwrv+hzKOWPMbOPiRicgeLmv/9AZDS4zjHAMnz/jd3xhLc94tJn8zGHcNvHi7GbVue8m4bBff2focVUeNJTrjC2buKr3ABA498yUzDxqbZNIRPPVmXuiSv7UOWMifa/II1/wTVvzFiOekT5vtK/9mAl8Kl5g5pYLT2+/TlM8ay7NwEaSOMoEhb91tRPHMH8FJLVxhNntkc0qjFpiBQdEGMzg55baOrWIw4jLubCOa+94zrtnx53XfCsiZbILWOlmIIyoEB5SljOj99x8oOGJNQJEQnk/fZ9LLupuHL0TM0BJjl5NqtwevT2O39d+SmPG1h+CTP5o53o/uM/M1wdba2z8xFWO++LqZV13+C+NaGn9O6Ik+/KOxkE79evO2ky8zgTh7l5v8Q5/XuLDn3hw++AaMK/W0b8DcL4O7qjlQas6NZr41JcJS5HYHzLqu+fkpt5qKQd21DJWC6182ru1IRDiYhd820bBWcFG4Ig6CMNQYSG71QcLQEmN/Fa6aBg8p8f10DkRrxu26z8wB3rzcVIp64Va45UOTJlK6x8yjzv2yiZrNnW5Sd16/07iMLdfzqvtMROyML7QuKjHr+mZ3cGeIiQ+tRuOIjVyI2yJaLtqWZfYiJb3QfM4vfs3MtXZmnlYQBCFK9I+q971EssuMPfp1RPXq+0mr2Axn+XNVL/6TmU9d/5h5fevz5tGKMHW6TERu2V4THepxw6vfMeI88UIT9Sq0jysZrngYvrG1OT9WEAShFxlaYuy3jCv767zxgZXwxvcoyZgDM6832woWmajl9Y+b51tfMMXSg9OTxp5lLLp3fw33LzE5jfO/akrl9VJd1UFBP1mRSRCEoceQuvsku/yLRfRHy7j8gCmmnjqKbSd9o1kYlDI5pEfXmupQRRtMrddglDLWsbsK6kpMqsZ5v+ybOtCCIAhCpxlaYhznd1P3RhWuqiJTalGHXdoZ9n8IT1wF2142xSH+fbbJ173yUbwt1wideqWJen7hVvP8pItbny9nsqka9dVV4csCCoIgCP2WoRXA1ZuW8Uu3w67/mdzZ834Vmmt6bLOpZNRYa2rPAqSMNDm+2RNh24nQcyVkmpSb7S+bqOm2VvkJV+tXEARB6PcMKcvYiqCurIuiGDdUmfSeYEp2GSHOnmTyc5d+3iwiAKbAxWOXm/q8t681+bkzrzOLEWRPbPt9pn/ePEZSlk4QBEEYUAwpyzgp1kGM3UZpbWP0TvrS7XBimykfaPHRfaYK0rUvwrYXzRq0Sz8PS75v6ig31pl1ddNGm7+TL+v4fcafBxf9yRRXFwRBEAYVQ0qMlVKkJ8RQWuOOzgm1NpWb6kpN/m/GGLPy0PrHTam9xCxTo9kRaxZN3/OOKdX4xdfMHG9nsNlDC2YIgiAIg4YhJcYAGYkx0bOMS3cbIQbY/ZYR47X/gaa60OL8M75gLOVNT8Onft/9QhmCIAjCoGJIzRkDZCTGRs8ytlbHiU02y8N5PaY61qjTzMo3wUy9Aq5+SoRYEARBaMWQE+PMhBhKaqJkGR9cZVb5mXYV7H/frP9ZecisnCMIgiAIETLkxDgjMYayaLmpD602qxeNO8esRvTad8wqJxMuiM75BUEQhCHBEBTjWOqbvNQ1drPwR10ZlOyA/Hkw+lSzGHdDhVnAQSpfCYIgCJ1gyIlxeoJZ1ai0u67qQ6vN48j54IwzNaSdCSZYSxAEQRA6wZCLps5MNGJcUuMmP70biygc+siUqMybaZ5f+H9QWwxxqd1vpCAIgjCkGHJinJFg1r3tlmVcVwYblprVk6xVkVJHmj9BEARB6CRDT4z9lnGXg7i0Ngs21BbDVY9HsWWCIAjCUGXoibHfMi6p7WKu8ep/msUdzv2FWbRBEARBELrJkAvgiouxkxBj75qbumwvvPkjGHs2zP9q9BsnCIIgDEmGnBgDpCd2oT611vDi7WB3wkV/BKV6pnGCIAjCkGPIuanBuKo7XZ967cOmytan/iAlLQVBEISoMiQt48zELpTEXPk3GDHHrD0sCIIgCFFkSIpxRkIsZZ0J4GqogpKdpuylbUh+ZIIgCEIPMiSVJSMxhtKaRrTWkR1QtAHQzQU+BEEQBCGKDEkxTk+IwePTVNVHWJ/66DrzmDe9x9okCIIgDF2GpBhnJnYy1/joOkgZCQmZPdgqQRAEYagyJMXYqsIVca7x0bUwXAp8CIIgCD3D0BRjfxWuiIK46sqgfL9U2xIEQRB6jCEpxs0rN0VgGRetN48ixoIgCEIPMSTFOC2hE4tFWMFbudN7rkGCIAjCkGZIVuBy2m3EOe1UNzS1vZPWUHEQ9iyD9DGyTrEgCILQYwxJMQZIjnO0ndqkNTx+Bez6n3k+58bea5ggCIIw5BiyYpzkclLVlmW8/wMjxPNugRnXQPak3m2cIAiCMKQYsmKc7HJQ3dCGZbzqbxCfCWfdDc64Xm2XIAiCMPQYkgFc0I5lXLIbdrwGc74kQiwIgiD0CkNWjJPjnOEt44/+btYslnliQRAEoZcYsmKc5HJQVd/CMvZ6YONTMOWzkJjdNw0TBEEQhhxDVoyTXcYyDlm5qWgDuKvMUomCIAiC0EtEJMZKqfOUUjuUUruVUneFeT1FKfWSUmqDUmqLUuqG6Dc1uiTHOWj0+nB7fM0b979nHkef3jeNEgRBEIYkHYqxUsoO/BU4H5gEXKWUapnrcyuwVWs9DVgM/FYpFRPltkaVJJcTIDSIa9/7kDURErP6qFWCIAjCUCQSy3gusFtrvVdr3QgsBS5psY8GkpRSCkgEyoAIFwvuG5JdJqsrUPjD2wQHV4lVLAiCIPQ6KmTONNwOSl0GnKe1vtH//Bpgntb6tqB9koAXgYlAEnCl1vqVMOe6GbgZICcnZ9bSpUuj1Q9qampITEyMeP8NxR5+/4mbH853MSbVTnLldmauu5PNk++kJGtB1NrVFTrbl/6M9KV/In3pn0hf+ifR7MuSJUs+0VrPbvWC1rrdP+By4F9Bz68B/txin8uA3wMKGAvsA5LbO++sWbN0NFm2bFmn9v94f6kedefLevmOE2bDu/dq/eNkrWtKotqurtDZvvRnpC/9E+lL/0T60j+JZl+Aj3UYTYzETX0YyA96PgI42mKfG4Bn/e+12y/GEyMeKvQB1pxxYLGI/e9D9mRIyOjDVgmCIAhDkUjEeA0wTilV4A/K+hzGJR3MQeBMAKVUDjAB2BvNhkabZCuAq94DnkY4+BGMPq2PWyUIgiAMRTqsTa219iilbgPeAOzAA1rrLUqpW/yv3wfcAzyklNqEcVXfqbUu6cF2d5skfwBXdUOTyS/21MOovp0rFgRBEIYmES0UobV+FXi1xbb7gv4/CgyoShnxMXbsNmVSmw6uNBtFjAVBEIQ+YMiu2qSUIslaualsJaSPkRKYgiAIQp8wZMthgr8kZp3bWMYjT+nr5giCIAhDlCEtxkkuBwnVe6G+HEaJGAuCIAh9w5AW42SXk/yaDeaJWMaCIAhCHzGkxTjJ5WBs/SZIyIb0wr5ujiAIgjBEGdJinBznZHLTZuOiVqqvmyMIgiAMUYa0GA+zVzKMEhgxt6+bIgiCIAxhhrQYj2naA4B32LQ+bokgCIIwlBnSYjzSvQuAmrTJfdwSQRAEYSgzpMU4p247e33DqNKuvm6KIAiCMIQZ0mKcUbWNzbrAlMQUBEEQhD5i6IpxbSlxdUfZ7BttSmIKgiAIQh8xdMW4aD0Am3QhVfViGQuCIAh9xxAWY1N5a4tvlFjGgiAIQp8ypMXYmzKaKhJlzlgQBEHoU4awGK9H5Zn84qp6sYwFQRCEvmNoinFtCZTvxzZ8BomxDirqG/u6RYIgCMIQZmiK8b73zOPo00lPiKGsVsRYEARB6DuGrhjHJkPudBFjQRAEoc8ZomL8Low6FewOMhJiKK0RMRYEQRD6jqEnxhWHoGwvFC4CEMtYEARB6HOGnhhb88UFCwG/GNc1orXuw0YJgiAIQ5mhKcbxmZA9CTBi3OjxUdvo7eOGCYIgCEOVoSXGWpv54oKFoBRgxBigTOaNBUEQhD5iaIlxxUGoLoLRpwY2ZSQaMS6tdfdVqwRBEIQhztASY389avJmBDalJ8QCSBCXIAiC0GcMPTFWdsieHNiUkWBZxiLGgiAIQt8wtMT42EbIPgmcrsCmwJyxiLEgCILQRwwtMS7aAMOmhmyKj7ET67BRLmIsCIIg9BFDR4yrj0HNccidFrJZKUV6Qoy4qQVBEIQ+Y+iIsRW81UKMQapwCYIgCH3LEBLjjYCCYVNavSSWsSAIgtCXDCExXg8ZYyA2qdVLGQkxlEmesSAIgtBHDCEx3hjWRQ0m11gqcAmCIAh9xdAQ49pSqDzYKpLaIiMxhtpGLw1NUp9aEARB6H2GhhjvW24eR50a9mUr17i8TqxjQRAEofcZGmK85x1wpcDwmWFftsS4VFzVgiAIQh8w+MVYa9izDAoXg80edhepwiUIgiD0JYNfjIt3QNURGHNGm7uIGAuCIAh9yeAX4z3vmMd2xFgWixAEQRD6kiEgxm9DxjhIHdnmLskuJ3abklxjQRAEoU8Y3GLc1AD7P4SxZ7a7m82myEiIkQAuQRAEoU8Y3GJ8bCN46mH06R3umpUUy4lqsYwFQRCE3mfwizG0WXkrmOykWIpFjAVBEIQ+YHCLcdFGiEuDlBEd7mos44ZeaJQgCIIghBKRGCulzlNK7VBK7VZK3dXGPouVUuuVUluUUu9Gt5ld5NhGUwJTqQ53zUqKpaSmEZ9P90LDBEEQBKGZDsVYKWUH/gqcD0wCrlJKTWqxTyrwN+BirfVk4PLoN7WTeJvg+FYYdnJEu2cnufD6tJTEFARBEHqdSCzjucBurfVerXUjsBS4pMU+nwee1VofBNBan4huM7tAyU7wuiOaLwZjGQMSxCUIgiD0OpGI8XDgUNDzw/5twYwH0pRSy5VSnyilro1WA7vMsU3msY2VmlpiibEEcQmCIAi9jSOCfcJNuLacWHUAs4AzgThgpVJqldZ6Z8iJlLoZuBkgJyeH5cuXd7rBbVFTUxNyvjG7XyHPFsP7W47A1mMdHn+izgfA+2vW4zvqjFq7ukLLvgxkpC/9E+lL/0T60j/pjb5EIsaHgfyg5yOAo2H2KdFa1wK1Sqn3gGlAiBhrre8H7geYPXu2Xrx4cReb3Zrly5cTcr79/we5U1m8pP2CHxa1bg/fee8N0ocXsnjxmKi1qyu06ssARvrSP5G+9E+kL/2T3uhLJG7qNcA4pVSBUioG+BzwYot9XgBOV0o5lFLxwDxgW3Sb2gm09kdSRxa8BZAQ6yAhxi5uakEQBKHX6dAy1lp7lFK3AW8AduABrfUWpdQt/tfv01pvU0q9DmwEfMC/tNabe7Lh7VJxEBoqITey+WKL7GQXxTUixoIgCELvEombGq31q8CrLbbd1+L5vcC90WtaNyjebh6zJ3fqsKzEWE5USeEPQRAEoXcZnBW4ineYx8xxnTosKylWLGNBEASh1xmcYlyyExKyID69U4dlSX1qQRAEoQ8YvGKcOaHTh2UlxVLd4KGhydsDjRIEQRCE8Aw+MdbauKmzxnf6UCn8IQiCIPQFg0+Ma0ugoQIyOy/G2YGSmBLEJQiCIPQeEUVTDyhKrOAtsYwFQRC6QlNTE4cPH6ahoeuGSUpKCtu29V25iWjSlb64XC5GjBiB0xlZRcfBJ8ZWJHVW1+aMQcRYEIShzeHDh0lKSmL06NGoCJagDUd1dTVJSUlRblnf0Nm+aK0pLS3l8OHDFBQURHTM4HNTl+wCZwIkt1zLomMyEmKxKVm5SRCEoU1DQwMZGRldFuKhjlKKjIyMTnkWBqEY7zD5xV34EtltiqykWIoqZc5YEIShjQhx9+js5zf4xLh4Z5dc1BajMhI4UFobxQYJgiAIQvsMLjF210DV4U5X3gqmMDOBvcUixoIgCH1JYmJiXzehVxlcYly62zx2IZLaojArgdLaRirrmqLUKEEQBEFon8ElxtXHzGPyiC6foiDTjMb2iataEAShz9Fac8cddzBlyhROPvlknnzySQCKiopYuHAh06dPZ8qUKbz//vt4vV6uv/76wL6///3v+7j1kTO4UptqT5jHxKwun6IgMwGAfSU1TM9PjUKjBEEQBi4/eWkLW49Wdfo4r9eL3W4P+9qkvGR+fFFkq+o9++yzrF+/ng0bNlBSUsKcOXNYuHAhjz/+OOeeey7f//738Xq91NXVsX79eo4cOcLmzWYF34qKik63u68YXJZxjV+ME7K7fIqR6fHYFOyTeWNBEIQ+54MPPuCqq67CbreTk5PDokWLWLNmDXPmzOHBBx/k7rvvZtOmTSQlJVFYWMjevXv52te+xuuvv05ycnJfNz9iBpllXAyxyeB0dfkUMQ4b+enx7C0RMRYEQYjUgm1JtIp+aK3Dbl+4cCHvvfcer7zyCtdccw133HEH1157LRs2bOCNN97gr3/9K0899RQPPPBAt9vQGww+yzih6y5qiwKJqBYEQegXLFy4kCeffBKv10txcTHvvfcec+fO5cCBA2RnZ3PTTTfxpS99ibVr11JSUoLP5+Ozn/0s99xzD2vXru3r5kfM4LOME7vuorYoyEzgo71laK1ZsaeUtPgYJuUNHHeHIAjCYOHSSy9l5cqVTJs2DaUUv/nNbxg2bBgPP/ww9957L06nk8TERB555BGOHDnCDTfcgM/nA+CXv/xlH7c+cgaXGNec6FbBD4vCrETqm7xsOFzJFx9aw6LxWdx/7ewoNFAQBEGIhJqaGsBUsrr33nu59957Q16/7rrruO6661odN5Cs4WAGl5u69kRULONCf0T1nU9vxO3xUSE5x4IgCEIPMmjEWPk8UF/erUhqCyu9acfxagAq60WMBUEQhJ5j0Iixs6nS/NONHGOLYckuXE4b8TF2zpiYLWIsCIIg9CiDZs44prHC/BMFy9hmU3xh3igKshLYV1zLyj2l3T6nIAiCILTFoLGMA2IchTljgB98ahJXzxtFSpyT+iYvjR5fVM4rCIIgCC0ZfGIchTzjYJLjnIDMGwuCIAg9x6ARY2dThfknSpaxRYqIsSAIgtDDDBoxjmmsAGcCxCRE9byWGFc1iBgLgiAMNjweT183ARhsYhyFSOqWiJtaEAShb/j0pz/NrFmzmDx5Mvfffz8Ar7/+OjNnzmTatGmceeaZgCkQcsMNN3DyySczdepUnnnmGQASExMD53r66ae5/vrrAbj++uv55je/yZIlS7jzzjtZvXo1CxYsYMaMGSxYsIAdO3YAZuWpb3/728yfP5+pU6fy5z//mbfffptLL700cN4333yTz3zmM93u6+CKpu4BMQ5YxiLGgiAMRV67C45t6vRhcV4P2NuQmGEnw/m/6vAcDzzwAOnp6dTX1zNnzhwuueQSbrrpJt577z0KCgooKysD4J577iElJYVNm0w7y8vLOzz3zp07eeutt7Db7VRVVfHee+/hcDh46623+N73vsczzzzD/fffz759+/jggw9IS0ujrKyMtLQ0br31VoqLi8nKyuLBBx/khhtuiPyDaYNBI8bOpkpImBL188qcsSAIQt/wpz/9ieeeew6AQ4cOcf/997Nw4UIKCgoASE9PB+Ctt95i6dKlgePS0tI6PPfll18eWG+5srKS6667jl27dqGUoqmpKXDeW265BYfDEfJ+11xzDY8++ig33HADK1eu5JFHHul2XweNGPe0ZVwpJTEFQRiKRGDBhqO+m0soLl++nLfeeouVK1cSHx/P4sWLmTZtWsCFHIzWGqVUq+3B2xoaGkJeS0hoji/64Q9/yJIlS3juuefYv38/ixcvbve8N9xwAxdddBEul4vLL788INbdYXDMGXs9OJuqolLwoyUxDhtxTrtYxoIgCL1IZWUlaWlpxMfHs337dlatWoXb7ebdd99l3759AAE39TnnnMNf/vKXwLGWmzonJ4dt27bh8/kCFnZb7zV8+HAAHnroocD2c845h/vuuy8Q5GW9X15eHnl5efzsZz8LzEN3l8EhxnWlKHTU05osUuKcIsaCIAi9yHnnnYfH42Hq1Kn88Ic/ZP78+WRlZXH//ffzmc98hmnTpnHllVcC8IMf/IDy8nKmTJnCtGnTWLZsGQC/+tWv+NSnPsUZZ5xBbm5um+/1ne98h+9+97uceuqpeL3ewPYbb7yRkSNHcsoppzBt2jQef/zxwGtXX301+fn5TJo0KSr9HRxu6toT5jHKBT8sRIwFQRB6l9jYWF577bWwr51//vkhzxMTE3n44Ydb7XfZZZdx2WWXtdoebP0CnHLKKezcuTPw/J577gHA4XDwu9/9jp/85CetXO4ffPABN910U0R9iYTBIcY1fjEWy1gQBEHoYWbNmkVCQgK//e1vo3bOwSHGoxawes6fmZs7rUdOnxzn4HB5fY+cWxAEQRhYfPLJJ1E/5+CYM3bGUZcwMurVtyyS45ySZywIwpBCa93XTRjQdPbzGxxi3MOIm1oQhKGEy+WitLRUBLmLaK0pLS3F5XJFfMzgcFP3MClxTmobvTR5fTjtMn4RBGFwM2LECA4fPkxxcXGXz9HQ0NApMerPdKUvLpeLESNGRLy/iHEEWIU/qhs8pCfE9HFrBEEQehan0xmoctVVli9fzowZM6LUor6lN/oiZl4ESElMQRAEoScRMY4AEWNBEAShJxExjgARY0EQBKEnETGOABFjQRAEoScRMY4AEWNBEAShJ4lIjJVS5ymldiildiul7mpnvzlKKa9SqnUx0AFMsl+MpfCHIAiC0BN0KMZKKTvwV+B8YBJwlVKq1TIV/v1+DbwR7Ub2NS6nnRiHTSxjQRAEoUeIxDKeC+zWWu/VWjcCS4FLwuz3NeAZ4EQU29dvSIlzUlknYiwIgiBEn0jEeDhwKOj5Yf+2AEqp4cClwH3Ra1r/QkpiCoIgCD2F6qj2qFLqcuBcrfWN/ufXAHO11l8L2ue/wG+11quUUg8BL2utnw5zrpuBmwFycnJmLV26NGodqampITExMWrna8mvVtfj8cEP5sf12HtY9HRfehPpS/9E+tI/kb70T6LZlyVLlnyitZ7d6gWtdbt/wCnAG0HPvwt8t8U++4D9/r8ajKv60+2dd9asWTqaLFu2LKrna8l3/rtBz7rnfz36HhY93ZfeRPrSP5G+9E+kL/2TaPYF+FiH0cRIalOvAcYppQqAI8DngM+3EPRAEdMgy/j5TgwW+j0jM+IpqWmkxu0hMVZKeguCIAjRo8M5Y621B7gNEyW9DXhKa71FKXWLUuqWnm5gf2FURjwAB0vr+rglgiAIwmAjIhNPa/0q8GqLbWGDtbTW13e/Wf2PUekJABwsq2VSXnIft0YQBEEYTEgFrggZmW4s4wNiGQuCIAhRRsQ4QlLinaTEOTlQJmIsCIIgRBcR404wKiOeQyLGgiAIQpQRMe4EI9PjxU0tCIIgRB0R404wKiOeIxX1NHl9fd0UQRAEYRAhYtwJRqUn4PVpjlbU93VTBEEQhEGEiHEnGJkhEdWCIAhC9BEx7gRW4Q+JqBYEQRCiiYhxJ8hJchHjsHGwtLavmyIIgiAMIkSMO4HNpiSiWhAEQYg6Isad5KTcZNYerMDna3/pSUEQBEGIFBHjTrJofBYlNW62Havq66YIgiAIgwQR406ycHwmAMt3FPdxSwRBEITBgohxJ8lOcjE5L5l3d4oYC4IgCNFBxLgLLBqfxdoD5VQ1NPV1UwRBEIRBgIhxF1g8IRuPT7Nid0lfN0UQBEEYBIgYd4EZI1NJinWIq1oQBEGICiLGXcBptzFrdBrrD1X2dVMEQRCEQYCIcRcZluyipMbd180QBEEQBgEixl0kMzGWstpGKf4hCIIgdBsR4y6SkRiD16epqJeIakEQBKF7iBh3kczEWICAq7q6oYnjVQ192SRBEARhgCJi3EUyEmOAZjH+xavbueqfq/qySYIgCMIARcS4i2QFLONGAPYU17C3uJaGJm9fNksQBEEYgIgYd5EMS4yrjWVcVFkPwMEyWV5REARB6Bwixl0kNc6J3aYorXXj82mOVZr54n0ltX3cMkEQBGGgIWLcRWw2RXpCDCXVjZTUuGnymhSn/SLGgiAIQicRMe4GmYmxlNa6OVrZHEW9v1TEWBAEQegcIsbdIDMxhuKaRooqzHxxYqxD3NSCIAhCpxEx7gaZibGU1jRbxnML0jlQKgFcgiAIQucQMe4GmYkxlNS4Kaqox+W0MT0/laLKBuobJb1JEARBiBwR426QkRhLQ5OPXSdqyEuJY3RmAgAHysRVLQiCIESOiHE3sEpibjpSSW6qi4IMI8YSUS0IgiB0BhHjbmCVxCyrbfRbxvEA7CuReWNBEAQhckSMu4FVEhMgNzWOJJeTzMQYsYwFQRCETiFi3A0yg8Q4L8UFwKiMBPaFyTVed7CcHzy/SdY/FgRBEFohYtwN0hNiAv/npsYBMDojIaxl/NhHB3l01UF2HK/utfYJgiAIAwMR424Q47CREucEmi3jMdkJnKh2U93QFLLvmv1lAKzcU9q7jRQEQRD6PSLG3cQK4rIs4zFZiQDsLW62jo9VNgSKgazcK2IsCIIghCJi3E0yE2NJdjlIjHUAzWK8p7gmsM9qv1U8KTeZj/aW4pV5Y0EQBCEIEeNuMiEnicl5KYHnozLicdhUiBiv2VdGQoydL55WQFWDh21FVX3RVEEQBKGf4ujrBgx0fnzRJIINXafdxsiMePacaHZTr95XxqzR6Zw+LhMw88ZThqe0PFWH7D5RTWFmIjab6na7BUEQhP6DWMbdxGG3EeMI/RjHZCUGLOPy2kZ2HK9m7ug0cpJdFGYmdGne+EBpLWf//j3e3n4iKu0WBEEQ+g8ixj3AmKxE9pfW4vH6+PhAOQBzCzIAmD8mg9X7ymjy+jp1zr0ltWhtRFkQBEEYXIgY9wBjshJo8moOldezfMcJYh02po4wbumzTsqmxu3hf1uOd+qcR/1rJh+vaoh6ewVBEIS+RcS4BxiTbSKqNx+p5MX1R7ng5FxcTjsAi8Znk58ex8Mr9nfqnEfKjRifqHZHta2CIAhC3xORGCulzlNK7VBK7VZK3RXm9auVUhv9fyuUUtOi39SBw5hMI8Z/XbabareHK+fkB16z2xTXzh/N6v1lbD1axeYjldz94hYq65vaOh0QmWW8v6SWhiZZS1kQBGGg0aEYK6XswF+B84FJwFVKqUktdtsHLNJaTwXuAe6PdkMHEinxTjITY9l+rJrRGfHMK0gPef2K2fnEOe18//lNXH7fSh5asZ+bHvm4XSE9WmFEuC3L2O3xcsGf3ufP7+yKXkcEQRCEXiESy3gusFtrvVdr3QgsBS4J3kFrvUJrXe5/ugoYEd1mDjzGZpu1ja+cMxKlQlORUuKdfHrGcNYdrGD8sCR+eslkVu8r45tPrW9zIYkjfsv4RFV4MT5SXk9do7fTc9GCIAgteWL1Qf4iA/teRWndfjUopdRlwHla6xv9z68B5mmtb2tj/28DE639W7x2M3AzQE5OzqylS5d2s/nN1NTUkJiYGLXzdZdHtrpZfsjD7xbHkRrbesxT5dasLPKwJN9BjF3x8p5Gnt7VxJ1zXOTH1of0xac1N/6vDruCJh/cd1Y8LkeowG8s9vC7T4xQ37swjqz4/hEO0N+uS3eQvvRPpC/R59419Ryu0fxxSXyXz9Ff+hINotmXJUuWfKK1nt1yeyRFP8JVmAir4EqpJcCXgNPCva61vh+/C3v27Nl68eLFEbx9ZCxfvpxonq+7nDSzgf0ltcwrzGhzn4uD/p85v4nnfvomtYkjSIwtCulLUWU9vjfeYdaoNNbsL2fC9LkUZCaEnOvQyv3wyRYA6lILWbxgdPQ60w3623Vpi+3HqnhlYxHfPHt8K0+GxUDpSyRIX/on/aUvf962gsrScmbMPZWUeGeXztFf+hINeqMvkZhPh4H8oOcjgKMtd1JKTQX+BVyitR7yqyHkJLvaFeKWJLucTBuRwvu7S1q9ZgVvzRiZBoQP4jpYVkesw0ZBZgLvSGGQTvP4Rwf58zsm4E4YGvxn5X5OVEuqYDjqGk38yu5iWfK1t4hEjNcA45RSBUqpGOBzwIvBOyilRgLPAtdorXdGv5lDg9PGZrLpcAW1TaGOh8P+tKbp+alA+CCug2V15KfHc8bEbFbuLaWuUUSlM2w+UglAZV37Ue3C4KC42s0PX9jCM58c6eum9Evq/feP3SdqOthTiBYdirHW2gPcBrwBbAOe0lpvUUrdopS6xb/bj4AM4G9KqfVKqY97rMWDmNPGZeHTsL0sNKraiqQOiHFYy7iekX4xbvT4+HD3kHdORIzH62Orf/GOjlLMhMFBrd8DIkV0wlPvz+wQMe49IlooQmv9KvBqi233Bf1/I9AqYEvoHNPzU4mPsbOltKUY15MS5yQ3xUWsw9bKMtZac6isjnkF6cwZnU6Sy8GLG45y9qSc3mz+gGVPcS0NTaY8aZWI8ZCg1m/5FVXW93FL+icBN7WIca/RP0JuBQBiHDbmF2awpaS1GOelxqGUIifZ1Wo0X17XRI3bQ356PDEOG1fMzue1TUVDatS/v6Q2kP7VWSwXNUBVg4jxUMASm2NtpAoOdeoDc8Yixr2FiHE/49SxmRyv0xwurwtsO1JRz/BUFwA5ybGtRPZgmdl3ZLpJQ7j2lFF4teaxVQd6qdV9z7f+u4GvL13XpWM3BYmxuKmHBgExFsu4FY0eHx6fJtZh43B5vVT16yVEjPsZs0aZiOmtR6sC2yzLGCA7ydXKTW2J8aiMeP9jAmdOzOaxjw7i9gyNH9KxygbWHqyguguW7eYjlUwclgSIGA8V6vxzxsXVbjydXEFtsGPNF0/OS0ZrAsvBCj2LiHE/ozDL5A/vKTZLJVY3NFHV4GkW4+TYVlW4DvnFOD+tOUH/hlMLKK1t5KUNRb3R7D6noq4Rr0+zel9Zp47z+jRbi6qYV5CO3aZEjIcItX7L2KehuEZc1cFYLuqpI1IBmTfuLUSM+xnJLicpsYq9/tGoNQ8abBnXuD2BaFCAg6V1ZCXFEhdjD2xbMCaD7KRYVoTJW7Y4UlE/KAJY3B5v4Ob6QTv9Dce+khrqGr1MGZ5CsstBVf3ATwn75EA5d7+4pc3SqgIhqX/HKodObEUkWJ/NpNxkbAr2iBj3CiLG/ZDcBBVwDe04ZpLux/mXZcxJjgVCc40PlNUG5ostlFIUZCZwKGjuORitNV98cA2f+dsKymsbo96H3qQiKDd4RSdTujYfMdMBJ49IISXOOSgs49+/uZOHVuxn1T5Jb2uLWnfz9I2IcSjWfHpynJOR6fESxNVLiBj3Q4Yl2NhTXIvWms1HKolx2BjrF+PsJBPIFZxrfMifY9yS/PT4wHxyS7YVVbPjeDVFlQ1855mNdFSjvCfw+TT3v7eny1HQFuV1ZjAxdUQKO45Xd6qq0q4T1ThsirFZiYNCjA+V1QW8A0+uORT187+/q7hL8/L9jRDLeAhlHUSCFbAVH2NnTFYie/1TZkLPImLcD8lNsFFZ30RZbSObj1RxUm4yTru5VJZlbN1A3B4vRyvryU+La3WekenxHK9yh42GfHHDUew2xa1LxvDm1uM8+tHBHuxReDYfreQXr27nivtWsr+k6z/4Mr9l/6mpuQCs3BO5RVhW20RqfAwOu43kKIqx16dZuvogxW0sedlTPPXxIWwKzp6Uw2ubj1FRFz2vR2VdE9c+sJpHV/X+dyXa1Lq9JMTYibHbxDJugWUZx8fYyU6OpXSAe84GCiLG/ZDcBLNQwe4TNWw+WsmUvOTAa/np8Tjtiu1+9/X2omq0hom5ya3OY1nLVjlNC601L204yunjMvnW2ROYOTKVR1d2nAZV1dDEtqLmKO8mry8QPBYJTV4f/3h3TyBAxHLBl9c1csU/VnbZQrbc1KeNzSIlzskHuyKfN66oayTVXwg/Oc4ZlTxjj9fH159cz13PbuL5db1XbtHj9fHfjw+zaHwWXz9rHI0eX1Tfv6yuEa3NPPtAp77JQ0Ksg5yUWLGMW2CJcVyMnZS4GCrrmvrEczbUEDHuh+QmmMuyfGcx1Q0epgxPCbzmcto5KTeZDYcqANhw2DxO85fKDCY/3VjLLQVz7cFyjlTUc/G0PGw2xZyCdPaV1HaY4vHtpzZwyV8+DOQ5/+ntXSz5v+URpz58cqCcX762nVc3mQjvnceriXHYeOrLp3Ci2s2rG7sW+W1ZxpmJMcwcmRqSN9wR5XWNpPnFOCXO2e0KXFpr/t+T63lpw1GUgqJetLre21XMsaoGrpyTz+S8FKaOSGHpmkNRu5FaVvaB0sgHYP2VWreX+Bg7uclxvXqNBgL1TcaFH+e0kxrvpNHrC6Q7CT2HiHE/JCNOEeOw8eJ6szjWlLyUkNenjUhl4+FKvD7N+kMVZCbGkpfianWefL9l3DKI68X1R4l12Dhn8jAAxmYl0uj1cai8bcv0o72l/G/rcRq9Ph5ZuZ8at4eHV+zH49P84a3IFiEvrTE3843+AcTO4zWMy05kyvAUkmId3bCMzXlT42MozErkQGldxAJUUWfc1GAi2Svru2cFHCit45WNRXx18RgKMhJ6tQrah7tLcTltnDHRlEG98ORcth+rpjxKi19U+AcqbcUhDCTqGj3ExzjISWld0S7a+Hx6QBXOqG80g/L4GAepcWagWiELqPQ4Isb9EJtSFGYmcKSiHqddMX5Y6KLW0/NTqXF72Ftcw8bDlUzPTwm7Bm9WYiwup42DQZZMjdvDc+uOcNakHBJjTWlyKzisrXxCn0/z81e3MSzZxZIJWTy66iAPfbiPqgYPiydk8fLGo2w/VhX22GBKa8386Ua/5brzeDUTckyxjeFpca3c6ZFSVttEYqyDGIeN0ZkJ1Dd5OR5hmcOKuqYQy7jJq7tlBVg5q/MLM8hJdvWqC/REtZthyS5iHOZnnetPhyuJUh6tNegpqmwYUOISjlq3l4RYO8OSYzlW2dCjbti/v7uHM3/7Lt4BkmpmBbfFxdgDUzgixj2PiHE/xSr+MT4niViHPeQ1yyX9/q4S9hTXMM2fnN8SpRT5aaER1Y+tOkBVg4ebTy8MbBvTgRi/vKmIjYcruePcCdx2xlgq65v47Zs7mTs6nT9cOZ3EGAe/f7PjlTMty3jr0SpKa9wUVTYw3l/5anhqXLcsY+umUZBhPrd9EQaEldc1BizjFL8V0J0grhJ/wFZmYiy5Ka5eDQ46UdVAVlJs4HlmYkxIm7pL8A25M7EC/RHLMh6WEofb4+tRsdl1vJojFfWs908t9XfqgwK4UuLMd6iiXoK4ehoR437KmCwjkC1d1ACFmQkkxTp49KMDaB1+vthiZHp8wP3c0OTlXx/s49SxGSHHJLuc5CTHtinGL204yoi0OC6dMZyZI9OYnp+K1nDzwkJS42O48fRC3thyvMPAKWtu1+3x8bJ/ftiyjEekxYXU4+4MZXWNpPkFdXSmcc3vL+1YjOsbvbg9voCQW2LcncIflhWamRQTcIH2VvGN4mp3IPUNzIAAoKQb0bCNnuY4gmDBGujzxrWNlmVsPq+e9GBY0cjv7izusfeIJnVNXpx2hdNuC/w2ZJ3vnkfEuJ9iWcZThreOkrbZFFPzUwL5f1NHtBZsi/z0eA6VmTnUZ9YeprjazVcXj22139jsRHafqG61XWvN2gPlzCvIwGZTKKX4wYUnce0pozhjYjYAX15USGFWAnc+s7HdHNTSWjfx/iph//3E5MAGLOO0OKobPK2imd0eb4diVl7XRFqCEeO8lDhiHLaILGMrP9kS8uQ447bvjmVcXNOIUpAeH8OwZBcen+611JDiancLy9gvxl20jB//6CBT7n6D5TtOAOZzcdjMdMiBTlrGL288yuubu1+a9VBZHX9dtrvbA5w6t2UZ+8W4Bz0Y1iD0Xf/n2N+pb/TicprfacBNPcDz7wcCIsb9lLkFGYzPSWTh+Kywr0/3W7ajM+IDbtZw5KfHU+P2UFzj5h/v7mXaiBQWjMlotd/YrMRAoZFg9pfWUVrbyOzRaYFts0en89NLpmDz35hdTjv/d/k0iirr+cWr29psS2lNI5PzkkmJc7L5SBWJsY5A4NnwVGPRHgmaN/b6NAt/s4wHPtzX5jkBymubI6JtNsWo9PiIxNiy9NJaWMbdclPXuEnz5y3n+K2u3gjiqm/0Uu32hIhxapwTu00F5uojRWvN3S9u4XvPbaLR42PXceMxqahrJDfVRVKsg4MReB6C+fPbu/nGkxu6/Vm8vLGIe9/Ywbu7umdl1jaaPOOAGPfgNSqrNQO0jUcqKR0AdbDrG72BQXOq5aYWy7jHETHupwxPjeN/31jEKP8caEuseeL2XNTQnGv8+zd3cbCsjtvPHBc22GtsdiI1bk+rm9LH+83CC9ZqUm0xc2QaN51eyBOrD4W1sMHclDISYgOW/PicxEBbhvuLlgSL8b6SGo5XuTt075UHuakBRmcmRFRExApIsubFoiHGpTXuwFxtb1hdFlZxkewgMbbZFOkJMZRUm376fDqiWuTbiqp5aMV+rp43kliHLVDRrLyuibT4GEZmxHfaMi6ucVPf5OXeN3Z06riWWGLW3eVB6xu9xMc6yE6KxWFTPRYhrrXxjMwvyEBrk37W36lr8hIfY7xELqeNGIdN5ox7ARHjAcqMkWnE2G3MLUhvdz9LjJ9YfZBp+akB13JL2griWnuwnGSXg7FZieEOC+GLpxWgFLy66VjY10trG8lIjAkS46TAa8P9kb/B88Zbi4yorz9U0cot+eHuEnafqKbJ66O6wRMixgWZCRwoq4vIvQ2QltByzrg7lnFjwD0c6XzkzY98zD/f29vl9wQCghlsGYNxVVvz2K9vOcapv3qHTYfbz8O2AumunJNPdnJsQOgr6ptIiXMyOiOhU3PGTV4fZbWNJLscPLP2MJs7kQfeEsvl/872E12OMWj0+Gj0+oh32nHabRRkJvTYykS1jV4aPT4Wjs8iIyGG5Tt6V4zrGzue5ml9jIc4v5taKUVqnFPmjHsBEeMBSlZSLG9/axGfmzOy3f1GBJXJ/ObZ48NaxdB2etPH+8uZNSot4JJuj5xkF7NHpQWKegTj9WnK6xrJSIjh5OGpQKgYZybGEOuwhURUW2s6Vzd42Btk6ZbWuPniQ2v45avbA+6zdL+gAozOSKDR4+NoB1ZgyznjJFd03NSWGGcmxmBT7bupG5q8vLXtOG9vP97qtWOVDSE1yNvjRMAyDs03z0yMCQRwbT9WjU/DX5a1nxd+zP+5DUtxkZUYGzh3pT/yfGRGPIfL6yJO1bGi6G9dMpa0+Bj++HZkeelgvjc1QSuUldS4A1MbT6zuWlnOQLSwP7VvXE5ij4lxWU1zQZqF47M6VR2uuzR5fSy6dxn3vbenU8fVN3lDVoBLjXeKm7oXEDEewOSnx2PvQCQTYh0MS3Yxa1QaC8dltrlfVmIsyS5HyE2poq6RXSdqmD26fes7mPOnmEITe1tU5arwl1JMT4jhlDEZLJ6QxZknNVvpSimGp4WmN20rqiLJf8MMTgt57KODuD0+NhyuDAhqaoib2h9RXdK+5dRcLMSIsN2mSIp1tBLjd3cW882n1vPjFfUdzvmVVDeLscNuIysptt0KT3uLa/Hp1oOgIxX1XPCn97n8HytxezrO6bWs17CWsf81Kx3pjS3HOVLTdrW1osoGHDZFZkIs2UmuEMs4Ld7JqPR4mryaoxGmolnHF2YlsmBMBruOh5/GCMdDK/az+N5lAeEvrWlkUl4yZ0zM5sk1h7qU71zrz6NN8AvO2OwkDpTW9kjutDVfn5EYw9jsREprG3stR3v9oQpOVLtZvr1z1nhd0JwxmHnjaLmptxVVMfOeNznt1+/w+X+uiniw2Rc0eny9ugypiPEQ4MEb5vD3L8xs0yoGI4ZjsxNZs78sYImsO1gBmPngSDlviqnq9drmUFe15V7MSIwlJc7JQzfMbTUfPjw1tPDH1qKqQHGS9YfKAWNJPrJyPzF2GyU17oD1nJ4Q6qYG2NdBkFFFXRPxMfaQPO7kFiUxX91UxHUPrObVTUUcqPKx1v+ZhKO+0ayrnJnU3JZhKXHtWsa7/PPrJTWNgajbhiYvX/7Px9S6PRworYtoYYYT1Q3YbYqMhNBgvszEGEpq3GitOVRWx8RhScQ57by8t+2b67HKBnKSXdhsiqwkYxn7fJrK+iZS45yMzDCDnUjnWYNd6MNT4zhaGXm614ZDFZTUNAYGQSU1bjISYrnp9EJKahr56ctbIzpPMFZRi4BlnJ2IT0eem94ZrGuanhAbuDa9FV1vWeHrD1dENKCzqG/0BtzUAClRtIyfWH2QWreHSbnJrNhTypr95VE5L5gVxbozBdKSpWsOMvFHr0etaE5HiBgPAU7KTW7lvgzHNaeMYk9xLZf85QOWrj7I35fvwWFTgcjtSMhLjWPGyFRea5HGYrkqW4pFMCPS4gIBXMXVboqr3UzOS2ZafkpgYPDi+qOU1DRy+5kmPcsK7rKsW4CcJBdxTnuHQVzldU2Bcn8WLZdRfGvbcdITYlhx15mAqRrWFoEc44Rm69Sq8NQWweezrON7Xt7K5iNV/O3qmZw+LpM/vb2rw9WXiqtN4FjL6YTMxFjcHh+1jV4OldcxZXgKn583ko+KvG1aJUWVDeT6XcHZSbFU1jdRUutGa0iJjwkMoiKdNw622vNS42j0+CIWJCtf/Jg/X7vMH3cwrzCDWxaN4fGPDvJRUefywq21jC3LeFyOmaLZ1QOu6sAgNCEmMGC0XNedpaKuka88+klEQXgAK/aU4LApGj0+NnYQJxBMa8s4OquZNXp8vLjhKOdMHsZvLpsKRDeK/QfPb+a3/+tegGAw+0vqcIQZ4PYUIsZCgEtnjOA/X5pLRV0Tdz27iZ0nqrn9zHEh80eRcMGUXDYfqQoJsAlYCIntiXE8pbWN1Dd6A6tDTcpLZnp+KtuPmXWK//7uHiYOS+LG0wtx2BTv+cU42DK22RSjMuL5cHcJL2042qboVARV37JIjnMEcp211qzYXcophRmkJ8SQ7lLtzi0GF/ywGNZBScxdx2tIdhkLbdeJajxeHy+sP8pls0Zw5kk5fO+Ck6hqaOKvy3a3eQ4wc8YtXdTQnGt8tKKe41Vu8tPiOXNitnGNt7HAx7GqhkAkuHXO3f70ptQ4J7nJLpz2yCOQiwNVyWLI8wfqReLi1loHrNVjlQ1UNTTh8Wky/H361jnjmTkylQc3uwPfr0iw3NRWxHBBZgI2Bbs74T6PFGsQmp4QQ4b/u1/WxWUt39x6nNc2H+PNra3jC1pS6/aw7mAFl80aAcAaf1ZEJPTUnPHyHSeoqGviMzOGkxLnJNZhC8QnRIPiandUo+L3l9YyKiOhXY9iNBExFkJYMCaTt7+1iFduP41PfnA2t585rvPnGGvymINduoG5s4TWgmFhRVQfqahnqyXGuclMz0/D69Nc9veVHCqr44efmoTLaWfCsKSA5ZHWQlTPmJjNzuPVfO2JdVz34Jqw71de1xiIpLYItoz3ltRyrKoh0J+8RFsHlrEVrNPcx5wUF9UNnpDF7IPZdaKGBWMySYixs+t4DVuOVlHj9gTyy0/KTeZTU/N46uPDIdWwWnKiyh3W+2EJgDXnnp8eF6hZfbSi9SBBa5P+ZEWCZ/vXz7b6nZbgxGZTDEtxRWyhFde4/TdfO3mpLv97d3xsWW0j1Q3mcztW1RD0+Zo+Oe02fvipSTR4jYsyUuosyzjWCE6sw87ojIQesYzLat3EOmzEx9hJ93/3yzqZ922xwr9O94ZDHVu5q/eV4fFpLpqWx5isBNbs64QYN3qJczoCz1PjY6hv8nZ7rvvZtUfITIzh9HGZKKVMudgIa8h3RF2jh7pGL4fL66M2z7u/pJbR/imZ3kDEWGhFanwMk/NSOgwOa4vxOUm4nLbAMo/QbCGkxTvbOKo51/hweR3biqrIS3GRGh8TcJMfLKvj3suncupYE4hmpUjFOe2BikEW3zlvIlt/eh7XzB/FruMmBaolFfVNrSzjYDFesdvMuZ06xrzf8ERjGbcVRRywjBOD3dRt5xo3NHk5UFrL+GFJ/gpoNXy0z9xw5welrF0yLY/K+iY+3NN2JG5xjZusxLYtY8vNPzI9PuCCLgojiFX1HhqafM2WcaJ53OkXKisnOy8lLqyg3v7EOpa2iHIOrgwWPODqiOCSpscqGwLzxsEDuqkjUolzwEq/UEVCXZNVe7lZcMZmJ3ZZjA+V1bUZF1BaazIIlFKk+79rpV1wU2utWeG//puOVHS4/we7S4hx2Jg1Ko25Bel8fKA8ouh3rbW/bnfQnHEEKX/PrzvC+X98v80BY0VdI+9sP8HF04bjsBvZyUl2Rc0ytj5Tt8cXWKylI576+BDf/u+GsK95vD4OltUxOjN8nYeeQMRYiDpOu43JeSkhYlzmr5Jl/RDDYd2o739vL2v2lTEpz5QCzUqK5TMzhnPPp6dw6YwRgf2n+guftCXwLqed6fmpeHw6rPuqIsycsbWMIhhLZHhqHKP8o+O8RBtuj6/N/FYrajkjMdRNDeHnxvYU1+DTJoBobHYSu05U89HeMgozE8hObrZyTx+fSVKso831nr0+TWmNO2DFBmOJ4LqDJlAmPz0el9NOUgwcDTNAKKoyN8fcFHMtrHMG3NT+z3p4alwry7qyvokXNxzlrW2hZR+Lq5sHCilxTuJj7GGt8pbs80fD222KY1UNQUGAzZ+v3aaYmG5vd6DSkjq35aZuFpxxOYnsL6lt1/vQkjX7y7j8vhWc/ptlXHX/qrAWWVltY2BqJjnOgcOmInapa60DWQl7ims5XuVmeGocu0/UUOtuf578w90lzBmdhstpZ87odKobPOw41rEb3u3x4dO0clND2yUx6xu9/OLVbWwrqgp4tFqyam8pjV4fF07NDWwzlnF05oyDg6ysrIH/bTnG6y0CSYN5+uPDPLP2cNjP8khFPR6fDiw80xuIGAs9wrQRqWw+WtmcklLrDpnXDUduioubFxaytaiKo5UNgXxkgN9dOZ1r5o8K2d+yjNsrB2oVM9nTwurx+TQVLSp3gRGLhiYfpTVuVu4tZcGYjOYqYYnm57LzeHgLqqTGTZLLERKdndNOFS5r/nl8ThLjchI5XuVmxZ5S5hWGliuNddg5e1IOb2w5FlYsSmvd+HRo9S0L6zPfebyaGIctIIrpLltYN7OVhmVZxsaqg53+qG9r8JKXGsexqoYQa8sqJtJysFIcNFBQSpGXGt6qbsn+klrsNsXkvGSOVwVZxi3iDial2zlUVh/xSlK1jVYAV7NlPC47CY9Pc6ATZT5/+Pxm9pfW8enpeewtqWX5zta1p62qc2D6npYQE7EYv7uzmDN++y4vbjgasIpvOr0An4YtR9tesrSyvontx6o5xf89muNPTfz4QMeuaisHOziauqOSmA+t2B/IRV97IHx09BH/4KswyNLMSXFxvNIdleUrS4K8Ddb67b96fTt3/HdD2Hr5Hq+PjUcq0Jqwy7/u9wcnimUsDHim5afQ0OQL5LOW1jS2O18M5mb1vQtOYvX3zmLpzfO58fSCdvc3y0va2hV5a8GNPcWhN9nqBg8+HRqFDaaymVKw6N7lVNQ1BeaLoVmMd7VR7rOkprGVq9hyCYcTn53Hq3HYFAWZCYzzDxrqm7zML2yd133h1FyqGjxhLcATVeFzjIHAyjs+baLVrWjrdJeiKIx1ag0arHY77DYyEmICN+KUIDH2+nQgbQlgw+EKwJQ0tW6wWmtOVIW60PNS4zosyAIm1WhEWhwj0uIoqjRzxtYiHMFMyjDCEamr2rKMg60/q+hNpK7qRo+PPcU1fHbmCO69fBo5ybE8+OH+VvuZ731zezM6Icar/fO8P31pK29sOcbw1DgunJoHwEb/Zx2O7X7rdMpwM1gdkRZHZmJMh5XXgMBa3vHhLOMwgWeV9U3c9+4elkzIIjfFxdqD4cX4WGU9sQ5byO9tWLKLRn91tmBe3VQUUuglEoLz/w+W1lPX6GFfSS3Vbg9PrjnUav/tx6ppaDL3ps1HwoixP3DQqlnQG4gYCz2CNc+7t9J84a2UlEiIcdiYX5hBQqyj3f2cdhuXzRrBwvFtFzNJdjnJToplT4vI4ZbVtyxOG5fJS7edxrT8FBJjHZw2tnmhjjiHCTrZ1Y5lnNlCjONjHOSmuAIrbAWz83gNozMTiHHYGJfdXI1sXkHrhTxOG2dc1a+EcVU3pw6FT1+z2pSf1nxjSXepsAOEosoGbIqwqz8luRyBaYZwgVjWtES12xNYhrK20Ut9kzfkfMMjtIz3ldQyOiOBnGQXxysbKK1tXoQjmLxERWZibMSu6tpGLzF2U3PZYkxWIjYFW45GlgK0t6SGJq/mpNwknHYb18wfxfu7SloVNCmrbQwZLKZ3QozXHawgOymWslo3H+4u5dSxGSY9LMXFhnaEdWtQJgKYQW5hVmLYZUV3HKsO8SjUWZZxmDnjcG7qp9YcorK+iW+fO4GZI9MCsQktOVblJjfFFRKZnBtmkY49xTV89bG1PNTB4jAtsdzUafFODpXXsa2oGq1N+tqDH+5vFTNiBTTGOGxhr/m+kloSYuxh4zB6ChFjoUcYmR5ParwzIMalLW5K0eLnl57MzQvHtLvPmKzEVmJs3VhaWsZgLIpHvzSPdT86u5W1OS4nqR3L2B2S1mTRVnDQruPVAYt4eFocLqeN0RnxARdxMLEOOwvHZ7Fqb2vrL9wiEcFYlll+enNp1AyXotrtaeXCO1ZZT1ZSLM4gwbPmr4M/q+ZArOYb6cbDlYGKaZarMFxlsOGpLkpq2q9EpbVmf2ktBZkJDEt2Udvo5UBpXdicT6UUC8ZksGJPaUQuz7pGD/GxoQF/cTF25hVk8NqmYxGdw5p/neBfAvSquSOJcdhCVhir9w9EgtP5InVTe32ajYcrOG/KMK49ZTRAUOBiKpvasYy3Hq0iMzE2JLq+ICOhVVETrTVffGgNP3phc0ibITS4rb01jbcdq2JYsovJeSnMGJnKkYr6sKmExyrrW32vc8IEN1opjZ1d+7mkppGkWAdjsxM5VFYXGJDcef5EjlTUtyrRu+5gBRkJMcwrSA/r8u/ttCYQMRZ6CKUU00aksq/SF1KXui+wIpWDb7LhymgGo5QKESSLcf5zhQvWCV4kouX77ykOPaa42s3+0jpO9s97222KC07O5fLZ+W32Y1xOIkcq6luJWFuLRFhkJoWxjONM31qW6iyqbGBYSlzINss6sOYOgaD0KGPhHq9q4FhVA2dPzgEIVFILJ8ZWrnF7ZUKLq93UNXpDBidbjla16V1ZMCaD4mp3q+mIcNS6vSHzxRYX++d+25uPtdh+rBqnXVGYaQZTGYmxXDUnnydWH+I1/42/OZ0v1E0dScGTXSeqqW30MmNkKnecO4EfXHgS50421e2m5qewv7SuzcUbthZVBaxii4KsBEpqGkPWC99XUhuSRghB1cmCLOPEWAd2mwpbEvNQWV2gItsMf6W+cK5qU0gm9HtlPQ+2jK1BztqDFZ0qNGItQpOfZtZv33q0ktR4J1+YN4oxWQn84a1dIX1ff6icGSNTmZyXws7j1a1iMfaX1AYq+fUWIsZCjzEtP5XD1T6OVtSjNYFiDb3NmKwEqhs8ISkPFXUdp1qFY3xOIg1NPq7+10dc+Y+VHPQHejR6fFTWN7UpxnWN3pB50pV+C9dKmwL43RXTuXXJ2DbfuzArEa1p5W48XuUm2eVold5lYYlpfnqzGGe4zIi/pbv4WGUDucmhFowVfBVsGSfGOkh2OQLHWy7qC0820bKH27GMLTEOXi7TYn9JLS9vPBpYGGS03zIGa6oj/HfIGtSEC8ZpScvUHYvzpwzDaVe8sP5Ih+fYXlTFmKzEEFf3dy84iZkjU/nGU+vZeLgipBSmRXpCDJX1TWFT7YJZ73f3Ts9PIyHWwY2nFwaur7V86vow1rG1/vSk3FAxHu2PCg6uSvehf479eJU78Huw5oyDv0vWyk3hArgOlNYxyv+9mjI8mRi7rZWr2ufTHA8qJGNhLaQSbBlbgxyvTwdSCyPBqgk/Ij2eoqoG1h+qZHJeMjab4heXnsyhsjq+9vg6vP6yrnuKa5men8rkvGSavDqkfkCT18fh8vpenS8GEWOhB1kwJgMNXPGPlQA94qaOhOaI6uYbUXmtf/nEdiKxw7FgTCYThyVR1+hh4+FK7nnF1Ea2rNNwlps1HxxcvWvlnhKSXI5AkE1E/bCC0U6EivGBIOskHJZlNjI9dM4YWhf+OFbZ+qYZsIxbfFbBUdEbD1ditylOHZtJYqwjyDI25w92mQ5vpwrXr1/fzm2Pr+P2J9YBpjpWcHsy2/gOWXO+O1uk7zR6fPxt+e4Qd3ydfy3jlqTGx7BwXBYvbyzqsHDEjmPVARe1hctp5x/XzCYjIZavPrY2YPmnt7CMoe3IZIt1BytIjXeGLToxY2QqLqeNd7a1rsS1p7iGRq+Pk3JD22YFMga7qj8MWkHKskib3dShg5WUeGerOeP6Ri8nqt2B1L9Yh53Jw5NbWcaltY00eXVgjtjCYbeRneQKEeOdx6s5Y2I2SS5Hm67qVzYWtXK5l9a6/ZZxHFobd7c1IJlXmMFPLpnMuzuL+f5zmwKBfjNGpgV+f1uDvCFHyk1aU1tryfcUIsZCjzG/MIPbZ8QGioe0/DH2FmP8azEHzxtX1DehlFkYojPkp8fz+tcX8sJtp3HbGWN5c+txPthVwo9f2IK9jTre4ZanXLGnlPmFGZ0qrGK5zVquiHXAP7/VFjNGpjEqIz7E7ZYaq7ApQtKbatweqt2eVmIcsIxbfFbDU+MCc8YbDlcwIScJl9POiLTmBT+Ka9w4bCrk2JxkF0q1LvyhtWb1vjLG5yRS3eAh1mFjeGpcYG4R2vauuJx2RmcmsKNFANVb247zm9d3hAS+1TV6iG/Di3Dx9DyKKhtCykc+88lhPglKC6qsa+JoZQMThyW3Oj4rKZZff3Yqh8vrAyVMM0ICuKwqXO27qtcfqmB6fmrYOcv4GAeLx2fz2uZjrQYNlqhMbuGmHpkej1IEAgm9Ps3KvaWc7l/Jzfrc6toQ43BrGlu5+8Eel5kj09h4uDLE7WuJ7bDk1r//nKBc47pGDwfL6piUm8JpYzN5d2dxq/n74mo3tz2xlj++tTNkuzVFFDzgnJzXPNC9et4ovryokKVrDvHVxz5BKZMaOSo9nsRYB5uPVrL2YDkPfriPD/wWubiphUHFzBwHb31zEY/fOI9ZoyJf/SmaDEt2ER9jDxHj/SW15CS5ulxlDOBLpxUwPDWOGx9Zw9vbT3D3RZNCbgAW6QkxZCTEBMT4cHkdB0rrWDCmddR0e8THOMhLcYX0o8nr40h5fbtl+04bl8m7dywJiU632xQ5ya4Qy9iqhtRy0NRsGYeKsWUZNzR5WX+wgmn+gYgRY3OjPlFl3IfBC1jEOGxkJ8W2sox3n6ihtLaRG08r5I2vL+Txm+bjsNtwOe2B6YT2IvIn5CS1ygF/21+AJHgeuNbtDZTCbMlZJ+WQEGPnV69vp77Ry/PrjvCt/27ghgfXBKKOLeGa2MIytjhtXCanjs0ILM4QGsBl+lFa62bHsWp++tLWVisqVTc0sfNENTPy2/69nH/yME5Uu/mkhRW6tagKl9NGgX8u28LltJOXEheY4th6tIrK+iY+O3MEyS4H2/2WsVWdrGU9+tT41ssoWjnZwQPBafmpuD2+kCDHosD3KnTOGCA3udky3nm8Bq1NUNyi8VkUVTa0Cnx8a9txtCZktSeP12diUhJjQwYGLefNv3v+STz71QXMHJnGovFZJLlMadeTcpN45pPDfOZvK/jJS1v5wfMmoG20WMbCYMPltLNgbGavRiYGY7MpCrMSQoJ7Pt5fxqzR3RscuJx27jp/Ig1NPq49ZRTX+KNewzEmKKLaqjFsRcd2hjHZiYH5VDCuXo9PMyq98zeO3Bb1pVfuNdZfS/drczR1azd1ZX0T//34ENVuDxdNM/PFI9LiOezPNS6uCb+ARV5qXCDi2mKVP692XmE6IzPiQwZvlnXcXq76+Jwk9getS+z1aZbtMGK8OSh9xcwZh0+bS4h18NsrprH+UAXXPbiau57dyLT8VLSG25euo8nrY4d/XnpibngxBvjOuRMBcNpVIMI8uP1ltY08sfogD3y4j1+8si3k2HUHTTGK6SNT2zz/mSflEOOwtYoS3lZUxYRhyWEHmYVZzRHVVhrYgrEZTByWHHDvN4Qp+gFmIHaiKrRAh2UZjwoSwJP9bt8tQbm7luUbLktgWJBlHPhchyUFarO/uyPUVf3GFlNR60hFc5GX8romtDZz0Dn+RUxiHbaQAiMWM0em8fRXFvDQDXMD2+YWpOP2+Lh5YSFvfXMhd543kduWjA3UQO8tRIyFIcH47CS2Hq3C59McqajnaGUDc6JgqV80LY83vr6QH180ud39xgVFdK/YXUJmYmwgrakzFGYmsCcoMtxaxnBUFwra57bI931x/RHGZScyISdUZEamx3P9gtGcOTE7ZLuVa/ynd3ZTmJUQqPg0Ii2OGreHiromDpbWhRXjOaPT+WhfWUiq1kd7SxmW7ApxNVo0ryLVjmU8LAmtm6cD1h8qp6y2kbwUF9uKqvD4g6ZqG9u2jAHOm5LLPZdMYfW+MlLjYvjXtbP5xWdOZt3BCm5+5GP+t/U4yS5HWLerxbT8VC6altcqPSawjGJtIx8fKMNhUzy88gAvbTga2OehFftJi3cyp53BYmKsg0Xjs3htU7Or2ufTJpI6t7X7HIzbdV9xLVprPthVwvicRLKTXEwYlsSO49X+utStU5vAiNiJanfIQPBAaR1JLkeIx8Ry+24KWle4qLIBpz38UoQ5yWYhlVq3hx3HanA5bYxMjycvNY7xOYkh88bVDU2s2F3Kaf5BrFUUJbgmvN2mGJEWz8Tc5HZL7wZz+5njWP39s/jeBScxNjuJrywew7fPndDrxoOIsTAkWDg+i5IaN+sPV/Cxfz5w9ujWla66woRhSR26u8dmJ1JZ38TO4zW8v6skpMxmZyjMSqTWHzgD4V2FkZKX4qKosgGtzQBlzf5yLp6W16pddpvi7osntyoNaAViFVe7uXreqMBxI/wpVP/95BB7S2o566ScVu/9/84cx8j0eL793w3UuD1orfloXxnzCtPDfi7DIrSMoTkY6e1tJ7DbFDctLKShyRcQkjp325axxRfmj+L+a2bx+E3zyEqK5aJpeXznvAl8cqCc93eVMDE3ucPr99vLp/HsVxeEbLPc7YfL69lWVM2Npxcyc2Qqdz2zkW1FVeyv9PLO9hPceHphh2284ORhHKtq4O3txvr/7Zs7qKhr4pQ2pj9GZyRQ7fawcm8pH+4p4ZxJJlVq/LAkqhs8HK1soK7JQ4zD1ur7vMhvqS4PslQPltUxKiM+5HOw2RST8pJDPBHHKhvISXa1WmsbQgt/7DhexficpMB+i8ZnsXpfWSDdavmOYhq9Pm47Yywpcc6AGLdcK/2u8ydyxzkT2v3sgol12PssuDQYEWNhSLBkYjZOu+KNzcf4eH85CTH2Nuf8egIrovrqf31EjdvDDaeO7tJ5WgajHSitw+W0tVnwoz3yUuNwe0w5wpf9ltnF0/M6dTxArMPGZ2cOD2wf4V99649v7SIzMZbPBL1mkRDr4LeXT+NIRT13PbORHcerKa52h60+Fvxe7c0Zj86IJ8ZuC9TRfnvbCeaMTgtMB2w5WonPp6lr8pIQwRrd50weRmFWs/fiq4vHsvr7Z/Hnq2ZwdweeEDBz48mu0Hl2h7886TvbT+D1aeYXpvO3q2eR5HJyw4NreHJHI8kuB9ecMqqNszZz9qRhFGYmcMujn3Dr42v567I9XDV3JBcFLcYQTIE/ovquZzaREOPgS6eZcrPW72DnsWrqG71h077y0+MZk5UQYqkeLKsL68U4eXgK24qqAnXLiyrr2wzetKYfXt5QZCLUg7wyi8Zn0+j1Bbwnb2w5RkZCDHNGpzNndDqr97ewjP2/gXMnD+O0cZ2fAuprRIyFIUFKnJMFYzJ5fcsx1uwvY+aotIjdWNHAiqguq3Xzl8/PDBRI6Cwta23vL61jVHpCWKujI6wiIPe+sYPn1h1hWn5qpyzs7KRYXE4bF03LC5lPts5b2+jli6eNbjP/efbodL59zgRe3ljE5X836W/zwtTlBrh63kjuv8aIVls47DYKsxLYeaya3Sdq2HG8mrNOyqEwMwGX08bmI1U0eLxoTdjUpkhwOe1cNC2vVXBQZ0iPN8F8SsHMUWkMS3HxwPVzqG5oYluZj+tPLWgl4uFIjHXwwm2nct7kYbyysYiF47O455LJbVrs1hzqwbI6vnjqaNL81qDlUdjuF+OW88UWi8Zns2pvKfWNXrw+zeHyOkaGiVWYMjyZhiYfRbVGjI+FKSRjMT0/lZkjU/n9WzspqWkMiVeYPTqNOKedd3cUU1ztZtn2E5w9KQe7TTG/MJ19JbWcqGpoFuMOat/3d7r2jRSEAch5U4bx3Wc3AXD+lPDWQ0+RkxzLhSfnctakbM6e1NptGylWZPjegGVc2+WVZRZPyOL6BaN5ZOV+fBp+9KlJnTreYbfx9C0LWs1XJ8c5SIp1oDEpJe1x65KxTMpN5o6nN5AcFxc26AZMStM5/gpU7TFhWBKr9pby/5auI8nl4FNT83DYbZyUm8zmI5XUNBiXZySWcU+RnhDD3pJaJuQkBUR3Ul4y/7hmNve++DFf7ITXJMnl5C+fn8G1+0YxdURqh0uUOmyK+Bg7Xzq9MLA9Jc5JboqLFXtKiHPaW0VSWyyekMUDH+5j1b5SxmYl0uTVYWMVpvgzCg5UedFaU1TZwDmTw1vGcTF2nvnKAj7cXcpLG46GLLHocto5ZUwGy3cWc7zKTZNPc6O/3XP9631/tK+MkppGnHZFctzAlrOB3XpB6ARnT8rhe89tQmvaDY7pCZRS/PXqmd0+j82/ytOe4lp8/nWaF0/I6vjAMDjsNu6+eDKXzRrBc+uOcNnsER0f1IJwRUuUUnx21ggKMhMCiwy0x5KJ2bz9rcXUN3q7HTQzPieJF9Yf5XiVm39fNzsQ+DUlL4Xn1x3hF6+ayOXuWLbdxZqfbJnqd9q4TDyzXO0uCRoOpVSrZTfD4bDbuHreSCYPT2l1Xa6ck88f3toFGMs2HHML0nE5bby7o5gYv+iPCuOmLsxKJM5pZ3+Vj4q6JtweX0iueLj2nzYuM6xredH4LN7ZfoIDpXXced7EgIdpUm4ySbEOnlt3xJ86GNtn2RrRQsRYGDJkJsYyZ3Q6nxwobzdtpL8zYVgSb209zq4TNbg9PkZ2Mx9yyvCUTlUCi4S7L+54TjWYlDhnRMLdEZbI3rZkLGcGBY5NGZ7Mf1Yd4Pn1R/nW2eOZNSo6wXtdwZr3nt3LA0KAn1wyJez2r581npOHp3DXs5vCzgOD31ItzOD59UcCeeThKr/Z/UFcB6oqA1XIulrwxwocmzYihZuCllR12G3cfuY4fv7qNhJjHV3KJuhviBgLQ4rvnDuBrUVVHUaq9me+dFoBz607wveeMy739gp+DDUWjcvi8RvntbIUp/rrOV9w8jBuO6Pt+t+9gWUZz+7DAUE4zjwphw/vzMLXzqpV3z53Aj96YQtvbTuBy2kLW8gDTBDX44fL+dPbxtoOl2McCaMzE/jNZ6eyYGxGKxf8l04rYPnOE3y4uzRsTfiBxsC9IwlCF5g9Oj1qKU19xeS8FC6dMZxn15oFDXq7UlB/xmZTLAhTTOWk3GQe+eJc5haET53qTS6dMZzEWGcg6rw/EbzwRTgm56XwzFcWsONYNXWNnjZT+uYXpvPQiv18uKeE08Zmditz4Yo54Vcys9kUv718Ouf98b2Q5UEHKhGJsVLqPOCPgB34l9b6Vy1eV/7XLwDqgOu11muj3FZBEPx8+5wJvLKxCK+vdQF+ITxWVae+Zmx2EmOzey+tridoWaWtJedNyeXvZ8Vz3pmLe3TwMyzFxZvfWNRuEZeBQodirJSyA38FzgYOA2uUUi9qrbcG7XY+MM7/Nw/4u/9REIQeIC81jjvOncCmI5W9mqIlCJES51C94oVoax3vgUYklvFcYLfWei+AUmopcAkQLMaXAI9oU6NvlVIqVSmVq7Uuan06QRCiwY1B6SmCIAxsIhlSDwcOBT0/7N/W2X0EQRAEQQhDJJZxOD9Dy3C7SPZBKXUzcLP/aY1SakcE7x8pmUBJh3sNDKQv/RPpS/9E+tI/kb6EJ2wlnEjE+DAQHM42AjjahX3QWt8P3B/Be3YapdTHWuvZPXHu3kb60j+RvvRPpC/9E+lL54jETb0GGKeUKlBKxQCfA15ssc+LwLXKMB+olPliQRAEQYiMDi1jrbVHKXUb8AYmtekBrfUWpdQt/tfvA17FpDXtxqQ23dBzTRYEQRCEwUVEecZa61cxghu87b6g/zVwa3Sb1ml6xP3dR0hf+ifSl/6J9KV/In3pBEq3U/pMEARBEISeR6oFCIIgCEIfMyjEWCl1nlJqh1Jqt1Lqrr5uT2dQSuUrpZYppbYppbYopf6ff/vdSqkjSqn1/r8L+rqtkaCU2q+U2uRv88f+belKqTeVUrv8j72/XE0nUUpNCPrs1yulqpRSXx8o10Up9YBS6oRSanPQtjavg1Lqu/7fzw6l1Ll90+rwtNGXe5VS25VSG5VSzymlUv3bRyul6oOuz31tnrgPaKMvbX6nBuB1eTKoH/uVUuv92/v7dWnrPtx7vxmt9YD+wwSV7QEKgRhgAzCpr9vVifbnAjP9/ycBO4FJwN3At/u6fV3oz34gs8W23wB3+f+/C/h1X7ezk32yA8cw+YED4roAC4GZwOaOroP/+7YBiAUK/L8ne1/3oYO+nAM4/P//Oqgvo4P3629/bfQl7HdqIF6XFq//FvjRALkubd2He+03Mxgs40C5Tq11I2CV6xwQaK2LtH9RDa11NbCNwVe97BLgYf//DwOf7rumdIkzgT1a6wN93ZBI0Vq/B5S12NzWdbgEWKq1dmut92GyIub2RjsjIVxftNb/01p7/E9XYWob9HvauC5tMeCui4V/8aArgCd6tVFdpJ37cK/9ZgaDGA+aUpxKqdHADOAj/6bb/G64BwaCa9ePBv6nlPrEX3ENIEf78879j9l91rqu8TlCbyoD8bpA29dhoP+Gvgi8FvS8QCm1Tin1rlLq9L5qVCcJ950ayNfldOC41npX0LYBcV1a3Id77TczGMQ4olKc/R2lVCLwDPB1rXUVZuWrMcB0oAjj8hkInKq1nolZyetWpdTCvm5Qd1Cm0M3FwH/9mwbqdWmPAfsbUkp9H/AAj/k3FQEjtdYzgG8CjyulkvuqfRHS1ndqwF4X4CpCB7AD4rqEuQ+3uWuYbd26NoNBjCMqxdmfUUo5MV+Ax7TWzwJorY9rrb1aax/wT/qRe6o9tNZH/Y8ngOcw7T6ulMoF8D+e6LsWdprzgbVa6+MwcK+Ln7auw4D8DSmlrgM+BVyt/RN5frdhqf//TzBzeeP7rpUd0853aqBeFwfwGeBJa9tAuC7h7sP04m9mMIhxJOU6+y3+uZV/A9u01r8L2p4btNulwOaWx/Y3lFIJSqkk639MkM1mzPW4zr/bdcALfdPCLhEywh+I1yWItq7Di8DnlFKxSqkCzLrkq/ugfRGjlDoPuBO4WGtdF7Q9S5k12FFKFWL6srdvWhkZ7XynBtx18XMWsF1rfdja0N+vS1v3YXrzN9PXUWxRioS7ABP9tgf4fl+3p5NtPw3j3tgIrPf/XQD8B9jk3/4ikNvXbY2gL4WYCMMNwBbrWgAZwNvALv9jel+3NcL+xAOlQErQtgFxXTADiCKgCTOK/1J71wH4vv/3swM4v6/bH0FfdmPm7KzfzH3+fT/r/+5tANYCF/V1+yPoS5vfqYF2XfzbHwJuabFvf78ubd2He+03IxW4BEEQBKGPGQxuakEQBEEY0IgYC4IgCEIfI2IsCIIgCH2MiLEgCIIg9DEixoIgCILQx4gYC4IgCEIfI2IsCIIgCH2MiLEgCIIg9DH/H/rG2vytMMgjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "input_dim = X_mfcc.shape[1]\n",
    "hidden_layers = [20,19,18,17]\n",
    "init_activation = 'relu'\n",
    "activation_funcs = ['relu','relu','relu','relu']\n",
    "optimizer = 'adam'\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = 20\n",
    "(X_mfcc, Y, model) = train_mlp(X_mfcc,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "history_mfcc = model.fit(X_mfcc,Y,epochs=epochs,)\n",
    "results = model.evaluate(X_mfcc_test,Y_test)\n",
    "print(\"test loss, test acc:\", results)\n",
    "pd.DataFrame(history.history).plot(figsize=(8,5))\n",
    "plt.grid(True)\n",
    "plt.gca().set_ylim(0,1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3aa789",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "f32084d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9349, 21)\n",
      "(40249, 21)\n",
      "84\n",
      "(9349, 84)\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "increment = 12\n",
    "#kurtosis, max, mean, medain, min, skew, std\n",
    "X_chroma_cens_collapse_kurtosis = np.average(X_chroma_cens[:,start:start+increment],axis=1).reshape(X_chroma_cens.shape[0],1)\n",
    "X_chroma_cens_test_collapse_kurtosis = np.average(X_chroma_cens_test[:,start:start+increment],axis=1).reshape(X_chroma_cens_test.shape[0],1)\n",
    "X_chroma_cens_collapse_max = np.average(X_chroma_cens[:,start+increment:start+2*increment],axis=1).reshape(X_chroma_cens.shape[0],1)\n",
    "X_chroma_cens_test_collapse_max = np.average(X_chroma_cens_test[:,start+increment:start+2*increment],axis=1).reshape(X_chroma_cens_test.shape[0],1)\n",
    "X_chroma_cens_collapse_mean = np.average(X_chroma_cens[:,start+2*increment:start+3*increment],axis=1).reshape(X_chroma_cens.shape[0],1)\n",
    "X_chroma_cens_test_collapse_mean = np.average(X_chroma_cens_test[:,start+2*increment:start+3*increment],axis=1).reshape(X_chroma_cens_test.shape[0],1)\n",
    "X_chroma_cens_collapse_median = np.average(X_chroma_cens[:,start+3*increment:start+4*increment],axis=1).reshape(X_chroma_cens.shape[0],1)\n",
    "X_chroma_cens_test_collapse_median = np.average(X_chroma_cens_test[:,start+3*increment:start+4*increment],axis=1).reshape(X_chroma_cens_test.shape[0],1)\n",
    "X_chroma_cens_collapse_min = np.average(X_chroma_cens[:,start+4*increment:start+5*increment],axis=1).reshape(X_chroma_cens.shape[0],1)\n",
    "X_chroma_cens_test_collapse_min = np.average(X_chroma_cens_test[:,start+4*increment:start+5*increment],axis=1).reshape(X_chroma_cens_test.shape[0],1)\n",
    "X_chroma_cens_collapse_skew = np.average(X_chroma_cens[:,start+5*increment:start+6*increment],axis=1).reshape(X_chroma_cens.shape[0],1)\n",
    "X_chroma_cens_test_collapse_skew = np.average(X_chroma_cens_test[:,start+5*increment:start+6*increment],axis=1).reshape(X_chroma_cens_test.shape[0],1)\n",
    "X_chroma_cens_collapse_std = np.average(X_chroma_cens[:,start+6*increment:start+7*increment],axis=1).reshape(X_chroma_cens.shape[0],1)\n",
    "X_chroma_cens_test_collapse_std = np.average(X_chroma_cens_test[:,start+6*increment:start+7*increment],axis=1).reshape(X_chroma_cens_test.shape[0],1)\n",
    "\n",
    "X_chroma_cqt_collapse_kurtosis = np.average(X_chroma_cqt[:,start+0*increment:start+1*increment],axis=1).reshape(X_chroma_cqt.shape[0],1)\n",
    "X_chroma_cqt_test_collapse_kurtosis = np.average(X_chroma_cqt_test[:,start+0*increment:start+1*increment],axis=1).reshape(X_chroma_cqt_test.shape[0],1)\n",
    "X_chroma_cqt_collapse_max = np.average(X_chroma_cqt[:,start+1*increment:start+2*increment],axis=1).reshape(X_chroma_cqt.shape[0],1)\n",
    "X_chroma_cqt_test_collapse_max = np.average(X_chroma_cqt_test[:,start+1*increment:start+2*increment],axis=1).reshape(X_chroma_cqt_test.shape[0],1)\n",
    "X_chroma_cqt_collapse_mean = np.average(X_chroma_cqt[:,start+2*increment:start+3*increment],axis=1).reshape(X_chroma_cqt.shape[0],1)\n",
    "X_chroma_cqt_test_collapse_mean = np.average(X_chroma_cqt_test[:,start+2*increment:start+3*increment],axis=1).reshape(X_chroma_cqt_test.shape[0],1)\n",
    "X_chroma_cqt_collapse_median = np.average(X_chroma_cqt[:,start+3*increment:start+4*increment],axis=1).reshape(X_chroma_cqt.shape[0],1)\n",
    "X_chroma_cqt_test_collapse_median = np.average(X_chroma_cqt_test[:,start+3*increment:start+4*increment],axis=1).reshape(X_chroma_cqt_test.shape[0],1)\n",
    "X_chroma_cqt_collapse_min = np.average(X_chroma_cqt[:,start+4*increment:start+5*increment],axis=1).reshape(X_chroma_cqt.shape[0],1)\n",
    "X_chroma_cqt_test_collapse_min = np.average(X_chroma_cqt_test[:,start+4*increment:start+5*increment],axis=1).reshape(X_chroma_cqt_test.shape[0],1)\n",
    "X_chroma_cqt_collapse_skew = np.average(X_chroma_cqt[:,start+5*increment:start+6*increment],axis=1).reshape(X_chroma_cqt.shape[0],1)\n",
    "X_chroma_cqt_test_collapse_skew = np.average(X_chroma_cqt_test[:,start+5*increment:start+6*increment],axis=1).reshape(X_chroma_cqt_test.shape[0],1)\n",
    "X_chroma_cqt_collapse_std = np.average(X_chroma_cqt[:,start+6*increment:start+7*increment],axis=1).reshape(X_chroma_cqt.shape[0],1)\n",
    "X_chroma_cqt_test_collapse_std = np.average(X_chroma_cqt_test[:,start+6*increment:start+7*increment],axis=1).reshape(X_chroma_cqt_test.shape[0],1)\n",
    "\n",
    "#increment = 20\n",
    "X_chroma_stft_collapse_kurtosis = np.average(X_chroma_stft[:,start+0*increment:start+1*increment],axis=1).reshape(X_chroma_stft.shape[0],1)\n",
    "X_chroma_stft_test_collapse_kurtosis = np.average(X_chroma_stft_test[:,start+0*increment:start+1*increment],axis=1).reshape(X_chroma_stft_test.shape[0],1)\n",
    "X_chroma_stft_collapse_max = np.average(X_chroma_stft[:,start+1*increment:start+2*increment],axis=1).reshape(X_chroma_stft.shape[0],1)\n",
    "X_chroma_stft_test_collapse_max = np.average(X_chroma_stft_test[:,start+1*increment:start+2*increment],axis=1).reshape(X_chroma_stft_test.shape[0],1)\n",
    "X_chroma_stft_collapse_mean = np.average(X_chroma_stft[:,start+2*increment:start+3*increment],axis=1).reshape(X_chroma_stft.shape[0],1)\n",
    "X_chroma_stft_test_collapse_mean = np.average(X_chroma_stft_test[:,start+2*increment:start+3*increment],axis=1).reshape(X_chroma_stft_test.shape[0],1)\n",
    "X_chroma_stft_collapse_median = np.average(X_chroma_stft[:,start+3*increment:start+4*increment],axis=1).reshape(X_chroma_stft.shape[0],1)\n",
    "X_chroma_stft_test_collapse_median = np.average(X_chroma_stft_test[:,start+3*increment:start+4*increment],axis=1).reshape(X_chroma_stft_test.shape[0],1)\n",
    "X_chroma_stft_collapse_min = np.average(X_chroma_stft[:,start+4*increment:start+5*increment],axis=1).reshape(X_chroma_stft.shape[0],1)\n",
    "X_chroma_stft_test_collapse_min = np.average(X_chroma_stft_test[:,start+4*increment:start+5*increment],axis=1).reshape(X_chroma_stft_test.shape[0],1)\n",
    "X_chroma_stft_collapse_skew = np.average(X_chroma_stft[:,start+5*increment:start+6*increment],axis=1).reshape(X_chroma_stft.shape[0],1)\n",
    "X_chroma_stft_test_collapse_skew = np.average(X_chroma_stft_test[:,start+5*increment:start+6*increment],axis=1).reshape(X_chroma_stft_test.shape[0],1)\n",
    "X_chroma_stft_collapse_std = np.average(X_chroma_stft[:,start+6*increment:start+7*increment],axis=1).reshape(X_chroma_stft.shape[0],1)\n",
    "X_chroma_stft_test_collapse_std = np.average(X_chroma_stft_test[:,start+6*increment:start+7*increment],axis=1).reshape(X_chroma_stft_test.shape[0],1)\n",
    "\n",
    "X_chroma_merge = np.concatenate([X_chroma_cens_collapse_kurtosis,X_chroma_cens_collapse_max,\n",
    "                                 X_chroma_cens_collapse_mean,X_chroma_cens_collapse_median,\n",
    "                                 X_chroma_cens_collapse_min, X_chroma_cens_collapse_skew,\n",
    "                                 X_chroma_cens_collapse_std,\n",
    "                                 X_chroma_cqt_collapse_kurtosis, X_chroma_cqt_collapse_max,\n",
    "                                 X_chroma_cqt_collapse_mean, X_chroma_cqt_collapse_median,\n",
    "                                 X_chroma_cqt_collapse_min, X_chroma_cqt_collapse_skew,\n",
    "                                 X_chroma_cqt_collapse_std,\n",
    "                                 X_chroma_stft_collapse_kurtosis, X_chroma_stft_collapse_max,\n",
    "                                 X_chroma_stft_collapse_mean, X_chroma_stft_collapse_median,\n",
    "                                 X_chroma_stft_collapse_min, X_chroma_stft_collapse_skew,\n",
    "                                 X_chroma_stft_collapse_std],axis=1)\n",
    "X_chroma_merge_test = np.concatenate([X_chroma_cens_test_collapse_kurtosis,X_chroma_cens_test_collapse_max,\n",
    "                                 X_chroma_cens_test_collapse_mean,X_chroma_cens_test_collapse_median,\n",
    "                                 X_chroma_cens_test_collapse_min, X_chroma_cens_test_collapse_skew,\n",
    "                                 X_chroma_cens_test_collapse_std,\n",
    "                                 X_chroma_cqt_test_collapse_kurtosis, X_chroma_cqt_test_collapse_max,\n",
    "                                 X_chroma_cqt_test_collapse_mean, X_chroma_cqt_test_collapse_median,\n",
    "                                 X_chroma_cqt_test_collapse_min, X_chroma_cqt_test_collapse_skew,\n",
    "                                 X_chroma_cqt_test_collapse_std,\n",
    "                                 X_chroma_stft_test_collapse_kurtosis, X_chroma_stft_test_collapse_max,\n",
    "                                 X_chroma_stft_test_collapse_mean, X_chroma_stft_test_collapse_median,\n",
    "                                 X_chroma_stft_test_collapse_min, X_chroma_stft_test_collapse_skew,\n",
    "                                 X_chroma_stft_test_collapse_std],axis=1)              \n",
    "        \n",
    "print(X_chroma_merge.shape)\n",
    "print(X_chroma_merge_test.shape)\n",
    "\n",
    "print(7*increment)\n",
    "print(X_chroma_stft.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "73c32e85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "293/293 [==============================] - 4s 9ms/step - loss: 2.3254 - accuracy: 0.2082\n",
      "Epoch 2/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.0897 - accuracy: 0.2965\n",
      "Epoch 3/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.0208 - accuracy: 0.3197\n",
      "Epoch 4/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.9710 - accuracy: 0.3304\n",
      "Epoch 5/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.9364 - accuracy: 0.3520\n",
      "Epoch 6/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.9016 - accuracy: 0.3681\n",
      "Epoch 7/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.8767 - accuracy: 0.3798\n",
      "Epoch 8/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.8540 - accuracy: 0.3890\n",
      "Epoch 9/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.8318 - accuracy: 0.3946\n",
      "Epoch 10/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.8170 - accuracy: 0.3989\n",
      "Epoch 11/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.8049 - accuracy: 0.4007\n",
      "Epoch 12/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.7968 - accuracy: 0.4064\n",
      "Epoch 13/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.7795 - accuracy: 0.4125\n",
      "Epoch 14/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.7758 - accuracy: 0.4112\n",
      "Epoch 15/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.7624 - accuracy: 0.4180\n",
      "Epoch 16/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.7597 - accuracy: 0.4151\n",
      "Epoch 17/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.7492 - accuracy: 0.4185\n",
      "Epoch 18/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.7371 - accuracy: 0.4208\n",
      "Epoch 19/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.7331 - accuracy: 0.4280\n",
      "Epoch 20/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.7253 - accuracy: 0.4275\n",
      "Epoch 21/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.7151 - accuracy: 0.4337\n",
      "Epoch 22/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.7061 - accuracy: 0.4346\n",
      "Epoch 23/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6939 - accuracy: 0.4411\n",
      "Epoch 24/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6905 - accuracy: 0.4404\n",
      "Epoch 25/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6850 - accuracy: 0.4440\n",
      "Epoch 26/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6771 - accuracy: 0.4398\n",
      "Epoch 27/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 1.6655 - accuracy: 0.4475\n",
      "Epoch 28/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6644 - accuracy: 0.4450\n",
      "Epoch 29/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6534 - accuracy: 0.4534\n",
      "Epoch 30/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6572 - accuracy: 0.4437\n",
      "Epoch 31/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6555 - accuracy: 0.4488\n",
      "Epoch 32/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6310 - accuracy: 0.4563\n",
      "Epoch 33/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6363 - accuracy: 0.4549\n",
      "Epoch 34/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6459 - accuracy: 0.4530\n",
      "Epoch 35/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6284 - accuracy: 0.4598\n",
      "Epoch 36/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6154 - accuracy: 0.4606\n",
      "Epoch 37/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6004 - accuracy: 0.4688\n",
      "Epoch 38/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.6026 - accuracy: 0.4655\n",
      "Epoch 39/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5961 - accuracy: 0.4685\n",
      "Epoch 40/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5825 - accuracy: 0.4726\n",
      "Epoch 41/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5876 - accuracy: 0.4760\n",
      "Epoch 42/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 1.5801 - accuracy: 0.4778\n",
      "Epoch 43/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5676 - accuracy: 0.4768\n",
      "Epoch 44/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5653 - accuracy: 0.4804\n",
      "Epoch 45/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5614 - accuracy: 0.4787\n",
      "Epoch 46/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5543 - accuracy: 0.4812\n",
      "Epoch 47/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5555 - accuracy: 0.4807\n",
      "Epoch 48/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5391 - accuracy: 0.4879\n",
      "Epoch 49/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5378 - accuracy: 0.4928\n",
      "Epoch 50/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5358 - accuracy: 0.4891\n",
      "Epoch 51/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5276 - accuracy: 0.4893\n",
      "Epoch 52/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.5210 - accuracy: 0.4900\n",
      "Epoch 53/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5274 - accuracy: 0.4933\n",
      "Epoch 54/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.5215 - accuracy: 0.4909\n",
      "Epoch 55/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4992 - accuracy: 0.5005\n",
      "Epoch 56/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4993 - accuracy: 0.5029\n",
      "Epoch 57/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4888 - accuracy: 0.5029\n",
      "Epoch 58/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4855 - accuracy: 0.5052\n",
      "Epoch 59/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.4893 - accuracy: 0.5048\n",
      "Epoch 60/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4719 - accuracy: 0.5087\n",
      "Epoch 61/200\n",
      "293/293 [==============================] - 2s 7ms/step - loss: 1.4546 - accuracy: 0.5149\n",
      "Epoch 62/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4652 - accuracy: 0.5124\n",
      "Epoch 63/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4524 - accuracy: 0.5187\n",
      "Epoch 64/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4475 - accuracy: 0.5164\n",
      "Epoch 65/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4434 - accuracy: 0.5219\n",
      "Epoch 66/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4447 - accuracy: 0.5207\n",
      "Epoch 67/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4262 - accuracy: 0.5255\n",
      "Epoch 68/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4175 - accuracy: 0.5262\n",
      "Epoch 69/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4088 - accuracy: 0.5267\n",
      "Epoch 70/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4114 - accuracy: 0.5295\n",
      "Epoch 71/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4076 - accuracy: 0.5256\n",
      "Epoch 72/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.4024 - accuracy: 0.5313\n",
      "Epoch 73/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3990 - accuracy: 0.5322\n",
      "Epoch 74/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.4270 - accuracy: 0.5342\n",
      "Epoch 75/200\n",
      "293/293 [==============================] - 2s 9ms/step - loss: 1.3816 - accuracy: 0.5372\n",
      "Epoch 76/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3766 - accuracy: 0.5437\n",
      "Epoch 77/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3650 - accuracy: 0.5456\n",
      "Epoch 78/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3700 - accuracy: 0.5444\n",
      "Epoch 79/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3590 - accuracy: 0.5463\n",
      "Epoch 80/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3599 - accuracy: 0.5424\n",
      "Epoch 81/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3641 - accuracy: 0.5413\n",
      "Epoch 82/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3424 - accuracy: 0.5460\n",
      "Epoch 83/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3348 - accuracy: 0.5510\n",
      "Epoch 84/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3386 - accuracy: 0.5545\n",
      "Epoch 85/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3220 - accuracy: 0.5589\n",
      "Epoch 86/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3315 - accuracy: 0.5566\n",
      "Epoch 87/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3083 - accuracy: 0.5631\n",
      "Epoch 88/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3115 - accuracy: 0.5636\n",
      "Epoch 89/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.3068 - accuracy: 0.5616\n",
      "Epoch 90/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.2834 - accuracy: 0.5671\n",
      "Epoch 91/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.2829 - accuracy: 0.5739\n",
      "Epoch 92/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.2848 - accuracy: 0.5724\n",
      "Epoch 93/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 1.2852 - accuracy: 0.5706\n",
      "Epoch 94/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.2886 - accuracy: 0.5713\n",
      "Epoch 95/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 1.2595 - accuracy: 0.5836\n",
      "Epoch 96/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 1.2533 - accuracy: 0.5811\n",
      "Epoch 97/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.2644 - accuracy: 0.5749\n",
      "Epoch 98/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.2557 - accuracy: 0.5823\n",
      "Epoch 99/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.2402 - accuracy: 0.5849\n",
      "Epoch 100/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.2330 - accuracy: 0.5873\n",
      "Epoch 101/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.2242 - accuracy: 0.5972\n",
      "Epoch 102/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.2145 - accuracy: 0.5960\n",
      "Epoch 103/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.2288 - accuracy: 0.5918\n",
      "Epoch 104/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.2147 - accuracy: 0.5935\n",
      "Epoch 105/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.2034 - accuracy: 0.5966\n",
      "Epoch 106/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.1943 - accuracy: 0.6039\n",
      "Epoch 107/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.1985 - accuracy: 0.6011\n",
      "Epoch 108/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.1742 - accuracy: 0.6095\n",
      "Epoch 109/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.1881 - accuracy: 0.6040\n",
      "Epoch 110/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.1855 - accuracy: 0.6082\n",
      "Epoch 111/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.1867 - accuracy: 0.6058\n",
      "Epoch 112/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.1759 - accuracy: 0.6093\n",
      "Epoch 113/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.1712 - accuracy: 0.6079\n",
      "Epoch 114/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.1462 - accuracy: 0.6162\n",
      "Epoch 115/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.1523 - accuracy: 0.6165\n",
      "Epoch 116/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.1342 - accuracy: 0.6223\n",
      "Epoch 117/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.1433 - accuracy: 0.6208\n",
      "Epoch 118/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.1343 - accuracy: 0.6239\n",
      "Epoch 119/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.1139 - accuracy: 0.6346\n",
      "Epoch 120/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.1373 - accuracy: 0.6201\n",
      "Epoch 121/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.1123 - accuracy: 0.6270\n",
      "Epoch 122/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.1033 - accuracy: 0.6322\n",
      "Epoch 123/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.1178 - accuracy: 0.6325\n",
      "Epoch 124/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.0920 - accuracy: 0.6342\n",
      "Epoch 125/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.1017 - accuracy: 0.6331\n",
      "Epoch 126/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.0978 - accuracy: 0.6355\n",
      "Epoch 127/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.0973 - accuracy: 0.6369\n",
      "Epoch 128/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.0977 - accuracy: 0.6433\n",
      "Epoch 129/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.1156 - accuracy: 0.6295\n",
      "Epoch 130/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.0682 - accuracy: 0.6461\n",
      "Epoch 131/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.0337 - accuracy: 0.6568\n",
      "Epoch 132/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.0734 - accuracy: 0.6447\n",
      "Epoch 133/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.0723 - accuracy: 0.6421\n",
      "Epoch 134/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.0467 - accuracy: 0.6545\n",
      "Epoch 135/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.0600 - accuracy: 0.6502\n",
      "Epoch 136/200\n",
      "293/293 [==============================] - 2s 9ms/step - loss: 1.0864 - accuracy: 0.6369\n",
      "Epoch 137/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.0514 - accuracy: 0.6514\n",
      "Epoch 138/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.0388 - accuracy: 0.6620\n",
      "Epoch 139/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 1.0458 - accuracy: 0.6559\n",
      "Epoch 140/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.0359 - accuracy: 0.6534\n",
      "Epoch 141/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 1.0057 - accuracy: 0.6693\n",
      "Epoch 142/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.0243 - accuracy: 0.6619\n",
      "Epoch 143/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.0249 - accuracy: 0.6575\n",
      "Epoch 144/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.0077 - accuracy: 0.6635\n",
      "Epoch 145/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 1.0296 - accuracy: 0.6599\n",
      "Epoch 146/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 1.0388 - accuracy: 0.6615\n",
      "Epoch 147/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.9757 - accuracy: 0.6785\n",
      "Epoch 148/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9983 - accuracy: 0.6709\n",
      "Epoch 149/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.9951 - accuracy: 0.6716\n",
      "Epoch 150/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9568 - accuracy: 0.6814\n",
      "Epoch 151/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9582 - accuracy: 0.6816\n",
      "Epoch 152/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9621 - accuracy: 0.6799\n",
      "Epoch 153/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9827 - accuracy: 0.6786\n",
      "Epoch 154/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9559 - accuracy: 0.6855\n",
      "Epoch 155/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9638 - accuracy: 0.6827\n",
      "Epoch 156/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.9855 - accuracy: 0.6754\n",
      "Epoch 157/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.9470 - accuracy: 0.6834\n",
      "Epoch 158/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9250 - accuracy: 0.6913\n",
      "Epoch 159/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.9469 - accuracy: 0.6860\n",
      "Epoch 160/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293/293 [==============================] - 3s 9ms/step - loss: 0.9642 - accuracy: 0.6838\n",
      "Epoch 161/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9514 - accuracy: 0.6847\n",
      "Epoch 162/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9416 - accuracy: 0.6870\n",
      "Epoch 163/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9346 - accuracy: 0.6934\n",
      "Epoch 164/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.9296 - accuracy: 0.6936\n",
      "Epoch 165/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9680 - accuracy: 0.6810\n",
      "Epoch 166/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9276 - accuracy: 0.6969\n",
      "Epoch 167/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.8920 - accuracy: 0.7045\n",
      "Epoch 168/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9044 - accuracy: 0.7086\n",
      "Epoch 169/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9008 - accuracy: 0.7042\n",
      "Epoch 170/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9019 - accuracy: 0.7006\n",
      "Epoch 171/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9787 - accuracy: 0.6764\n",
      "Epoch 172/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.8754 - accuracy: 0.7148\n",
      "Epoch 173/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.8737 - accuracy: 0.7116\n",
      "Epoch 174/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9331 - accuracy: 0.7015\n",
      "Epoch 175/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.9020 - accuracy: 0.7044\n",
      "Epoch 176/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8757 - accuracy: 0.7114\n",
      "Epoch 177/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.8578 - accuracy: 0.7159\n",
      "Epoch 178/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.8640 - accuracy: 0.7177\n",
      "Epoch 179/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8771 - accuracy: 0.7117\n",
      "Epoch 180/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8527 - accuracy: 0.7163\n",
      "Epoch 181/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8386 - accuracy: 0.7240\n",
      "Epoch 182/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8768 - accuracy: 0.7077\n",
      "Epoch 183/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8331 - accuracy: 0.7261\n",
      "Epoch 184/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8537 - accuracy: 0.7176\n",
      "Epoch 185/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8527 - accuracy: 0.7189\n",
      "Epoch 186/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8911 - accuracy: 0.7067\n",
      "Epoch 187/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8334 - accuracy: 0.7250\n",
      "Epoch 188/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.8362 - accuracy: 0.7209\n",
      "Epoch 189/200\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 0.8576 - accuracy: 0.7154\n",
      "Epoch 190/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.8464 - accuracy: 0.7219\n",
      "Epoch 191/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.8376 - accuracy: 0.7321\n",
      "Epoch 192/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.8344 - accuracy: 0.7242\n",
      "Epoch 193/200\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 0.8155 - accuracy: 0.7322\n",
      "Epoch 194/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8797 - accuracy: 0.7115\n",
      "Epoch 195/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8109 - accuracy: 0.7338\n",
      "Epoch 196/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8190 - accuracy: 0.7322\n",
      "Epoch 197/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8266 - accuracy: 0.7276\n",
      "Epoch 198/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8069 - accuracy: 0.7316\n",
      "Epoch 199/200\n",
      "293/293 [==============================] - 2s 9ms/step - loss: 0.8047 - accuracy: 0.7340\n",
      "Epoch 200/200\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 0.8362 - accuracy: 0.7319\n",
      "1258/1258 [==============================] - 11s 8ms/step - loss: 11.3254 - accuracy: 0.1056\n",
      "test loss, test acc: [11.325444221496582, 0.10564237833023071]\n"
     ]
    }
   ],
   "source": [
    "# Now that we have X_chroma all set up, we need to train and test it\n",
    "input_dim = X_chroma_merge.shape[1]\n",
    "hidden_layers = [20,19,18,17]\n",
    "init_activation = 'relu'\n",
    "activation_funcs = ['relu','relu','relu','relu']\n",
    "optimizer = 'adam'\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = 200\n",
    "(X_chroma_merge, Y, model) = train_mlp(X_chroma_merge,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "history = model.fit(X_chroma_merge,Y,epochs=epochs,)\n",
    "results = model.evaluate(X_chroma_merge_test,Y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "66de0996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9349, 7)\n",
      "(40249, 7)\n",
      "42\n",
      "(9349, 42)\n",
      "[[ 0.20907183 -0.04795524  0.23917748  0.98904675 -0.03416466 -0.01869483]\n",
      " [ 2.5969286  -0.1362452  -0.5054727  -0.01988691 -0.1878658   4.2842083 ]\n",
      " [ 0.7060461   1.2577915  -0.4130194   1.0615699  -0.09775992  0.42199284]\n",
      " ...\n",
      " [-0.24188799 -0.200364   -0.3140691  -0.20671429 -0.23203039 -0.26597607]\n",
      " [ 0.36613807 -0.24815409 -0.7869396  -0.28091946 -0.4870557  -0.1599629 ]\n",
      " [-0.19974287 -0.11263731 -0.49169943  0.67468435 -0.19026972 -0.08547851]]\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "increment = 6\n",
    "#kurtosis, max, mean, medain, min, skew, std\n",
    "X_tonnetz_collapse_kurtosis = np.average(X_tonnetz[:,start:start+increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_kurtosis = np.average(X_tonnetz_test[:,start:start+increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "X_tonnetz_collapse_max = np.average(X_tonnetz[:,start+increment:start+2*increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_max = np.average(X_tonnetz_test[:,start+increment:start+2*increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "X_tonnetz_collapse_mean = np.average(X_tonnetz[:,start+2*increment:start+3*increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_mean = np.average(X_tonnetz_test[:,start+2*increment:start+3*increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "X_tonnetz_collapse_median = np.average(X_tonnetz[:,start+3*increment:start+4*increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_median = np.average(X_tonnetz_test[:,start+3*increment:start+4*increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "X_tonnetz_collapse_min = np.average(X_tonnetz[:,start+4*increment:start+5*increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_min = np.average(X_tonnetz_test[:,start+4*increment:start+5*increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "X_tonnetz_collapse_skew = np.average(X_tonnetz[:,start+5*increment:start+6*increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_skew = np.average(X_tonnetz_test[:,start+5*increment:start+6*increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "X_tonnetz_collapse_std = np.average(X_tonnetz[:,start+6*increment:start+7*increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_std = np.average(X_tonnetz_test[:,start+6*increment:start+7*increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "\n",
    "X_tonnetz_merge = np.concatenate([X_tonnetz_collapse_kurtosis,X_tonnetz_collapse_max,\n",
    "                                 X_tonnetz_collapse_mean,X_tonnetz_collapse_median,\n",
    "                                 X_tonnetz_collapse_min, X_tonnetz_collapse_skew,\n",
    "                                 X_tonnetz_collapse_std],axis=1)\n",
    "X_tonnetz_merge_test = np.concatenate([X_tonnetz_test_collapse_kurtosis,X_tonnetz_test_collapse_max,\n",
    "                                 X_tonnetz_test_collapse_mean,X_tonnetz_test_collapse_median,\n",
    "                                 X_tonnetz_test_collapse_min, X_tonnetz_test_collapse_skew,\n",
    "                                 X_tonnetz_test_collapse_std],axis=1)     \n",
    "print(X_tonnetz_merge.shape)\n",
    "print(X_tonnetz_merge_test.shape)\n",
    "print(7*increment)\n",
    "print(X_tonnetz.shape)\n",
    "\n",
    "print(X_tonnetz[:,start:start+increment])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "1ea419ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "293/293 [==============================] - 3s 8ms/step - loss: 2.7113 - accuracy: 0.1078\n",
      "Epoch 2/5\n",
      "293/293 [==============================] - 2s 8ms/step - loss: 2.6224 - accuracy: 0.1023\n",
      "Epoch 3/5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.5696 - accuracy: 0.1017\n",
      "Epoch 4/5\n",
      "293/293 [==============================] - 3s 9ms/step - loss: 2.5380 - accuracy: 0.0982\n",
      "Epoch 5/5\n",
      "293/293 [==============================] - 3s 10ms/step - loss: 2.5186 - accuracy: 0.1031\n",
      "1258/1258 [==============================] - 12s 9ms/step - loss: 2.3704 - accuracy: 0.0634\n",
      "test loss, test acc: [2.3703606128692627, 0.06338045746088028]\n"
     ]
    }
   ],
   "source": [
    "# Now that we have X_tonnetz all set up, we need to train and test it\n",
    "input_dim = X_tonnetz_merge.shape[1]\n",
    "hidden_layers = [4,2]\n",
    "init_activation = 'relu'\n",
    "activation_funcs = ['relu','relu',]\n",
    "optimizer = 'adam'\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = 5\n",
    "(X_tonnetz_merge, Y, model) = train_mlp(X_tonnetz_merge,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "history = model.fit(X_tonnetz_merge,Y,epochs=epochs,)\n",
    "results = model.evaluate(X_tonnetz_merge_test,Y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2568d60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I think this entire block is old\n",
    "'''\n",
    "start = 412\n",
    "increment = 7\n",
    "#kurtosis, max, mean, medain, min, skew, std\n",
    "X_tonnetz_collapse_kurtosis = np.average(X_tonnetz[:,start:start+increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_kurtosis = np.average(X_tonnetz_test[:,start:start+increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "X_tonnetz_collapse_max = np.average(X_tonnetz[:,start+increment:start+2*increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_max = np.average(X_tonnetz_test[:,start+increment:start+2*increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "X_tonnetz_collapse_mean = np.average(X_tonnetz[:,start+2*increment:start+3*increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_mean = np.average(X_tonnetz_test[:,start+2*increment:start+3*increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "X_tonnetz_collapse_median = np.average(X_tonnetz[:,start+3*increment:start+4*increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_median = np.average(X_tonnetz_test[:,start+3*increment:start+4*increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "X_tonnetz_collapse_min = np.average(X_tonnetz[:,start+4*increment:start+5*increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_min = np.average(X_tonnetz_test[:,start+4*increment:start+5*increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "X_tonnetz_collapse_skew = np.average(X_tonnetz[:,start+5*increment:start+6*increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_skew = np.average(X_tonnetz_test[:,start+5*increment:start+6*increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "X_tonnetz_collapse_std = np.average(X_tonnetz[:,start+6*increment:start+7*increment],axis=1).reshape(X_tonnetz.shape[0],1)\n",
    "X_tonnetz_test_collapse_std = np.average(X_tonnetz_test[:,start+6*increment:start+7*increment],axis=1).reshape(X_tonnetz_test.shape[0],1)\n",
    "\n",
    "X_tonnetz_merge = np.concatenate([X_tonnetz_collapse_kurtosis,X_tonnetz_collapse_max,\n",
    "                                 X_tonnetz_collapse_mean,X_tonnetz_collapse_median,\n",
    "                                 X_tonnetz_collapse_min, X_tonnetz_collapse_skew,\n",
    "                                 X_tonnetz_collapse_std],axis=1)\n",
    "X_tonnetz_merge_test = np.concatenate([X_tonnetz_test_collapse_kurtosis,X_tonnetz_test_collapse_max,\n",
    "                                 X_tonnetz_test_collapse_mean,X_tonnetz_test_collapse_median,\n",
    "                                 X_tonnetz_test_collapse_min, X_tonnetz_test_collapse_skew,\n",
    "                                 X_tonnetz_test_collapse_std],axis=1)     \n",
    "print(X_tonnetz_merge.shape)\n",
    "print(X_tonnetz_merge_test.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e8ad2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now training on everything\n",
    "input_dim = X_tonnetz_merge.shape[1]\n",
    "hidden_layers = [4,2]\n",
    "init_activation = 'relu'\n",
    "activation_funcs = ['relu','relu',]\n",
    "optimizer = 'adam'\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = 5\n",
    "(X_tonnetz_merge, Y, model) = train_mlp(X_tonnetz_merge,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "history = model.fit(X_tonnetz_merge,Y,epochs=epochs,)\n",
    "results = model.evaluate(X_tonnetz_merge_test,Y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "eaf09d67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_cnn(X,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs):\n",
    "    \n",
    "    #usage: history = train_mlp(X,Y,input_dim,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "    \n",
    "    # X: input training matrix\n",
    "    # Y: labels (numerical)\n",
    "    # init_activation: activation function for the first layer (just easier to code if it's separate from the others)\n",
    "    # hidden_layers: list of numbers of nodes for hidden each layer,\n",
    "    # --------------> starting from the second (the first will have all 520 features)\n",
    "    # activation_funcs: activation function for each hidden layer (string)\n",
    "    # optimizer: some kind of thing\n",
    "    # loss: string specifying loss function\n",
    "    # metrics: list of strings of metrics to use to measure the success of the model on training set\n",
    "    # epochs: number of training epochs\n",
    "    \n",
    "    # first, scale data to mean 0 and variance 1\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    # then, get X and Y in proper forms\n",
    "    X = np.asarray(X).astype('float32')\n",
    "    Y = np.asarray(Y).astype('float32')\n",
    "    \n",
    "    inputs = keras.Input(shape=(X.shape[1],X.shape[0]))\n",
    "    x = layers.Conv1D(input_shape=(X.shape[1],X.shape[0]),activation='relu',kernel_size=1,filters=1)(inputs)\n",
    "    for n in range(len(hidden_layers)):\n",
    "        x = layers.Conv1D(input_shape=(X.shape[1],X.shape[0]),activation='relu',filters=1,kernel_size=1)(x)\n",
    "    \n",
    "    x = layers.GlobalMaxPooling1D()(x)\n",
    "    outputs = layers.Dense(16, activation=\"softmax\")(x)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    model.compile(optimizer=optimizer,loss=loss,metrics=metrics)\n",
    "    return (X, Y, model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "994ccb2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 84, 9349) for input KerasTensor(type_spec=TensorSpec(shape=(None, 84, 9349), dtype=tf.float32, name='input_87'), name='input_87', description=\"created by layer 'input_87'\"), but it was called on an input with incompatible shape (None, 84).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\Finn\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Finn\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Finn\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Finn\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Finn\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Finn\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model_60\" (type Functional).\n    \n    Input 0 of layer \"conv1d_19\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 84)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 84), dtype=float32)\n      • training=True\n      • mask=None\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_32552/1138316778.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX_chroma_cens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_cnn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_chroma_cens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minit_activation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mhidden_layers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation_funcs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_chroma_cens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_chroma_cens_test\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"test loss, test acc:\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\Finn\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1021, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\Finn\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1010, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\Finn\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1000, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\Finn\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 859, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\Finn\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\Finn\\anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 228, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" '\n\n    ValueError: Exception encountered when calling layer \"model_60\" (type Functional).\n    \n    Input 0 of layer \"conv1d_19\" is incompatible with the layer: expected min_ndim=3, found ndim=2. Full shape received: (None, 84)\n    \n    Call arguments received:\n      • inputs=tf.Tensor(shape=(None, 84), dtype=float32)\n      • training=True\n      • mask=None\n"
     ]
    }
   ],
   "source": [
    "input_dim = X_chroma_cens.shape[1]\n",
    "hidden_layers = [(X_chroma_cens.shape[1],X_chroma_cens.shape[0]),(X_chroma_cens.shape[1],X_chroma_cens.shape[0])]\n",
    "init_activation = 'relu'\n",
    "activation_funcs = ['relu','relu',]\n",
    "optimizer = 'adam'\n",
    "loss = \"sparse_categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "epochs = 5\n",
    "(X_chroma_cens, Y, model) = train_cnn(X_chroma_cens,Y,init_activation,hidden_layers,activation_funcs,optimizer,loss,metrics,epochs)\n",
    "history = model.fit(X_chroma_cens,Y,epochs=epochs,)\n",
    "results = model.evaluate(X_chroma_cens_test,Y_test)\n",
    "print(\"test loss, test acc:\", results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
